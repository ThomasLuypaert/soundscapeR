<?xml version="1.0"?>
<doc>
    <assembly>
        <name>AudioAnalysisTools</name>
    </assembly>
    <members>
        <member name="M:AudioAnalysisTools.AcousticComplexityIndex.CalculateAci(System.Double[0:,0:])">
            <summary>
            Returns an array of ACOUSTIC COMPLEXITY INDICES
            This implements the index of N. Pieretti, A. Farina, D. Morri.
            in "A new methodology to infer the singing activity of an avian community: The Acoustic Complexity Index (ACI)"
            in Ecological Indicators 11 (2011) pp868â€“873.
            </summary>
            <param name="spectrogram">this is an AMPLITUDE spectrum. All its values are positive.</param>
            <returns>array of ACI values.</returns>
        </member>
        <member name="M:AudioAnalysisTools.AcousticComplexityIndex.SumOfAmplitudeDifferences(System.Double[0:,0:])">
            <summary>
            Returns an array of DIFFERENCE values used in top line of calculation of ACOUSTIC COMPLEXITY INDICES
            See the above method.
            NOTE: There is one less difference than the number of elements in the freq bin.
                  When ACI is subsequently calculated, the SUM of freq bin values will be over all values
                  but the sum of DIFFERENCES will be over one less value.
                  WHen ACI is calculated over a long interval i.e. one minute this is not a problem. When calculated over 0.2s, need to compensate.
                  To get an almost correct approx to the ACI value calculated over a long interval, we add the average DIF to the total DIFF.
                  So the number of difference values equals the number of freq bin values, when it comes to calculate ACI = DIFF / SUM
                  This problem arises because of the very short segment duration e.g. 0.2 s segment = 8-9 frames.
            </summary>
            <param name="spectrogram">this is an amplitude spectrum.</param>
            <returns>an array of DIFFERENCE values.</returns>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEntropy.CalculateSpectralEntropies(System.Double[0:,0:],System.Int32,System.Int32)">
            <summary>
            Calculates three SUMMARY INDICES - three different measures of spectral entropy.
            Each of them is derived from the frames of the passed amplitude spectrogram.
            1. the entropy of the average spectrum.
            2. the entropy of the variance spectrum.
            3. the entropy of the Coeff of Variation spectrum.
            </summary>
            <param name="amplitudeSpectrogram">matrix.</param>
            <param name="lowerBinBound">lower bin bound to be included in calculation of summary index.</param>
            <param name="reducedFreqBinCount">total bin count to be included in calculation of summary index.</param>
            <returns>two doubles.</returns>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEntropy.CalculateEntropyOfSpectralPeaks(System.Double[0:,0:],System.Int32,System.Int32)">
            <summary>
            CALCULATES THE ENTROPY OF DISTRIBUTION of maximum SPECTRAL PEAKS.
            Only spectral peaks between the lowerBinBound and the upperBinBound will be included in calculation.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.TimeStart">
            <summary>
            Gets the time offset from start of current segment to start of event in seconds.
             Proxied to EventBase.EventStartSeconds.
            </summary>
            <remarks>
            <para>
            NOTE: <see cref="P:AudioAnalysisTools.AcousticEvent.TimeStart"/> is relative to the start of a segment. This notion is obsolete!
            Events must always be stored relative to start of the recording.
            </para>
            Note: converted to private setter so we can control how this is set. Recommend using <see cref="M:AudioAnalysisTools.AcousticEvent.SetEventPositionRelative(System.TimeSpan,System.Double,System.Double)"/>
            after event instantiation to modify bounds.
            </remarks>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.TimeEnd">
            <summary>
            Gets the time offset (in seconds) from start of current segment to end of the event.
            This field is NOT in EventBase. EventBase only requires TimeStart because it is designed to also accomodate points.
            </summary>
            <remarks>
            <para>
            NOTE: <see cref="P:AudioAnalysisTools.AcousticEvent.TimeStart"/> is relative to the start of a segment. This notion is obsolete!
            Events must always be stored relative to start of the recording.
            </para>
            Note: converted to private setter so we can control how this is set.
            Recommend using <see cref="M:AudioAnalysisTools.AcousticEvent.SetEventPositionRelative(System.TimeSpan,System.Double,System.Double)"/> after event instantiation to modify bounds.
            </remarks>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.EventEndSeconds">
            <summary>
            Gets the end time of an event relative to the recording start.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.EventStartSeconds">
            <summary>
            Gets the start time of an event relative to the recording start.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.LowFrequencyHertz">
            <summary>
            Gets or sets units = Hertz.
            Proxied to EventBase.MinHz.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.HighFrequencyHertz">
            <summary>Gets or sets units = Hertz.</summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.Bandwidth">
            <summary>
            Gets the bandwidth of an acoustic event.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.Oblong">
            <summary>
            Gets or sets the bounds of an event with respect to the segment start
            BUT in terms of the frame count (from segment start) and frequency bin (from zero Hertz).
            This is no longer the preferred way to operate with acoustic event bounds.
            Better to use real units (seconds and Hertz) and provide the acoustic event with scale information.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.FreqBinCount">
            <summary> Gets or sets required for conversions to &amp; from MEL scale AND for drawing event on spectrum.</summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.FreqBinWidth">
            <summary>
            Gets required for freq-binID conversions.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.FrameDuration">
            <summary> Gets frame duration in seconds.</summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.FrameOffset">
            <summary> Gets or sets time between frame starts in seconds. Inverse of FramesPerSecond.</summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.FramesPerSecond">
            <summary> Gets or sets number of frame starts per second. Inverse of the frame offset.</summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.ScoreNormalised">
            <summary> Gets or sets score normalised in range [0,1]. NOTE: Max is set = to five times user supplied threshold.</summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.Score_MaxPossible">
            <summary> Gets max Possible Score: set = to 5x user supplied threshold.
            An arbitrary value used for score normalisation - it displays well in plot.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.Score2">
            <summary> Gets or sets second score if required.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.Periodicity">
            <summary>
            Gets or sets the periodicity of acoustic energy in an event.
            Use for events which have an oscillating acoustic energy - e.g. for frog calls.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.Intensity">
            <summary>Gets or sets assigned value when reading in a list of user identified events. Indicates a user assigned assessment of event intensity.</summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.Quality">
            <summary>Gets or sets assigned value when reading in a list of user identified events. Indicates a user assigned assessment of event quality.</summary>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.AcousticEvent"/> class.
            Sets some default colors for drawing an event on a spectrogram.
            THis is the first of three constructors.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.#ctor(System.TimeSpan,System.Double,System.Double,System.Double,System.Double)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.AcousticEvent"/> class.
            This constructor requires the minimum information to establish the temporal and frequency bounds of an acoustic event.
            </summary>
            <param name="segmentStartOffset">The start of the current segment relative to start of recording.</param>
            <param name="eventStartSegmentRelative">event start with respect to start of segment.</param>
            <param name="eventDuration">event end with respect to start of segment.</param>
            <param name="minFreq">Lower frequency bound of event.</param>
            <param name="maxFreq">Upper frequency bound of event.</param>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.EventDurationSeconds">
            DIMENSIONS OF THE EVENT
            <summary>Gets the event duration in seconds.</summary>
        </member>
        <member name="P:AudioAnalysisTools.AcousticEvent.Profile">
            <summary>
            Gets or sets which profile (combination of settings in a config file) produced this event.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.SetEventPositionRelative(System.TimeSpan,System.Double,System.Double)">
            <summary>
            Set the start and end times of an event with respect to the segment start time
            AND also calls method to set event start time with respect the recording/file start.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.SetTimeAndFreqScales(System.Int32,System.Int32,System.Int32)">
            <summary>
            THe only call to this method is from a no-longer used recogniser.
            Could be deleted.
            It sets the time and frequency scales for an event given the sr, and window size.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.SetTimeAndFreqScales(System.Double,System.Double)">
            <summary>
            This method assumes that there is no frame overlap i.e. frame duration = frame offset.
            </summary>
            <param name="framesPerSec">frames per second assuming no overlap.</param>
            <param name="freqBinWidth">Number of hertz per freq bin.</param>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.ConvertHertzToFrequencyBin(System.Boolean,System.Int32,System.Int32,System.Int32,System.Double,System.Int32@,System.Int32@)">
            <summary>
            Converts the Hertz (frequency) bounds of an event to the frequency bin number.
            The frequency bin is an index into the columns of the spectrogram data matrix.
            Since the spectrogram data matrix is oriented with the origin at top left,
            the low frequency bin will have a lower column index than the high freq bin.
            </summary>
            <param name="doMelscale">mel scale.</param>
            <param name="minFreq">lower freq bound.</param>
            <param name="maxFreq">upper freq bound.</param>
            <param name="nyquist">Nyquist freq in Herz.</param>
            <param name="binWidth">frequency scale.</param>
            <param name="leftCol">return bin index for lower freq bound.</param>
            <param name="rightCol">return bin index for upper freq bound.</param>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.ConvertEvent2Oblong(AudioAnalysisTools.AcousticEvent)">
            <summary>
            Calculates the matrix/image indices of the acoustic event, when given the time/freq scales.
            This method called only by previous method:- Acousticevent.SetTimeAndFreqScales().
            Translate time/freq dimensions to coordinates in a matrix.
            columns of matrix are the freq bins. Origin is top left - as per matrix in the sonogram class.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.GetEventAsRectangle">
            <summary>
            Should check that Oblong is not null before calling this method.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.SetScores(System.Double,System.Double,System.Double)">
            <summary>
            Sets the passed score and also a value normalised between a min and a max.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.DrawEvent``1(SixLabors.ImageSharp.Image{``0},System.Double,System.Double,System.Int32)">
            <summary>
            Draws an event on the image. Allows for custom specification of variables.
            Drawing the event requires a time scale and a frequency scale. Hence the additional arguments.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.InitializeAcousticEvent(System.TimeSpan,TowseyLibrary.Oblong,System.Int32,System.Int32,System.Double,System.Double,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.AcousticEvent"/> class.
            This method works ONLY for linear Hertz scale events.
            It requires the event bounds to provided (using Oblong) in terms of time frame and frequency bin counts.
            Scale information must also be provided to convert bounds into real values (seconds, Hertz).
            </summary>
            <param name="o">An oblong initialized with bin and frame numbers marking location of the event.</param>
            <param name="nyquistFrequency">to set the freq scale.</param>
            <param name="binCount">Number of freq bins.</param>
            <param name="frameDuration">tseconds duration of a frame - to set the time scale.</param>
            <param name="frameStep">seconds between frame starts i.e. frame step; i.e. inverse of frames per second. Sets the time scale for an event.</param>
            <param name="frameCount">to set the time scale.</param>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.GetSegmentationEvents(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.Boolean,System.TimeSpan,System.Int32,System.Int32,System.Double,System.Double,System.Double,System.Double)">
            <summary>
            Segments or not depending value of boolean doSegmentation.
            </summary>
            <param name="sonogram">s.</param>
            <param name="doSegmentation">segment? yes/no.</param>
            <param name="segmentStartOffset">time offset.</param>
            <param name="minHz">lower limit of bandwidth.</param>
            <param name="maxHz">upper limit of bandwidth.</param>
            <param name="smoothWindow">window for smoothing the acoustic intensity array.</param>
            <param name="thresholdSD">segmentation threshold - standard deviations above 0 dB.</param>
            <param name="minDuration">minimum duration of an event.</param>
            <param name="maxDuration">maximum duration of an event.</param>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.GetSegmentationEvents(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.TimeSpan,System.Int32,System.Int32,System.Double,System.Double,System.Double,System.Double)">
            <summary>
            Segments the acoustic energy in the passed frequency band and returns as list of acoustic events.
            Noise reduction is done first.
            </summary>
            <param name="sonogram">the full spectrogram.</param>
            <param name="segmentStartOffset">Start of current segment relative to the recording start.</param>
            <param name="minHz">Bottom of the required frequency band.</param>
            <param name="maxHz">Top of the required frequency band.</param>
            <param name="smoothWindow">To smooth the amplitude array.</param>
            <param name="thresholdSD">Determines the threshold for an acoustic event.</param>
            <param name="minDuration">Minimum duration of an acceptable acoustic event.</param>
            <param name="maxDuration">Maximum duration of an acceptable acoustic event.</param>
            <returns>a list of acoustic events.</returns>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.GetEventsInFile(System.Collections.Generic.List{AudioAnalysisTools.AcousticEvent},System.String)">
            <summary>
            returns all the events in a list that occur in the recording with passed file name.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.OverlapsEventInList(System.Collections.Generic.List{AudioAnalysisTools.AcousticEvent})">
            <summary>
            Returns the first event in the passed list which overlaps with this one IN THE SAME RECORDING.
            If no event overlaps return null.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.EventsOverlapInTime(AudioAnalysisTools.AcousticEvent,AudioAnalysisTools.AcousticEvent)">
            <summary>
            Determines if two events overlap in time.
            </summary>
            <param name="event1">event one.</param>
            <param name="event2">event two.</param>
            <returns>true if events overlap.</returns>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.GetEventsAroundMaxima(System.Double[],System.TimeSpan,System.Int32,System.Int32,System.Double,System.TimeSpan,System.TimeSpan,System.Double,System.Double)">
            <summary>
            Given a time series of acoustic amplitude (typically in decibels), finds events that match the passed constraints.
            </summary>
            <param name="values">an array of amplitude values, typically decibel values.</param>
            <param name="segmentStartOffset">not sure what this is about!.</param>
            <param name="minHz">minimum freq of event.</param>
            <param name="maxHz">maximum freq of event.</param>
            <param name="thresholdValue">event threshold in same units as the value array.</param>
            <param name="minDuration">minimum duration of an event.</param>
            <param name="maxDuration">maximum duration of an event.</param>
            <param name="framesPerSec">the time scale - required for drawing events.</param>
            <param name="freqBinWidth">the frequency scale - required for drawing events.</param>
            <returns>an array of class AcousticEvent.</returns>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.ConvertScoreArray2Events(System.Double[],System.Int32,System.Int32,System.Double,System.Double,System.Double,System.Double,System.Double,System.TimeSpan)">
            <summary>
            A general method to convert an array of score values to a list of AcousticEvents.
            NOTE: The score array is assumed to be temporal i.e. each element of the array is derived from a time frame.
            The method uses the passed scoreThreshold in order to calculate a normalised score.
            Max possible score := threshold * 5.
            normalised score := score / maxPossibleScore.
            Some analysis techniques (e.g. Oscillation Detection) have their own methods for extracting events from score arrays.
            </summary>
            <param name="scores">the array of scores.</param>
            <param name="minHz">lower freq bound of the acoustic event.</param>
            <param name="maxHz">upper freq bound of the acoustic event.</param>
            <param name="framesPerSec">the time scale required by AcousticEvent class.</param>
            <param name="freqBinWidth">the freq scale required by AcousticEvent class.</param>
            <param name="scoreThreshold">threshold.</param>
            <param name="minDuration">duration of event must exceed this to count as an event.</param>
            <param name="maxDuration">duration of event must be less than this to count as an event.</param>
            <param name="segmentStart">offset.</param>
            <returns>a list of acoustic events.</returns>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.ExtractScoreArrayFromEvents(System.Collections.Generic.List{AudioAnalysisTools.AcousticEvent},System.Int32,System.String)">
            <summary>
            FOR POSSIBLE DELETION!
            THis method called only once from a frog recogniser class that is no longer used> LitoriaCaerulea:RecognizerBase.
            THis method is potentially useful but can be deleted.
            Attempts to reconstruct an array of scores from a list of acoustic events.
            The events are required to have the passed name (a filter).
            The events are assumed to contain sufficient info about frame rate in order to populate the array.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.AcousticEvent.ClusterEvents(AudioAnalysisTools.AcousticEvent[])">
            <summary>
            Although not currently used, this method and following methods could be useful in future for clustering of events.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.SummaryActivity">
            <summary>
            a set of indices to describe level of acoustic activity and number of acoustic events in recording.
            Location of acoustic events also called segmentation in some literature.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ActivityAndCover.CalculateActivity(System.Double[],System.TimeSpan,System.Double)">
            <summary>
            Returns the number of active frames and acoustic events and their average duration in milliseconds
            Only counts an event if it is LONGER than one frame.
            Count events as number of transitions from active to non-active frame.
            </summary>
            <param name="dBarray">array of DB values.</param>
            <param name="frameStepDuration">frame duration in seconds.</param>
            <param name="dbThreshold">threshold in decibels.</param>
        </member>
        <member name="M:AudioAnalysisTools.ActivityAndCover.CalculateSpectralEvents(System.Double[0:,0:],System.Double,System.TimeSpan,System.Int32,System.Int32,System.Double)">
            <summary>
            Returns the number of acoustic events per second in the each frequency bin.
            Also returns the fractional cover in each freq bin, that is, the fraction of frames where amplitude > threshold.
            WARNING NOTE: This method assumes that a linear herz scale, i.e. that herz bin width is constant over the frequency scale.
            If you have octave freq scale, then call the following method with bin bounds pre-calculated.
            Bin width = Herz per bin i.e. column in spectrogram - spectrogram rotated wrt to normal view.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ActivityAndCover.CalculateSpectralEvents(System.Double[0:,0:],System.Double,System.TimeSpan,System.Int32,System.Int32)">
            <summary>
            Returns the number of acoustic events per second in the each frequency bin.
            Also returns the fractional cover in each freq bin, that is, the fraction of frames where amplitude > threshold.
            WARNING NOTE: If you call this method, you must provide the low and mid-freq bounds as BIN IDs, NOT as Herz values.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.BirdClefExperiment1">
             <summary>
             This class is experimental work on the Bird50 dataset provided by Herve Glotin.
             The work was started in Toulon (February 2016) and continued after my return in March 2016.
             The bird50 dataset is a randomly selected subset of the 2014 BirdClef 500 data set.
             The 2014 competition was won by Dan Stowell (QMUL).
             The 2015 competition containing 999 bird call recordings was won by Mario Lessek (Berlin)
            
             This class prepares species representations of bird calls by summing or averaging the instance representations.
             The representation consists of the concatenation of a set of spectra.
             There are currently five spectra derived from the spectra indices: SPT, RHZ, RVT, RPS and RNG.
             Each spectrum can be reduced from 256 values to say 160 by max pooling the top end of the spctrum.
             NOTE: MEL-scale DOES NOT work for birds because the dominant activity for birds is around 2-4 kHz.
             The MEL-scale effectively obliterates this band of the spectrum.
             </summary>
        </member>
        <member name="T:AudioAnalysisTools.BirdClefExperiment1.Arguments">
            <summary>
            AT: NOTE: arguments classes should not exist outside of the AnalysisPrograms project. I had to remove PowerArgs attributes.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.BirdClefExperiment1.Normalise(AudioAnalysisTools.BirdClefExperiment1.Arguments,AudioAnalysisTools.BirdClefExperiment1.Output)">
            <summary>
            Normalisation and Concatentation of spectra:
            can be done in three ways ie (i) Unit length (ii) Unit Area (iii) Unit bounds i.e. 0,1.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.BirdClefExperiment1.NormaliseVector(System.Double[],System.Double[])">
            <summary>
            Normalises the parts of a concatenated vector separately.
            Finally does a unit length norm in prepration for a dot product to give cosine similairty.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.BirdClefExperiment1.CalculateSimilarityScores(AudioAnalysisTools.BirdClefExperiment1.Arguments,AudioAnalysisTools.BirdClefExperiment1.Output)">
            <summary>
            This done using Cosine similarity. Could also use Euclidian distance.
            </summary>
            <param name=""></param>
        </member>
        <member name="M:AudioAnalysisTools.BirdClefExperiment1.CalculateAccuracy(AudioAnalysisTools.BirdClefExperiment1.Arguments,AudioAnalysisTools.BirdClefExperiment1.Output)">
            <summary>
            Produce a CONFUSION MATRIX and a RANK ORDER MATRIX.
            </summary>
            <param name=""></param>
        </member>
        <member name="M:AudioAnalysisTools.BirdClefExperiment1.ConstructWekaDatasets(AudioAnalysisTools.BirdClefExperiment1.Arguments,AudioAnalysisTools.BirdClefExperiment1.Output)">
            <summary>
            Construct datasets for WEKA machine learning.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.BirdClefExperiment1.MaxPoolingLimited(System.Double[],System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            reduces the dimensionality of a vector by max pooling.
            Used specifically for representation of spectral frames in Herve Glotin work.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ChannelIntegrity.ChannelMeanAndSD(System.Double[],System.Double[])">
            <summary>
            Tried this but first attempt did not seem to provide discriminative information.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.ConfigKeys">
            <summary>
            Defined string constants for keys in config tables.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.MfccConfiguration">
            <summary>
            CEPSTROGRAM - PARAMETERs.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.MfccConfiguration.FilterbankCount">
            <summary>
            Gets or sets the size of the Mel-scale filter bank.
            The default value is 64.
            THe minimum I have seen referenced = 26.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.MfccConfiguration.DoMelScale">
            <summary>
            Gets or sets a value indicating whether to convert linear frequency scale to melscale.
            Default = true.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.MfccConfiguration.CcCount">
            <summary>
            Gets or sets the number of cepstral coefficients.
            The default value is 12.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.MfccConfiguration.IncludeDelta">
            <summary>
            Gets or sets a value indicating whether to include
            the delta features in the returned MFCC feature vector.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.MfccConfiguration.IncludeDoubleDelta">
            <summary>
            Gets or sets a value indicating whether to include
            the delta-delta or acceleration features in the returned MFCC feature vector.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.EndpointDetectionConfiguration">
            <summary>
            SETS PARAMETERS CONCERNING ENERGY, END-POINT DETECTION AND SEGMENTATION.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.EndpointDetectionConfiguration.DetermineVocalisationEndpoints(System.Double[],System.Double)">
             <summary>
             WARNING: calculation of k1 and k2 is faulty.
             MinDecibelReference should not be used ie k1 = EndpointDetectionConfiguration.SegmentationThresholdK1;
             See the alternative below
            
             ************* PARAMETERS FOR:- ENDPOINT DETECTION of VOCALISATIONS
             See Lamel et al 1981.
             They use k1, k2, k3 and k4, minimum pulse length and k1_k2Latency.
             Here we set k1 = k3, k4 = k2,  k1_k2Latency = 0.186s (5 frames)
                              and "minimum pulse length" = 0.075s (2 frames)
             SEGMENTATION_THRESHOLD_K1 = decibels above the minimum level
             SEGMENTATION_THRESHOLD_K2 = decibels above the minimum level
             K1_K2_LATENCY = seconds delay between signal reaching k1 and k2 thresholds
             VOCAL_DELAY = seconds delay required to separate vocalisations
             MIN_VOCAL_DURATION = minimum length of energy pulse - do not use this - accept all pulses.
             SEGMENTATION_THRESHOLD_K1=3.5
             SEGMENTATION_THRESHOLD_K2=6.0
             K1_K2_LATENCY=0.05
             VOCAL_DELAY=0.2.
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.ContentAlgorithms.CreateFullBandTemplate1(AudioAnalysisTools.ContentDescriptionTools.TemplateManifest,System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]})">
            <summary>
            This algorithm is used for full band width events such as a rain and wind.
            It calculates a content score based on a template match to what is in the full spectrum.
            </summary>
            <param name="manifest">A description of the template which is to be created.</param>
            <param name="templateIndices">The actual dictionary of template arrays.</param>
            <returns>A new template.</returns>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.ContentAlgorithms.GetFullBandContent1(System.Collections.Generic.Dictionary{System.String,System.Double[]},AudioAnalysisTools.ContentDescriptionTools.TemplateManifest,System.Collections.Generic.Dictionary{System.String,System.Double[]})">
            <summary>
            This algorithm is used for full band width events such as a rain and wind.
            It calculates a content score based on a template match to what is in the full spectrum.
            </summary>
            <param name="oneMinuteOfIndices">Derived from the source recording.</param>
            <param name="template">A previously prepared template.</param>
            <param name="templateIndices">The actual dictionary of template arrays.</param>
            <returns>A similarity score.</returns>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.ContentAlgorithms.CreateBroadbandTemplate1(AudioAnalysisTools.ContentDescriptionTools.TemplateManifest,System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]})">
            <summary>
            This algorithm is used for broad band events such as a bird chorus.
            It selects acoustic content over a band of several kHz and calculates a content score based on a template match to what is in the band.
            </summary>
            <param name="manifest">A previously prepared template.</param>
            <param name="templateIndices">The actual dictionary of template arrays.</param>
            <returns>A similarity score.</returns>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.ContentAlgorithms.GetBroadbandContent1(System.Collections.Generic.Dictionary{System.String,System.Double[]},AudioAnalysisTools.ContentDescriptionTools.TemplateManifest,System.Collections.Generic.Dictionary{System.String,System.Double[]})">
            <summary>
            This algorithm is used for broad band events such as a bird chorus.
            It selects acoustic content over a band of several kHz and calculates a content score based on a template match to what is in the band.
            </summary>
            <param name="oneMinuteOfIndices">Derived from the source recording.</param>
            <param name="template">A previously prepared template.</param>
            <param name="templateIndices">The actual dictionary of template arrays.</param>
            <returns>A similarity score.</returns>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.ContentAlgorithms.CreateNarrowBandTemplate1(AudioAnalysisTools.ContentDescriptionTools.TemplateManifest,System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]})">
            <summary>
            This algorithm is used for narrow band events such as an insect bird chorus or content due to narrow band calls of a single bird species.
            It searches the full spectrum for a match to the template and then
             calculates how much of the match weight is in the correct narrow freq band.
            </summary>
            <param name="manifest">A previously prepared template.</param>
            <param name="templateIndices">The actual dictionary of template arrays.</param>
            <returns>A similarity score.</returns>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.ContentAlgorithms.GetNarrowBandContent1(System.Collections.Generic.Dictionary{System.String,System.Double[]},AudioAnalysisTools.ContentDescriptionTools.TemplateManifest,System.Collections.Generic.Dictionary{System.String,System.Double[]})">
            <summary>
            This algorithm is used for narrow band events such as an insect bird chorus or content due to narrow band calls of a single bird species.
            It searches the full spectrum for a match to the template and then
             calculates how much of the match weight is in the correct narrow freq band.
            </summary>
            <param name="oneMinuteOfIndices">Derived from the source recording.</param>
            <param name="template">A previously prepared template.</param>
            <param name="templateIndices">The actual dictionary of template arrays.</param>
            <returns>A similarity score.</returns>
        </member>
        <member name="T:AudioAnalysisTools.ContentDescriptionTools.ContentSignatures">
            <summary>
            This class contains methods which use functional templates to scan one or multiple files to obtain a content description.
            For consistency between recordings many parameters such as sample rate, frame size etc, must be declared as constants.
            In addition, the absolute values in the template description dictionary must be normalised using the fixed set of normalization bounds in IndexValueBounds.
            Note that each functional template uses one of a small number of algorithms to calculate a similarity value.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.ContentDescriptionTools.ContentSignatures.IndexValueBounds">
            <summary>
            The following min and max bounds are same as those defined in the IndexPropertiesConfig.yml file as of August 2019.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.ContentDescriptionTools.ContentSignatures.IndexNames">
            <summary>
            Gets an array of six spectral indices that are calculated.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.ContentDescriptionTools.ContentSignatures.UnusedIndexNames">
            <summary>
            Gets an array containing names of spectral indices that are not wanted. They are used to remove unwanted selectors.
            This is a temporary arrangement to utilize existing code.
            TODO Eventually separate out template results so do not have to use the AnalysisResult2 class.
            ToDO: this should now be deleteable.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.ContentSignatures.ContentDescriptionOfMultipleRecordingFiles(System.IO.FileInfo,System.IO.FileInfo)">
            <summary>
            Cycles through a set of acoustic indices in the order listed and calculates one acoustic signature for each minute of recording.
            WARNING!!!! It is assumed that the indices are listed in temporal order of the original recordings and that the original recordings were continuous.
                        When these conditions satisfied, the returned plots contain scores over consecutive minutes.
                        Alternatively could read recording minute from its file name.
            </summary>
            <param name="listOfIndexFiles">A text file, each line being the path to the acoustic indices derived from one recording.</param>
            <param name="templatesFile">A json file containing an array of acoustic templates.</param>
            <returns>A list of plots - each plot is the minute by minute scores for a single template.</returns>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.ContentSignatures.AnalyzeOneMinute(AudioAnalysisTools.ContentDescriptionTools.FunctionalTemplate[],System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.Dictionary{System.String,System.Double[]}},System.Collections.Generic.Dictionary{System.String,System.Double[]},System.Int32)">
            <summary>
            IMPORTANT: The indices passed in the dictionary "oneMinuteOfIndices" must be normalised.
            </summary>
            <param name="templates">The templates read from json file.</param>
            <param name="templatesAsDictionary">The numerical part of each template.</param>
            <param name="oneMinuteOfIndices">The normalised values of the indices derived from one minute of recording.</param>
            <param name="minuteId">The minute ID, i.e. its temporal position.</param>
            <returns>A single instance of a DescriptionResult.</returns>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.ContentVisualization.DrawNormalisedIndexMatrices(System.IO.DirectoryInfo,System.String,System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]})">
            <summary>
            Can be used for visual checking and debugging purposes.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.DataProcessing.ConvertArrayOfFunctionalTemplatesToDictionary(AudioAnalysisTools.ContentDescriptionTools.FunctionalTemplate[])">
            <summary>
            Converts an array of templates to dictionary.
            </summary>
            <param name="array">An array of templates.</param>
            <returns>A dictionary of templates.</returns>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.DataProcessing.ReadIndexMatrices(System.String)">
            <summary>
            Reads in all the index matrices whose keys are in the above array of IndexNames.
            Returns normalised values.
            </summary>
            <param name="filePath">Partial path to the index files.</param>
            <returns>a Dictionary of matrices containing normalised index values.</returns>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.DataProcessing.ReadSpectralIndicesFromIndexMatrices(System.IO.DirectoryInfo,System.String)">
            <summary>
            This method assumes that the start and end minute for reading from index matrices is first and last row respectively of matrices - assuming one minute per row.
            </summary>
            <param name="dir">the directory containing the matrices.</param>
            <param name="baseName">base name of the files.</param>
            <returns>a matrix of indices from required start time to required end time.</returns>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.DataProcessing.ReadSpectralIndicesFromIndexMatrices(System.IO.DirectoryInfo,System.String,System.TimeSpan,System.TimeSpan)">
            <summary>
            Read five sets of acoustic indices into a matrix each row of which is a combined feature vector.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.DataProcessing.GetRequiredIndices(System.Collections.Generic.Dictionary{System.String,System.Double[]},System.String[])">
            <summary>
            Not all templates will use the same indices.
            This method returns a dictionary of the required indices only.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.DataProcessing.ReduceIndicesByFactor(System.Collections.Generic.Dictionary{System.String,System.Double[]},System.Int32)">
            <summary>
            Reduces a dictionary of vectors by a factor. It is assumed that the input vectors are a power of 2 in length i.e. FFT spectra.
            It is assumed that the factor of reduction will also be a power of 2, typically 8 or 16.
            </summary>
            <returns>The dictionary of reduced vectors.</returns>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.DataProcessing.GetFreqBinBounds(System.Int32,System.Int32)">
            <summary>
            Returns the bin bounds assuming that the full spectrum consists of the default value = 256.
            </summary>
            <param name="bottomFrequency">Units = Hertz.</param>
            <param name="topFrequency">Hertz.</param>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.DataProcessing.ScanSpectrumWithTemplate(System.Collections.Generic.Dictionary{System.String,System.Double[]},System.Collections.Generic.Dictionary{System.String,System.Double[]})">
            <summary>
            THis method assumes that the passed template contains only one value for each key.
            </summary>
            <param name="templateDict"> Each kvp = string, double.</param>
            <param name="oneMinuteIndices">the indices.</param>
            <returns>A spectrum of similarity-distance scores.</returns>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.DataProcessing.ConvertDictionaryOfIndicesToMatrix(System.Collections.Generic.Dictionary{System.String,System.Double[]})">
            <summary>
            THis method can be used for debugging purposes.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.DataProcessing.ConvertResultsToDictionaryOfArrays(System.Collections.Generic.List{AudioAnalysisTools.ContentDescriptionTools.DescriptionResult},System.Int32,System.Int32)">
            <summary>
            Converts individual results to a dictionary of plots.
            </summary>
            <param name="results">a list of results for each content type in every minute.</param>
            <param name="arrayLength">The plot length will the total number of minutes scanned, typically 1440 for one day.</param>
            <param name="arrayStart">time start.</param>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.DataProcessing.ConvertResultsToPlots(System.Collections.Generic.List{AudioAnalysisTools.ContentDescriptionTools.DescriptionResult},System.Int32,System.Int32)">
            <summary>
            Converts individual results to a dictionary of plots.
            </summary>
            <param name="results">a list of results for each content type in every minute.</param>
            <param name="plotLength">The plot length will the total number of minutes scanned, typically 1440 or one day.</param>
            <param name="plotStart">time start.</param>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.DataProcessing.SubtractMeanPlusSd(System.Collections.Generic.List{TowseyLibrary.Plot})">
            <summary>
            A score normalization option.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.DataProcessing.SubtractModeAndSd(System.Collections.Generic.List{TowseyLibrary.Plot})">
            <summary>
            This method normalizes a score array by subtracting the mode rather than the average of the array.
            This is because the noise is often not normally distributed but rather skewed.
            However, did not work well.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.DataProcessing.PercentileThresholding(System.Collections.Generic.List{TowseyLibrary.Plot},System.Int32)">
            <summary>
            Subtract the percentile value from the scores and normalize the remaining values in 0,1.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.DataProcessing.GetRandomNumberArray(System.Int32)">
            <summary>
            used for experimental purposes.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.ContentDescriptionTools.DescriptionResult">
            <summary>
            This class holds the results of content description for a unit of recording, assumed to be one-minute.
            The results are held in a dictionary.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.ContentDescriptionTools.EditStatus">
             <summary>
             Templates are initially defined manually in a YAML file. Each template in a YAML file is called a "manifest".
             The array of manifests in a yml file is used to calculate an array of "functional templates" in a json file.
             The json file is generated automatically from the information provided in the manifests.yml file.
             A  template manifest contains the "provenance" of the template (i.e. details of the recordings, source locations etc used to make the functional template.
             It also contains the information required to calculate the template definition.
             The core of a functional template is its definition, which is stored as a dictionary of spectral indices.
             The functional template also contains information required to scan new recordings with the template definition.
            
             Each template manifest in a yml file contains an EditStatus field which describes what to with the manifest.
             There are three options as described below.
             </summary>
        </member>
        <member name="T:AudioAnalysisTools.ContentDescriptionTools.TemplateManifest">
            <summary>
            This is base class for both template manifests and functional templates.
            Most of the fields and properties are common to both manifests and functional templates.
            Manifests contain the template provenance. This does not appear in the functional template because provenance includes path data.
            This class also contains methods to create new or edit existing functional templates based on info in the manifests.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.TemplateManifest.CreateTemplateDefinition(AudioAnalysisTools.ContentDescriptionTools.TemplateManifest)">
            <summary>
            This method calculates new template based on passed manifest.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.ContentDescriptionTools.TemplateManifest.GeneralComment">
            <summary>
            Gets or sets a comment about the template.
            e.g. "Detects light rain".
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.ContentDescriptionTools.TemplateManifest.EditStatus">
            <summary>
            Gets or sets the template edit status.
            EditStatus can be "locked", etc.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.ContentDescriptionTools.TemplateManifest.SpectralReductionFactor">
            <summary>
            Gets or sets the factor by which a spectrum of index values is reduced.
            Full array (256 freq bins) of spectral indices is reduced by the following factor by averaging.
            This is to reduce correlation and computation.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.ContentDescriptionTools.TemplateManifest.BandMinHz">
            <summary>
            Gets or sets the bottom freq of bandpass filter.
            Bandpass filter to be applied where the target content exists only within a narrow band, e.g. 3-4 kHz for Silver-eye band.
            Bottom of the required frequency band.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.ContentDescriptionTools.TemplateManifest.BandMaxHz">
            <summary>
            Gets or sets the top freq of bandpass filter.
            Bandpass filter to be applied where the target content exists only within a narrow band, e.g. 3-4 kHz for Silver-eye band.
            Top of the required frequency band.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.ContentDescriptionTools.SourceAudioProvenance">
            <summary>
            This class holds info about provenance of a recording used to construct a template.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.ContentDescriptionTools.SourceAudioProvenance.Directory">
            <summary>
            Gets or sets the directory containing the source index files".
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.ContentDescriptionTools.SourceAudioProvenance.Basename">
            <summary>
            Gets or sets the basename for the source index files".
            Gets or sets the first minute (or matrix row assuming one-minute per row) of the selected indices.
            The rows/minutes are inclusive.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.ContentDescriptionTools.SourceAudioProvenance.Location">
            <summary>
            Gets or sets the template Recording Location".
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.ContentDescriptionTools.SourceAudioProvenance.StartOffset">
            <summary>
            Gets or sets the first minute (or matrix row assuming one-minute per row) of the selected indices.
            The rows/minutes are inclusive.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ContentDescriptionTools.FunctionalTemplate.#ctor(AudioAnalysisTools.ContentDescriptionTools.TemplateManifest)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.ContentDescriptionTools.FunctionalTemplate"/> class.
            CONSTRUCTOR must initialise the info from the Manifest.
            </summary>
            <param name="templateManifest">The template manifest.</param>
        </member>
        <member name="P:AudioAnalysisTools.ContentDescriptionTools.FunctionalTemplate.MostRecentEdit">
            <summary>
            Gets or sets the date the functional template was created.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.Indices.SpectralIndexValuesForContentDescription">
            <summary>
            TODO THIS CLASS IS WORK IN PROGRESS.
            IT IS PART OF CONTENT DESCRIPTION project.
            Purpose of this class is to avoid using the class IndexCalculateResult for returning results from IndexCalculateSixOnly.Analysis();
            This class is stripped down to just the required six spectral indices.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.SpectralIndexValuesForContentDescription.OSC">
            <summary>
            Gets or sets the oscillation spectral index index. Created October 2018.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.SpectralIndexValuesForContentDescription.PMN">
            <summary>
            Gets or sets PMN = Power Minus Noise.
            PMN is measured in decibels but should replace POW as the average decibel spectrogram.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.Indices.ConcatMode">
            <summary>
            Choices in how recording gaps are visualised.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.Indices.ConcatMode.TimedGaps">
            <summary>
            TimedGaps (default): Recording gaps will be filled with a grey "gap" segment of same duration as gap. Time
            scale remains linear and complete. This is, continuity of the time scale is preserved.
            This is the default mode for visualisation.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.Indices.ConcatMode.NoGaps">
            <summary>
            NoGaps: Recording gaps will be ignored. Segments joined without space. Continuity of the time scale will
            be broken. This will be best option when you want to show source data as an uninterrupted visual stream.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.Indices.ConcatMode.EchoGaps">
            <summary>
            EchoGaps: Recording gaps are filled with a repeat of the last three-index spectrum prior to the gap.
            Continuity of the time scale is preserved. Use there are many small, short, non-contigious blocks of
            source data (e.g. Sampling one minute every 10).
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.GapsAndJoins.GapRendering">
            <summary>
            Gets or sets the gap rendering mode.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.GapsAndJoins.DataIntegrityCheck(System.Collections.Generic.IEnumerable{AudioAnalysisTools.Indices.SummaryIndexValues},AudioAnalysisTools.Indices.ConcatMode)">
            <summary>
            Does several data integrity checks.
            </summary>
            <param name="summaryIndices">a dictionary of summary indices.</param>
            <param name="gapRendering">describes how recording gaps are to be rendered.</param>
            <returns>a list of erroneous segments.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Indices.GapsAndJoins.DataIntegrityCheck(System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]},AudioAnalysisTools.Indices.ConcatMode)">
            <summary>
            Does three data integrity checks.
            </summary>
            <param name="spectralIndices">a dictionary of spectral indices.</param>
            <param name="gapRendering">how to render the gap in image terms.</param>
            <returns>a list of erroneous segments.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Indices.GapsAndJoins.WriteErrorsToFile(System.Collections.Generic.List{AudioAnalysisTools.Indices.GapsAndJoins},System.IO.DirectoryInfo,System.String)">
            <summary>
            Writes a list of erroneous segment properties to file.
            </summary>
            <param name="errors">list of erroneous segments.</param>
            <param name="outputDirectory">directory in which json file to be written.</param>
            <param name="fileStem">name of json file.</param>
        </member>
        <member name="M:AudioAnalysisTools.Indices.GapsAndJoins.DataIntegrityCheckRecordingGaps(System.Collections.Generic.IEnumerable{AudioAnalysisTools.Indices.SummaryIndexValues},AudioAnalysisTools.Indices.ConcatMode)">
            <summary>
            This method reads through a SUMMARY index array looking for gaps in the recording.
            I initilly tried to detect these when the RankOrder index takes consecutive zero values.
            However this does not work with recordings sampled one minute in N minutes.
            So reverted to detecting the mising data flag which is when row.FileName == missingRow.
            If this occurs a gap event is flagged.
            </summary>
            <param name="summaryIndices">array of summary indices.</param>
            <param name="gapRendering">how to render the gap in image terms.</param>
            <returns>a list of erroneous segments.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Indices.GapsAndJoins.DataIntegrityCheckForFileJoins(System.Collections.Generic.IEnumerable{AudioAnalysisTools.Indices.SummaryIndexValues},AudioAnalysisTools.Indices.ConcatMode)">
            <summary>
            This method reads through a SUMMARY index array to check for file joins.
            </summary>
            <param name="summaryIndices">array of summary indices.</param>
            <param name="gapRendering">how to render the gap in image terms.</param>
            <returns>a list of erroneous segments.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Indices.GapsAndJoins.DataIntegrityCheckForZeroSignal(System.Collections.Generic.IEnumerable{AudioAnalysisTools.Indices.SummaryIndexValues})">
            <summary>
            This method reads through a ZeroIndex SUMMARY array.
            It reads the ZeroSignal array to make sure there was actually a signal to analyse.
            If this occurs an error is flagged.
            TODO: should do a unit test. Argument should be an a array of zeros with two insertions of short runs of ones.
            //    One of the runs should terminate the array. e.g. 000000000000000000000000000000001111110000000000000000000000001111111111111.
            </summary>
            <param name="summaryIndices">array of summary indices.</param>
            <returns>a list of erroneous segments.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Indices.GapsAndJoins.DataIntegrityCheckIndexValues(System.Collections.Generic.Dictionary{System.String,System.Double[]})">
            <summary>
            This method reads through three SUMMARY index arrays to check for signs that something might be wrong with the data.
            It reads through the ACI, Temporal Entropy and SNR summary index arrays to check that they have positive values.
            These should never be LTE zero. If any of these events occurs, an error is flagged.
            The tests done here are not particularly realistic and the chosen errors are possible unlikely to occur.
            TODO Other data integrity tests can be inserted in the future.
            </summary>
            <param name="summaryIndices">Dictionary of the currently calculated summary indices.</param>
            <returns>a list of erroneous segments.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Indices.GapsAndJoins.DataIntegrityCheckSpectralIndices(System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]},AudioAnalysisTools.Indices.ConcatMode)">
            <summary>
            This method reads through SPECTRAL index matrices to check for signs that something might be wrong with the data.
            Currently, it reads through the ACI matrix to check where the spectral row sums are close to zero. These should never be LTE zero.
            This test is not particularly realistic but might occur.
            Other tests can be inserted in the future.
            </summary>
            <param name="spectralIndices">Dictionary of the currently calculated spectral indices.</param>
            <param name="gapRendering">how to render the gap in image terms.</param>
            <returns>a list of erroneous segments.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Indices.GapsAndJoins.DrawErrorSegments(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},System.Collections.Generic.List{AudioAnalysisTools.Indices.GapsAndJoins},System.Boolean)">
            <summary>
            This method draws error segments on false-colour spectrograms and/or summary index plots.
            This method draws the error segments in hierarchical order, highest level errors first.
            This way error due to missing recording is drawn last and overwrites other casading errors due to missing recording.
            </summary>
            <param name="bmp">The chromeless spectrogram to have segments drawn on it.</param>
            <param name="list">list of erroneous segments.</param>
            <param name="drawFileJoins">drawing file joins is optional.</param>
            <returns>spectrogram with erroneous segments marked.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Indices.GapsAndJoins.DrawErrorPatch(System.Int32,System.Boolean)">
            <summary>
            Draws a error patch based on properties of the error type.
            Depends on how gap rendering is to be done.
            </summary>
            <param name="height">height in pixels of the error patch.</param>
            <param name="textInVerticalOrientation">orientation of error text should match orientation of the patch.</param>
        </member>
        <member name="M:AudioAnalysisTools.Indices.GapsAndJoins.RemoveGapPatch(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},AudioAnalysisTools.Indices.GapsAndJoins)">
            <summary>
            Cuts out gap portion of a spectrogram image.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.GapsAndJoins.DrawEchoPatch(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},AudioAnalysisTools.Indices.GapsAndJoins)">
            <summary>
            Draws an echo patch into a spectrogram image.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.Indices.IndexCalculate">
            <summary>
            Core class that calculates indices.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexCalculate.Analysis(AudioAnalysisTools.WavTools.AudioRecording,System.TimeSpan,System.Collections.Generic.Dictionary{System.String,AudioAnalysisTools.Indices.IndexProperties},System.Int32,System.TimeSpan,AudioAnalysisTools.Indices.IndexCalculateConfig,System.Boolean)">
            <summary>
            Extracts summary and spectral acoustic indices from the entire segment of the passed recording or a subsegment of it.
            </summary>
            <param name="recording"> an audio recording. IMPORTANT NOTE: This is a segment of the larger total recording.</param>
            <param name="subsegmentOffsetTimeSpan">
            The start time of the required subsegment relative to start of SOURCE audio recording.
                i.e. SegmentStartOffset + time duration from Segment start to subsegment start. </param>
            <param name="indexProperties">info about index value distributions. Used when drawing false-colour spectrograms. </param>
            <param name="sampleRateOfOriginalAudioFile"> That is, prior to being resample to the default of 22050.</param>
            <param name="segmentStartOffset"> Time elapsed from absolute start of total recording and start of the passed recording segment i.e. line37. </param>
            <param name="config"> Config variable containing info about the configuration for index calculation.</param>
            <param name="returnSonogramInfo"> boolean with default value = false. </param>
            <returns> An IndexCalculateResult. </returns>
        </member>
        <member name="T:AudioAnalysisTools.Indices.IndexCalculateConfig">
            <summary>
            CONFIG CLASS FOR the class IndexCalculate.cs.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexCalculateConfig.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.Indices.IndexCalculateConfig"/> class.
            CONSTRUCTOR.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexCalculateConfig.IndexCalculationDurationTimeSpan">
            <summary>
            Gets or sets the Timespan (in seconds) over which summary and spectral indices are calculated
            Default=60.0
            Units=seconds.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexCalculateConfig.IndexCalculationDuration">
            <summary>
            Gets or sets the duration of the sub-segment for which indices are calculated.
            Default = 60 seconds i.e. same duration as the Segment.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexCalculateConfig.BgNoiseBuffer">
            <summary>
            Gets bG noise for any location is calculated by extending the region of index calculation from 5 seconds before start to 5 sec after end of current index interval.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexCalculateConfig.BgNoiseNeighborhood">
            <summary>
            Gets or sets the amount of audio either side of the required subsegment from which to derive an estimate of background noise.
            Units = seconds
            As an example: IF (IndexCalculationDuration = 1 second) AND (BGNNeighborhood = 10 seconds)
                           THEN BG noise estimate will be derived from 21 seconds of audio centred on the subsegment.
                           In case of edge effects, the BGnoise neighborhood will be truncated to start or end of the audio segment (typically expected to be one minute long).
            </summary>
            <remarks>
            Ten seconds is considered a minimum interval to obtain a reliable estimate of BG noise.
            The  BG noise interval is not extended beyond start or end of recording segment.
            Consequently for a 60sec Index calculation duration, the  BG noise is calculated form the 60sec segment only.
            Default=5 seconds.
            </remarks>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexCalculateConfig.FrameLength">
            <summary>
            Gets or sets the FrameWidth - the number of samples to use per FFT window.
            FrameWidth is used WITHOUT overlap to calculate the spectral indices.
            Default value = 512.
            Units=samples.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexCalculateConfig.LowFreqBound">
            <summary>
            Gets or sets the LowFreqBound.
            Default value = 1000.
            Units=Herz.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexCalculateConfig.MidFreqBound">
            <summary>
            Gets or sets the MidFreqBound.
            Default value = 8000.
            Units=Herz.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexCalculateConfig.FrequencyScale">
            <summary>
            Gets or sets frequency scale is Linear or Octave.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexCalculateConfig.MinBandWidth">
            <summary>
            Gets or sets the fraction-valued minimum to be used in a pseudo-bandpass filter.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexCalculateConfig.MaxBandWidth">
            <summary>
            Gets or sets the fraction-valued maximum to be used in a pseudo-bandpass filter.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexCalculateConfig.MelScale">
            <summary>
            Gets or sets the number of Mel-scale filter banks to use.
            </summary>
            <remarks>
            The default, 0, implies no operation.
            </remarks>
        </member>
        <member name="T:AudioAnalysisTools.Indices.IndexCalculateSixOnly">
            <summary>
            THis class calculates only six major indices.
            WARNING: DO NOT USE Frame Overlap when calculating acoustic indices.
                     It yields ACI, BGN, POW and EVN results that are significantly different from the default.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexCalculateSixOnly.Analysis(AudioAnalysisTools.WavTools.AudioRecording,System.TimeSpan,System.Int32,System.Boolean)">
            <summary>
            Extracts six spectral acoustic indices from the entire segment of the passed recording.
            </summary>
            <param name="recording"> an audio recording. IMPORTANT NOTE: This is a one minute segment of the larger total recording.</param>
            <param name="segmentOffsetTimeSpan">
            The start time of the required segment relative to start of SOURCE audio recording.</param>
            <param name="sampleRateOfOriginalAudioFile"> That is, prior to being resample to the default of 22050.</param>
            <param name="returnSonogramInfo"> boolean with default value = false.</param>
            <returns> An IndexCalculateResult.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexCalculateSixOnly.GetSonogram(AudioAnalysisTools.WavTools.AudioRecording,System.Int32)">
            <summary>
            Transfers the required six indices from SpectralIndexBase to a dictionary.
            IMPORTANT NOTE: THis method needs to be updated if there is a change to the indices used for content description.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexDisplay.DrawImageOfSummaryIndexTracks(System.IO.FileInfo,System.IO.FileInfo,System.String,System.TimeSpan,System.Nullable{System.DateTimeOffset})">
            <summary>
            Uses a dictionary of index properties to draw an image of summary index tracks.
            </summary>
            <param name="csvFile"> file containing the summary indices.</param>
            <param name="indexPropertiesConfig"> indexPropertiesConfig.</param>
            <param name="title">image title.</param>
            <param name="indexCalculationDuration"> The index Calculation Duration. </param>
            <param name="recordingStartDate"> The recording Start Date. </param>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexDisplay.DrawImageOfSummaryIndices(System.Collections.Generic.Dictionary{System.String,AudioAnalysisTools.Indices.IndexProperties},System.IO.FileInfo,System.String,System.TimeSpan,System.Nullable{System.DateTimeOffset})">
            <summary>
            Reads csv file containing summary indices and converts them to a tracks image.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexDisplay.DrawImageOfSummaryIndices(System.Collections.Generic.Dictionary{System.String,AudioAnalysisTools.Indices.IndexProperties},System.Collections.Generic.Dictionary{System.String,System.Double[]},System.String,System.TimeSpan,System.Nullable{System.DateTimeOffset},System.Collections.Generic.List{AudioAnalysisTools.Indices.GapsAndJoins},System.Boolean)">
            <summary>
            Converts summary indices to a tracks image, one track for each index.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexDisplay.DrawHighAmplitudeClippingTrack(System.IO.FileInfo)">
            <summary>
            Reads csv file containing summary indices and converts them to a tracks image.
            </summary>
            <returns>an image of two clipping tracks.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexDisplay.DrawHighAmplitudeClippingTrack(System.Double[],System.Double[])">
            <summary>
            Reads csv file containing summary indices and converts them to a tracks image.
            </summary>
            <returns>a bitmap image.</returns>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexGenerationData.LongDurationSpectrogramConfig">
            <summary>
            Gets or sets the configuration options used to draw long duration spectrograms.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexGenerationData.RecordingExtension">
            <summary>
            Gets or sets the extension of the original audio file.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexGenerationData.BackgroundFilterCoeff">
            <summary>
            Gets or sets backgroundFilterCoeff is used to adjust colour contrast of false-colour images. Default = 0.75.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexGenerationData.FrameLength">
            <summary>
             Gets or sets default value for frame width from which spectrogram was derived.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexGenerationData.FrameStep">
            <summary>
             Gets or sets default value for frame step from which spectrogram was derived. There may be overlap.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexGenerationData.RecordingStartDate">
            <summary>
            Gets or sets the date the audio was recorded. Originally parsed from the file name by <c>FileDateHelpers</c>.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexGenerationData.AnalysisStartOffset">
            <summary>
            Gets or sets how far into the recording the analysis was started.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexGenerationData.IndexCalculationDuration">
            <summary>
            Gets or sets the default is one minute spectra i.e. 60 per hour.  However, as of January 2015, this is not fixed.
            User must enter the time span over which indices are calculated.
            This TimeSpan is used to calculate a tic interval that is appropriate to the time scale of the spectrogram.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.IndexGenerationData.BgNoiseNeighbourhood">
            <summary>
            Gets or sets the default is the entire segment i.e. typically of one minute duration.  However, as of January 2015, this is not fixed.
            User must enter the time span over which indices are calculated.
            If IndexCalculationDuration is set to a brief duration such as 0.2 seconds, then
            the backgroundnoise will be calculated from N seconds before the current subsegment to N seconds after => N secs + subseg duration + N secs.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexGenerationData.GetIndexGenerationData(System.IO.DirectoryInfo)">
            <summary>
            Returns the index generation data from file in passed directory.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexMatrices.ConcatenateSummaryIndexFilesWithTimeCheck(System.IO.FileInfo[],System.TimeSpan)">
            <summary>
            All the passed files will be concatenated. Filtering needs to be done somewhere else.
            </summary>
            <param name="files">array of file names.</param>
            <param name="indexCalcDuration">used to match rows of indices to elapsed time in file names.</param>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexMatrices.ConcatenateSpectralIndexFilesWithTimeCheck(System.IO.FileInfo[],System.TimeSpan,System.String)">
            <summary>
            Concatenates a series of Spectral Index files with a time check,
             i.e. check elapse time in file names against accumulated rows of indices.
            </summary>
            <param name="files">All the passed files will be concatenated. Filtering needs to be done somewhere else.</param>
            <param name="indexCalcDuration">used to match rows of indices to elapsed time in file names.</param>
            <param name="key">this is used only in case need to write an error message. It identifies the key.</param>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexMatrices.GetFilesInDirectories(System.IO.DirectoryInfo[],System.String)">
            <summary>
            Returns a unique, sorted, list of file paths, sorted on file name.
            IMPORTANT: Sorts on alphanumerics, NOT on date or time encoded in the file name.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexMatrices.AddDerivedIndices(System.Collections.Generic.Dictionary{System.String,System.Double[]})">
            <summary>
            DO NOT DELETE THIS METHOD DESPITE NO REFERENCES
            It can be useful in future.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexMatrices.ReadSpectrogram(System.IO.FileInfo,System.Int32@,Acoustics.Shared.TwoDimensionalArray)">
            <summary>
            This method reads spectrogram csv files where the first row contains column names
            and the first column contains row/time names.
            Note: no rotation of data is done!.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexMatrices.ReadSummaryIndexFiles(System.IO.FileInfo[],System.String[])">
            <summary>
            Returns dictionary of spectral indices.
            Assumes both arrays of same length and keys correspond to file name.
            TODO: Do this better one day!.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexMatrices.CompressIndexSpectrograms(System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]},System.TimeSpan,System.TimeSpan,System.Func{System.Double,System.Double})">
            <summary>
            Compresses the spectral index data in the temporal direction by a factor derived from the data scale and
            required image scale.
            In most cases, the compression is done by taking the average. ACI, ENT, BGN, and PMN are special cases,
            requiring a special form of averaging.
            This method got more complicated in June 2016 when it was refactored to cope with recording blocks less than
            one minute long.
            </summary>
            <param name="spectra">The spectra to compress as a dictionary of spectrogram matrices.</param>
            <param name="imageScale">The scale (time resolution) of the compressed output spectrogram.</param>
            <param name="dataScale">
            The scale (time resolution) of the input spectral indices. See <paramref name="spectra"/>.
            </param>
            <param name="roundingFunc">
            How fractional spectra should be dealt with.
            It should be one of or similar to <see cref="M:System.Math.Round(System.Double)"/>,
            <see cref="M:System.Math.Floor(System.Double)"/>, or <see cref="M:System.Math.Ceiling(System.Double)"/>.
            </param>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexMatrices.ReadSpectrogramCsvFiles(System.IO.DirectoryInfo,System.String,System.String[],System.Int32@)">
            <summary>
            Reads a list of Spectrogram Csv Files.
            </summary>
            <param name="ipdir">input dir.</param>
            <param name="fileName">the file name.</param>
            <param name="keys">an array of keys.</param>
            <param name="freqBinCount">number of freq bins.</param>
        </member>
        <member name="T:AudioAnalysisTools.Indices.IndexProperties">
            <summary>
            This class stores the properties of a particular index.
            THIS CLASS DOES NOT STORE THE VALUE OF THE INDEX - the value is stored in class IndexValues.
            This class stores default values, normalisation bounds and provides methods for the correct display of a SUMMARY INDEX in a tracks image.
            Display of SPECTRAL INDICES is handled in the class LDSpectrogramRGB.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexProperties.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.Indices.IndexProperties"/> class.
            constructor sets default values.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexProperties.GetPlotAnnotation">
            <summary>
            Units for indices include: dB, ms, % and dimensionless.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexProperties.GetPlotImage(System.Double[],SixLabors.ImageSharp.Color,System.Collections.Generic.List{AudioAnalysisTools.Indices.GapsAndJoins})">
            <summary>
            This method called from Indexdisplay.DrawImageOfSummaryIndices().
            It draws a single plot/track of one summary index.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexProperties.GetIndexProperties(System.IO.FileInfo)">
            <summary>
            Returns a cached set of configuration properties.
            WARNING CACHED!.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexProperties.Find(AudioAnalysisTools.Indices.IIndexPropertyReferenceConfiguration)">
            <summary>
            Loads the IndexProperties config file, specified by the property <see cref="P:AudioAnalysisTools.Indices.IIndexPropertyReferenceConfiguration.IndexPropertiesConfig"/>
             defined on  <paramref name="configuration" /> which may be found
            relative to the original parent config file <see cref="P:Acoustics.Shared.ConfigFile.IConfig.ConfigPath"/>.
            </summary>
            <remarks>
            This method is intended for use when a config file references another config file, in this case
            an IndexProperties config files, as a string property in the config file.
            </remarks>
            <exception cref="T:Acoustics.Shared.ConfigFile.ConfigFileException">
            if <paramref name="configuration" /> is not null or empty, and does not exist.
            </exception>
            <param name="configuration">
            The configuration object that has the <see cref="P:AudioAnalysisTools.Indices.IIndexPropertyReferenceConfiguration.IndexPropertiesConfig"/>
            key defined. If <see cref="P:AudioAnalysisTools.Indices.IIndexPropertyReferenceConfiguration.IndexPropertiesConfig"/> is not rooted it
            is treated as relative to the parent config file <see cref="P:Acoustics.Shared.ConfigFile.IConfig.ConfigPath"/>'s directory.
            </param>
            <returns>
            <code>null</code> if <paramref name="configuration" /> is null or empty, otherwise a reference to
            the desired config file.
            </returns>
        </member>
        <member name="M:AudioAnalysisTools.Indices.IndexProperties.Find(System.String,System.IO.FileInfo)">
            <summary>
            Loads the IndexProperties config file, specified by <paramref name="relativePath" /> which may be found
            relative to the original config file <paramref name="originalConfigFile"/>.
            </summary>
            <remarks>
            This method is intended for use when a config file references another config file, in this case
            an IndexProperties config files, as a string property in the config file.
            </remarks>
            <exception cref="T:Acoustics.Shared.ConfigFile.ConfigFileException">
            if <paramref name="relativePath" /> is not null or empty, and does not exist.
            </exception>
            <param name="relativePath">
            The path to the config file to find.
            If it is not rooted it is treated as relative to the <paramref name="originalConfigFile"/>'s directory.
            </param>
            <param name="originalConfigFile">
            The config file were the path to <paramref name="relativePath"/> was originally extracted.
            </param>
            <returns>
            <code>null</code> if <paramref name="relativePath" /> is null or empty, otherwise a reference to
            the desired config file.
            </returns>
        </member>
        <member name="T:AudioAnalysisTools.Indices.InitialiseIndexProperties">
            <summary>
            This static class contains all the keys to identify available acoustic indices.
            THIS CLASS DOES NOT STORE THE VALUE OF THE INDEX
               1) the value of spectral indices is stored in class SpectralIndexValues.
               2) the value of summary  indices is stored in class SummaryIndexValues.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.Indices.RainIndices.RainStruct">
            <summary>
            a set of indices derived from each recording.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.RainIndices.GetIndices(System.Double[],System.TimeSpan,System.TimeSpan,System.Double[0:,0:],System.Int32,System.Int32,System.Double)">
             <summary>
            
             </summary>
             <param name="signalEnvelope">envelope of the original signal.</param>
             <param name="spectrogram">the original amplitude spectrum BUT noise reduced.</param>
             <param name="binWidth">derived from original nyquist and window/2.</param>
        </member>
        <member name="M:AudioAnalysisTools.Indices.RainIndices.Get10SecondIndices(System.Double[],System.Double[0:,0:],System.Int32,System.Int32,System.TimeSpan,System.Double)">
            <summary>
            returns some indices relevant to rain and cicadas from a short (10seconds) chunk of audio.
            </summary>
            <param name="signal">signal envelope of a 10s chunk of audio.</param>
            <param name="spectrogram">spectrogram of a 10s chunk of audio.</param>
        </member>
        <member name="M:AudioAnalysisTools.Indices.RainIndices.ConvertAcousticIndices2Classifcations(AudioAnalysisTools.Indices.RainIndices.RainStruct)">
            <summary>
            The values in this class were derived from See5 runs of data taken from ????.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.SpectralIndexValues.ImportFromDictionary(System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]})">
            <summary>
            Imports a dictionary of spectra.
            Assumes `CheckExistenceOfSpectralIndexValues` has already been called.
            Assumes frequency component is in fist index (i.e. frequency is rows) and time in second index (time is columns).
            </summary>
            <param name="dictionaryOfSpectra">
            The dictionary to convert to spectral index base.
            </param>
        </member>
        <member name="M:AudioAnalysisTools.Indices.SpectralIndexValues.CheckExistenceOfSpectralIndexValues(System.Collections.Generic.Dictionary{System.String,AudioAnalysisTools.Indices.IndexProperties})">
            <summary>
            Used to check that the keys in the indexProperties dictionary correspond to Properties in the SpectralIndexValues class.
            Call this method before entering a loop because do not want the error message at every iteration through loop.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.SpectralIndexValues.Configuration">
            <summary>
            Gets the configuration used to generate these results.
            </summary>
            <remarks>
            This property was added when we started generating lots of results that used
            different parameters - we needed a way to disambiguate them.
            </remarks>
        </member>
        <member name="P:AudioAnalysisTools.Indices.SpectralIndexValues.OSC">
            <summary>
            Gets or sets the oscillation spectral index index. Created October 2018.
            6.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Indices.SpectralIndexValues.PMN">
            <summary>
            Gets or sets PMN = Power Minus Noise.
            7: PMN is measured in decibels but should replace POW as the average decibel spectrogram.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.Indices.SpectralIndicesToAndFromTable">
            <summary>
            This class contains methods for interconversion of files of Spectral Indices to/from a single "pivot-table" file.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.SpectralIndicesToAndFromTable.Main(AudioAnalysisTools.Indices.SpectralIndicesToAndFromTable.Arguments)">
            <summary>
            This method started 04-12-2014 to process consecutive days of acoustic indices data for 3-D spectrograms.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.SpectralIndicesToAndFromTable.ReadAllSpectralIndicesAndWriteToDataTable(System.IO.FileInfo,System.IO.DirectoryInfo,System.IO.DirectoryInfo)">
            <summary>
            Reads through multiple directories to read multiple files of spectral indices.
            The spectral indices are combined day-wise into pivot-tables which are written to file.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.SpectralIndicesToAndFromTable.ReadPivotTableToSpectralIndices(System.String)">
            <summary>
            Reads a single csv file in form of table and returns a dictionary of spectral indices.
            </summary>
            <param name="csvFileName">path to file containing a table of spectral index values.</param>
            <returns>dictionary of matrices.</returns>
        </member>
        <member name="T:AudioAnalysisTools.Indices.SummaryIndexValues">
            <summary>
            This class is used to store the values of all indices regardless of type.
            They are stored in dictionaries in order to make them accessible by key without having to write a special method each time a new index is created.
            Some of the functionality is in the parent class IndexBase.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.SummaryIndexValues.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.Indices.SummaryIndexValues"/> class.
            All summary indices initialised to zero except BackgroundNoise and AvgSignalAmplitude both = -100 dB.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Indices.SummaryIndexValues.ConvertToDictionaryOfSummaryIndices(System.Collections.Generic.List{AudioAnalysisTools.Indices.SummaryIndexValues})">
            <summary>
            Put SUMMARY indices into dictionary.
            ################# WARNING: THIS METHOD ONLY GETS A "HARD CODED" LIST OF SUMMARY INDICES. See the method.
            TODO need to generalise the following method.
            </summary>
            <param name="summaryIndices">a list of summary index values ordered by minute segments and not by name of index.</param>
            <returns>a dictionary whose keys are summary index names and values are arrays of double.</returns>
        </member>
        <member name="T:AudioAnalysisTools.CrossCorrelation">
            <summary>
            This class contains two methods that could eventually be deleted.
            The methods are only called by call recognizers that have not been maintained in a long time.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.CrossCorrelation.DetectBarsInTheRowsOfaMatrix(System.Double[0:,0:],System.Double,System.Int32)">
             <summary>
             TODO THis method could eventually be deleted. It has been replaced by the other methods below.
                  Amongst other things, the term "periodicity" is used incorrectly in this method.
                  It actually refers to the "harmonic interval".
             This method assumes the matrix is derived from a spectrogram rotated so that the matrix rows are spectral timeframes of a spectrogram.
            
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.CrossCorrelation.DetectHarmonicsInSonogramMatrix(System.Double[0:,0:],System.Double,System.Int32)">
            <summary>
            TODO TODO this method could be deleted. It is called only by a method to detect crow calls.
            THis is long since superceded.
            A METHOD TO DETECT HARMONICS IN THE ROWS of the passed portion of a sonogram.
            This method assume the matrix is derived from a spectrogram rotated so that the matrix rows are spectral columns of sonogram.
            Was first developed for crow calls.
            First looks for a decibel profile that matches the passed call duration and decibel loudness.
            Then samples the centre portion for the correct harmonic period.
            </summary>
            <param name="m">data matrix.</param>
            <param name="dBThreshold">Minimum sound level.</param>
            <param name="callSpan">Minimum length of call of interest.</param>
            <returns>a tuple.</returns>
        </member>
        <member name="T:AudioAnalysisTools.DSP.Clipping">
            <summary>
            TODO: This class should be Unit tested on a variety of clipped recordings.
            TODO: The calculations employed in this class to estimate clipping need to be revisted. Not clear what to do due to resampling.
            Estimates of clipping are complicated by the fact that down sampling greatly reduces the degree of clipping in a recording.
             Therefore it is difficult to know how much of the original recording was clipped after it has been downsampled.
             The assumption in the current calculations is that we want to know that a recording was clipped before it was subsequently processed.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.Clipping.GetClippingCount(System.Double[],System.Double[],System.Int32,System.Double,System.Int32@,System.Int32@)">
            <summary>
            This method attempts to estimate clipping in a recording.
            What should have been simple was made apparently complicated because downsampling very much affects clipping rate.
            Downsampling reduces the maximum signal value and removes a lot of clipping.
            This method was debugged on a highly clipped recording but hwich had been downsampled.
            </summary>
            <param name="signal">the original signal.</param>
            <param name="envelope">and its envelope.</param>
            <param name="frameStepSize">frame step originally used to calcualte the envelope.</param>
            <param name="epsilon">used to estimate how close wave form must be to max in order to be clipped.</param>
            <param name="highAmplitudeCount">returned high amplitude count.</param>
            <param name="clipCount">returned clip count.</param>
        </member>
        <member name="T:AudioAnalysisTools.DSP.DspFilters">
            <summary>
            digital signal processing FILTERS methods.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DspFilters.GetSignalOfAddedCosines(System.Int32,System.Double,System.Int32[])">
            <summary>
            returns a digital signal having sample rate, duration and harmonic content passed by user.
            Harmonics array should contain Hertz values of harmonics. i.e. int[] harmonics = { 500, 1000, 2000, 4000 };
            Phase is not taken into account.
            Generate Cos waves rather than Sin because amplitude should return to 1.0 if done correctly.
            </summary>
            <param name="sampleRate">sr of output signal.</param>
            <param name="duration">signal duration in seconds.</param>
            <param name="freq">an array of frequency harmonics in Hertz.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DspFilters.PreEmphasis(System.Double[],System.Double)">
            <summary>
            The source signal for voiced speech, that is, the vibration generated by the glottis or vocal chords,
            has a spectral content with more power in low freq than in high. The spectrum has roll off of -6dB/octave.
            Many speech analysis methods work better when the source signal is spectrally flattened.
            The pre-emphasis filter is just a 1-order FIR filter, with gentle roll-off.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DspFilters.AmplifyAndClip(System.Double[],System.Double)">
            <summary>
            This is ultracrude device but ................
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DspFilters.Filter_DecayingSinusoid(System.Double[],System.Double,System.Double,System.Double,System.Double)">
            <summary>
            converts passed arguments into step decay and step radians ie radians per sample or OMEGA.
            </summary>
            <param name="signal">the signal.</param>
            <param name="sf">sampling frequency.</param>
            <param name="tHalf">half life in seconds.</param>
            <param name="period">of the cycle of interest.</param>
            <param name="filterDuration">length of filter in seconds.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DspFilters.FIR_Filter(System.Double[],System.Double[])">
             <summary>
             A "finite impulse response" (FIR) filter uses only the input signals,
             while an "infinite impulse response" filter (IIR) uses
             both the input signal and previous samples of the output signal.
            
             FIR filters are always stable, while IIR filters may be unstable.
             This filter is linear, causal and time-invariant.
             </summary>
             <param name="signal">input signal.</param>
             <param name="filterCoeff">filter coefficients.</param>
             <returns>the filtered signal.</returns>
        </member>
        <member name="T:AudioAnalysisTools.DSP.DSP_Frames">
            <summary>
            Digital signal processing methods.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.DSP_Frames.EnvelopeAndFft.FractionOfHighEnergyFrames">
            <summary>
            Gets or sets the fraction of high energy signal frames PRIOR to noise removal.
            This value is used only when doing noise removal. If the value exceeds SNR.FractionalBoundForMode,
            then Lamel's noise removal algorithm may not work well.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_Frames.FrameStartEnds(System.Int32,System.Int32,System.Int32)">
            <summary>
            Returns the start and end index of all frames in a long audio signal.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_Frames.Frames(System.Double[],System.Int32[0:,0:])">
            <summary>
            Returns the signal broken into frames.
            This method is not called because the only reason to break a signal into frames is to do fft on the frames.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_Frames.ExtractEnvelopeAndFfts(AudioAnalysisTools.WavTools.AudioRecording,System.Boolean,System.Int32,System.Double,System.String)">
            <summary>
            Calling this method will set default FFT window if windowName is null.
            Otherwise sets the FFT window specified in the config file.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_Frames.ExtractEnvelopeAndFfts(AudioAnalysisTools.WavTools.AudioRecording,System.Boolean,System.Int32,System.Int32)">
            <summary>
            Calling this method sets the default FFT window, currently HANNING - see FFT.cs line 22.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_Frames.ExtractEnvelopeAndAmplSpectrogram(System.Double[],System.Int32,System.Double,System.Boolean,System.Int32,System.Double)">
            <summary>
            Calling this method sets the default FFT window, currently HANNING - see FFT.cs line 22.
            Same as previous method but use frame overlap (a double) as an argument rather than framestep (an integer).
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_Frames.ExtractEnvelopeAndAmplSpectrogram(System.Double[],System.Int32,System.Double,System.Boolean,System.Int32,System.Int32,System.String)">
            <summary>
            Returns the following 18 values encapsulated in class EnvelopeAndFft
            1) the minimum and maximum signal values
            2) the average of absolute amplitudes for each frame
            3) the minimum value in each frame
            3) the maximum value in each frame.
            3) the signal envelope as vector. i.e. the maximum of absolute amplitudes for each frame.
            4) vector of frame energies
            5) the high amplitude and clipping counts
            6) the signal amplitude spectrogram
            7) the power of the FFT Window, i.e. sum of squared window values.
            8) the nyquist
            9) the width of freq bin in Hz
            10) the Nyquist bin ID
            AND OTHERS
            The returned info is used by Sonogram classes to draw sonograms and by Spectral Indices classes to calculate Spectral indices.
            Less than half the info is used to draw sonograms but it is difficult to disentangle calculation of all the info without
            reverting back to the old days when we used two classes and making sure they remain in synch.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_Frames.SignalEnvelope(System.Double[0:,0:],System.Double[]@,System.Double[]@)">
            <summary>
            returns the min and max values in each frame. Signal values range from -1 to +1.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_Frames.ZeroCrossings(System.Double[0:,0:])">
            <summary>
            counts the zero crossings in each frame
            This info is used for determining the begin and end points for vocalizations.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.DSP.DSP_IIRFilter">
             <summary>
             digital signal processing FILTERS methods
            
             "Finite impulse response" (FIR) filters use only the input signals,
             while an "infinite impulse response" filter (IIR) uses
             both the input signal and previous samples of the output signal.
             FIR filters are always stable, while IIR filters may be unstable.
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_IIRFilter.CreateFilter(System.String)">
             <summary>
             method to convert string codes to a specific IIR filter.
             FOR EACH NEW FILTER ADD LINE HERE AND WRITE NEW METHOD TO CREATE FILTER
            
             IMPORTANT: These filters assume a SAMPLE RATE = 22050!!!!!!!!!!!!!.
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_IIRFilter.Chebyshev_Highpass_400">
            <summary>
            Create a Chebyshev_Highpass filter, shoulder=400, order=9; ripple=-0.1dB; sr=22050.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_IIRFilter.Chebyshev_Lowpass_1000">
            <summary>
            Create a Chebyshev_lowpass filter, shoulder=1000, order=9; ripple=-0.1dB; sr=22050.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_IIRFilter.Chebyshev_Lowpass_3000">
            <summary>
            Create a Chebyshev_lowpass filter, shoulder=3000, order=9; ripple=-0.1dB; sr=22050.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_IIRFilter.Chebyshev_Lowpass_5000">
            <summary>
            Create a Chebyshev_lowpass filter, shoulder=5000, order=9; ripple=-0.1dB; sr=22050
            Shoulder located at 0.2267573696 Pi.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_IIRFilter.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.DSP.DSP_IIRFilter"/> class.
            CONSTRUCTOR 1.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_IIRFilter.#ctor(System.Double[],System.Double[])">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.DSP.DSP_IIRFilter"/> class.
            CONSTRUCTOR 2
            Pass your own filter coefficients.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.DSP_IIRFilter.ApplyMovingAvHighPassFilter(System.Double[],System.Int32,System.Double[]@)">
            <summary>
            This method implements a crude form of high pass filtering.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.DSP.FeatureExtraction">
            <summary>
            This class is designed to extract clustering features for target input recordings.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FeatureExtraction.UnsupervisedFeatureExtraction(AudioAnalysisTools.DSP.FeatureLearningSettings,System.Collections.Generic.List{System.Double[][]},System.String,System.String)">
            <summary>
            Apply feature learning process on a set of target (1-minute) recordings (inputPath)
            according to the a set of centroids learned using feature learning process.
            Output feature vectors (outputPath).
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.DSP.FeatureLearning">
            <summary>
            This class is designed to learn bases (cluster centroids) through feature learning process.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FeatureLearning.UnsupervisedFeatureLearning(AudioAnalysisTools.DSP.FeatureLearningSettings,System.String)">
            <summary>
            Apply feature learning process on a set of patch sampling set in an unsupervised manner
            Output clusters.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FeatureLearning.MaxPooling(System.Double[0:,0:],System.Int32)">
            <summary>
            This method downsamples the input matrix (x,y) by a factor of n on the temporal scale (x) using max pooling.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FeatureLearning.SemisupervisedFeatureLearning(AudioAnalysisTools.DSP.FeatureLearningSettings,System.String,System.String[0:,0:])">
            <summary>
            This method is called semi-supervised feature learning because one of the clusters is formed using
            the positive frames manually selected from 1-min recordings.
            The input to this methods is a group of files that contains the call of interest,
            a 2D-array that contains file name, the second number and the corresponding frame numbers in each file.
            At the moment, this method only handles single-frames as patches (PatchHeight = 1).
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.DSP.FFT2D">
            <summary>
            Performs two dimensional FFT on a matrix of values.
            IMPORTANT: The matrix passed to this class for performing of 2D FFT need not necessarily have width equal to height
            but both width and height MUST be a power of two.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FFT2D.FFT2Dimensional(System.Double[0:,0:])">
            <summary>
            Performs a 2D-Fourier transform on data in the passed Matrix/image.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FFT2D.Matrix2PaddedVector(System.Double[0:,0:])">
            <summary>
            Concatenates the columns of the passed matrix and inserts zeros in every second position.
            The matrix is assumed to be an image and therefore read it using image coordinates.
            The output vector is now assumed to be a vector of Complex numbers,
            with the real values in the even positions and the imaginary numbers in the odd positions.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FFT2D.Matrix2ComplexVector(System.Double[0:,0:])">
            <summary>
            Concatenates the columns of the passed matrix and inserts zeros in every second position.
            The matrix is assumed to be an image and therefore read it using image coordinates.
            The output vector is now a vector of Complex numbers, with the imaginary part set to 0.
            </summary>
            <remarks>
            This method was created to replicate the functionality of <see cref="M:AudioAnalysisTools.DSP.FFT2D.Matrix2PaddedVector(System.Double[0:,0:])"/>
            to support a changed MathNet API.
            </remarks>
            <param name="M">The input matrix.</param>
            <returns>A flattened <paramref name="M" /> as a vactor.</returns>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FFT2D.FFT2DOutput2MatrixOfMagnitude(System.Double[],System.Int32[])">
            <summary>
            First construct complex sampleData, then calculate the magnitude of sampleData.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FFT2D.fftShift(System.Double[0:,0:])">
            <summary>
            This method "shifts" (that is, "rearranges") the quadrants of the magnitude matrix generated by the 2DFourierTransform
            such that the Top Left  quadrant is swapped with the Bottom-Right quadrant
                  and the Top-Right quadrant is swapped with the Bottom-Left.
            This has the effect of shifting the low frequency coefficients into the centre of the matrix and the high frequency
            coefficients are shifted to the edge of the image.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FFT2D.GetImageDataAsGrayIntensity(System.String,System.Boolean)">
            <summary>
            reads an image into a matrix.
            Takes weighted average of the RGB colours in each pixel.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FFT2D.TestFFT2D">
            <summary>
            METHOD to TEST the FFT2D.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.DSP.FreqScaleType">
            <summary>
            All the below octave scale options are designed for a final freq scale having 256 bins.
            Scale name indicates its structure. You cannot vary the structure.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FrequencyScale.#ctor(System.Int32,System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.DSP.FrequencyScale"/> class.
            CONSTRUCTOR
            Calling this constructor assumes the standard linear 0-nyquist freq scale is required.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FrequencyScale.#ctor(System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.DSP.FrequencyScale"/> class.
            CONSTRUCTOR
            Call this constructor when want to change freq scale but keep it linear.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FrequencyScale.#ctor(AudioAnalysisTools.DSP.FreqScaleType,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.DSP.FrequencyScale"/> class.
            CONSTRUCTOR
            Calling this constructor assumes either Linear or Mel is required but not Octave.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FrequencyScale.#ctor(AudioAnalysisTools.DSP.FreqScaleType,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.DSP.FrequencyScale"/> class.
            CONSTRUCTION OF OCTAVE Frequency Scales
            IMPORTANT NOTE: If you are converting Herz scale from LINEAR to OCTAVE, this conversion MUST be done BEFORE noise reduction
            WARNING!: Changing the constants for the octave scales will have undefined effects.
                      The options below have been debugged to give what is required.
                      However other values have not been debugged - so user should check the output to ensure it is what is required.
            NOTE: octaveToneCount = the number of fractional Hz steps within one octave. A piano octave contains 12 steps per octave.
            NOTE: Not all combinations of parameter values are effective. nor have they all been tested.
                  The following have been tested:
                    nyquist=11025, linearBound=125 t0 1000, octaveToneCount=31, 32.
                    nyquist=11025, linearBound=125, octaveToneCount=31.
                    nyquist=32000, linearBound=125, octaveToneCount=28.
            </summary>
            <param name="type">Scale type must be an OCTAVE type.</param>
            <param name="nyquist">sr / 2.</param>
            <param name="frameSize">Assumes that frame size is power of 2.</param>
            <param name="linearBound">The bound (Hz value) that divides lower linear and upper octave parts of the frequency scale.</param>
            <param name="octaveToneCount">Number of fractional Hz steps within one octave. This is ignored in case of custom scale.</param>
            <param name="hertzGridInterval">Only used where appropriate to draw frequency gridlines.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FrequencyScale.#ctor(AudioAnalysisTools.DSP.FreqScaleType)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.DSP.FrequencyScale"/> class.
            CONSTRUCTOR.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.FrequencyScale.Nyquist">
            <summary>
            Gets or sets half the sample rate.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.FrequencyScale.WindowSize">
            <summary>
            Gets or sets frame size for the FFT.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.FrequencyScale.WindowStep">
            <summary>
            Gets or sets step size for the FFT window.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.FrequencyScale.FinalBinCount">
            <summary>
            Gets or sets number of frequency bins in the final spectrogram.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.FrequencyScale.ScaleType">
            <summary>
            Gets or sets the scale type i.e. linear, octave etc.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.FrequencyScale.HertzGridInterval">
            <summary>
            Gets or sets herz interval between gridlines when using a linear or mel scale.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.FrequencyScale.LinearBound">
            <summary>
            Gets or sets top end of the linear part of an Octave Scale spectrogram.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.FrequencyScale.ToneCount">
            <summary>
            Gets or sets number of bands or tones per octave.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.FrequencyScale.BinBounds">
            <summary>
            Gets or sets the bin bounds of the frequency bands for octave scale
            bin id in first column and the Hz value in second column of matrix.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.FrequencyScale.GridLineLocations">
            <summary>
            Gets or sets the location of gridlines (first column) and the Hz value for the grid lines (second column of matrix).
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FrequencyScale.GetBinIdForHerzValue(System.Int32)">
            <summary>
            returns the binId for freq bin closest to the passed Hertz value.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FrequencyScale.GetBinIdInReducedSpectrogramForHerzValue(System.Int32)">
            <summary>
            returns the binId for the grid line closest to the passed frequency.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FrequencyScale.GetLinearBinBounds">
            <summary>
            Returns an [N, 2] matrix with bin ID in column 1 and lower Herz bound in column 2.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FrequencyScale.GetLinearFreqScale(System.Int32,System.Int32)">
            <summary>
            THis method assumes that the frameSize will be power of 2
            FOR DEBUG PURPOSES, when sr = 22050 and frame size = 8192, the following Hz are located at index:
            Hz      Index
            15        6
            31       12
            62       23
            125      46
            250      93
            500     186
            1000    372.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.FrequencyScale.GetLinearGridLineLocations(System.Int32,System.Int32,System.Int32)">
            <summary>
            T.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.KmeansClustering.SortClustersBasedOnSize(System.Collections.Generic.Dictionary{System.Int32,System.Double})">
            <summary>
            sort clusters based on their size and output the ordered cluster ID
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.KmeansClustering.ReconstructSpectrogram(System.Double[0:,0:],Accord.MachineLearning.KMeansClusterCollection)">
            <summary>
            reconstruct the spectrogram using centroids.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.DSP.LocalContrastNormalisation">
            <summary>
            Performs local contrast normalisation on a matrix of values where the matrix is assumed to be derived from an image.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.LocalContrastNormalisation.ComputeLCN(System.Double[0:,0:],System.Int32)">
             <summary>
             WARNING!!: This method implements a convolution and like all convolutions is very slow (unless it can be fully parellised);
                        Consider using another noise normalisation method such as in the class NoiseRemoval_Briggs.
            
             This method does local contrast normalisation. Typically LCN normalises by division only and is motivated by what is known
             to happen in the visual cortext.
             Every matrix element or pixel value is divided by the (scaled) standard deviation of pixel values
             in a local field centred on the pixel. Scaling affects the severity of the normalisation.
             There are several ways of doing LCN. That is can divide by the local sum of squares. Or can calculate the local z-score
             which effectively normalises by both subtraction and division.
             This method is based on formula given by LeCun. Python code at the bottom of this class is the actual
             code used by LeCun which appears to do something different.
             Wish I knew Python!.
            
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.MFCCStuff.DecibelSpectra(System.Double[0:,0:],System.Double,System.Int32,System.Double)">
            <summary>
            Converts amplitude spectra (in a spectrogram) to dB spectra, normalising for window power and sample rate.
            NOTE 1: This calculation is done in three separate steps in order to avoid duplicating the tricky
                    calculations in the method GetLogEnergySpectrogram().
            NOTE 2: The decibels value is a ratio. Here the ratio is implied.
                    dB = 10*log(amplitude ^2) but in this method adjust power to account for power of Hamming window and SR.
            </summary>
            <param name="amplitudeM"> the amplitude spectra. </param>
            <param name="windowPower">value for window power normalisation.</param>
            <param name="sampleRate">to NormaliseMatrixValues for the sampling rate.</param>
            <param name="epsilon">small value to avoid log of zero.</param>
            <returns>a spectrogram of decibel values.</returns>
        </member>
        <member name="M:AudioAnalysisTools.DSP.MFCCStuff.GetLogEnergySpectrogram(System.Double[0:,0:],System.Double,System.Int32,System.Double)">
            <summary>
            This method converts the passed matrix of spectrogram energy values, (i.e. squared amplitude values) to log-energy values.
            This method is used when calculating standard, mel-freq and mfcc spectrograms.
            In the case of mel-scale, the passed energy spectrogram is output from the mel-frequency filter bank,
            and the energy values are converted directly to log-energy, normalising for window power and sample rate.
            Note that the output is log-energy, not decibels: decibels =  10 * log-energy.
            NOTE 1: THIS METHOD ASSUMES THAT THE LAST FREQ BIN (ie the last matrix column) IS THE NYQUIST FREQ BIN.
            NOTE 2: THIS METHOD ASSUMES THAT THE FIRST FREQ BIN (ie the first matrix column) IS THE MEAN or DC FREQ BIN.
            NOTE 3: The window contributes power to the signal which must subsequently be removed from the spectral power.
            NOTE 4: Spectral power must be normalised for sample rate. Effectively calculate freq power per sample.
            NOTE 5: The power in all freq bins except f=0 must be doubled because the power spectrum is an even function about f=0;
                    This is due to the fact that the spectrum actually consists of 512 + 1 values, the centre value being for f=0.
            </summary>
            <param name="energyM"> the amplitude spectra. </param>
            <param name="windowPower">value for window power normalisation.</param>
            <param name="sampleRate">to NormaliseMatrixValues for the sampling rate.</param>
            <param name="epsilon">small value to avoid log of zero.</param>
            <returns>a spectrogram of decibel values.</returns>
        </member>
        <member name="M:AudioAnalysisTools.DSP.MFCCStuff.Mel(System.Double)">
            <summary>
            Returns a Mel value for the passed Herz value
            NOTE: According to Wikipedia there is no single objective mel(ody) scale conversion.
            Mel scale is based on just-noticeable difference in pitch by the ear with ascend pitch. I.E> THis is psycho-acoustic phenomenon.
            1000Hz is used as the common reference point i.e. 1000Hz = 1000Mel.
            In speech processing, typically use a linear conversion below 1000Hz.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.MFCCStuff.InverseMel(System.Double)">
            <summary>
            Converts a Mel value to Herz.
            NOTE: By default this Mel scale is linear to 1000 Hz.
            </summary>
            <returns>the Herz value.</returns>
        </member>
        <member name="M:AudioAnalysisTools.DSP.MFCCStuff.HerzTranform(System.Double,System.Double,System.Double)">
            <summary>
            this method calculates a user customised version of the fixed mel frequency convernsion in
            the method Mel(double f).
            </summary>
            <param name="f">this is the linear frequncy in Herz.</param>
            <param name="c">this value = 2595.0 in the standard Mel transform.</param>
            <param name="div">this value = 700 in the standard Mel transform.</param>
            <returns>Mel frequency.</returns>
        </member>
        <member name="M:AudioAnalysisTools.DSP.MFCCStuff.LinearFilterBank(System.Double[0:,0:],System.Int32,System.Double,System.Int32,System.Int32)">
            <summary>
            Does linear filterbank conversion for sonogram for any frequency band given by minFreq and maxFreq.
            Performs linear integral as opposed to Mel integral
            The first step is to calculate the number of filters for the required frequency sub-band.
            </summary>
            <param name="matrix">the sonogram.</param>
            <param name="filterBankCount">number of filters over full freq range 0 Hz - Nyquist.</param>
            <param name="nyquist">max frequency in original spectra.</param>
            <param name="minFreq">min freq in passed sonogram matrix.</param>
            <param name="maxFreq">max freq in passed sonogram matrix.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.MFCCStuff.GetMelBinBounds(System.Int32,System.Int32)">
            <summary>
            Returns an [N, 2] matrix with bin ID in column 1 and lower Herz bound in column 2 but on Mel scale.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.MFCCStuff.MelFilterBank(System.Double[0:,0:],System.Int32,System.Double,System.Int32,System.Int32)">
            <summary>
            Does conversion from linear frequency scale to mel-scale for any frequency band given by minFreq and maxFreq.
            Uses Greg's MelIntegral
            The first step is to calculate the number of filters for the required frequency sub-band.
            </summary>
            <param name="matrix">the spectrogram.</param>
            <param name="filterBankCount">number of filters over full freq range 0 Hz - Nyquist.</param>
            <param name="nyquist">max frequency in original spectra.</param>
            <param name="minFreq">min freq in the passed sonogram matrix.</param>
            <param name="maxFreq">max freq in the passed sonogram matrix.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.MFCCStuff.Cepstra(System.Double[0:,0:],System.Int32,System.Double[0:,0:])">
            <summary>
            use this version when want to make matrix of Cosines only one time.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.MFCCStuff.Cosines(System.Int32,System.Int32)">
            <summary>
            Returns a matrix of cosine basis functions.
            These are prepared prior to performing a DCT, Discrete Cosine Transform.
            The rows k = 0 to coeffCount are the basis functions.
            The columns, m = 0 to M where M = signalLength or the length of the required DCT.
            The value of m/M ranges from 0 to 1.0.
            The value of Pi*m/M ranges from 0 to Pi radians.
            The value of k*Pi*m/M ranges from 0 to k*Pi radians. WHen k=2, 2Pi radians corresponds to one rotation.
            </summary>
            <param name="signalLength">The length of the signal to be processed. e.g. the frequency bin count or filter bank count or ...</param>
            <param name="coeffCount">The number of basis funcitons = the rquired number of DCT coefficients.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.MFCCStuff.AcousticVectors(System.Double[0:,0:],System.Double[],System.Boolean,System.Boolean)">
            <summary>
            This method assumes that the supplied mfcc matrix DOES NOT contain frame dB (log energy) values in column zero.
            These are added in from the supplied array of frame log-energies.
            </summary>
            <param name="mfcc">A matrix of mfcc coefficients. Column zero is empty.</param>
            <param name="frameDbNormed">log-energy values for the frames.</param>
            <param name="includeDelta">Whether or not to add delta features.</param>
            <param name="includeDoubleDelta">Whether or not to add double delta features.</param>
            <returns>A matrix of complete mfcc values with additional deltas, frame energies etc.</returns>
        </member>
        <member name="M:AudioAnalysisTools.DSP.MFCCStuff.GetMfccFeatureVector(System.Double[],System.Double[0:,0:],System.Int32,System.Boolean,System.Boolean)">
            <summary>
            Constructs a feature vector of MFCCs including deltas and double deltas as requested by user.
            The dB array has been normalised in 0-1.
            </summary>
            <param name="dB">log-energy values for the frames.</param>
            <param name="matrix">A matrix of mfcc coefficients. Column zero is empty.</param>
            <param name="timeId">index for the required timeframe.</param>
            <param name="includeDelta">Whether or not to add delta features.</param>
            <param name="includeDoubleDelta">Whether or not to add double-delta features.</param>
            <returns>a mfcc feature vector for a single time-frame.</returns>
        </member>
        <member name="T:AudioAnalysisTools.DSP.NoiseProfile">
            <summary>
            contains info re noise profile of an entire spectrogram.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseProfile.CalculateModalNoiseProfile(System.Double[0:,0:],System.Double)">
            <summary>
            (1) MODAL METHOD
            Assumes the passed matrix is a spectrogram. i.e. rows=frames, cols=freq bins.
            Returns the noise profile over freq bins. i.e. one noise value per freq bin.
            </summary>
            <param name="matrix">the spectrogram with origin top-left.</param>
            <param name="sdCount">number of standard deviations.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseProfile.CalculateMeanNoiseProfile(System.Double[0:,0:])">
            <summary>
            (1) MEAN SUBTRACTION
            Assumes the passed matrix is a spectrogram. i.e. rows=frames, cols=freq bins.
            Returns the noise profile over freq bins. i.e. one noise value per freq bin.
            Note that NoiseThresholds array is identical to NoiseMedian array.
            </summary>
            <param name="matrix">the spectrogram with origin top-left.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseProfile.CalculateMedianNoiseProfile(System.Double[0:,0:])">
            <summary>
            (1) MEDIAN SUBTRACTION
            Assumes the passed matrix is a spectrogram. i.e. rows=frames, cols=freq bins.
            Returns the noise profile over freq bins. i.e. one noise value per freq bin.
            Note that NoiseThresholds array is identical to NoiseMedian array.
            </summary>
            <param name="matrix">the spectrogram with origin top-left.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseProfile.CalculateBackgroundNoise(System.Double[0:,0:])">
            <summary>
            (1) MODAL METHOD
            Calculates the modal background noise for each freqeuncy bin.
            Return the smoothed modal profile.
            Set the default zero value for number of SDs.
            </summary>
            <param name="spectrogram">Assumes the passed spectrogram is oriented as: rows=frames, cols=freq bins.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseProfile.GetNoiseProfile_fromLowestPercentileFrames(System.Double[0:,0:],System.Int32)">
            <summary>
            (2) LOWEST PERCENTILE FRAMES METHOD
            Assumes the passed matrix is a spectrogram and that all values in the data matrix are positive.
            Returns the noise profile over freq bins. i.e. one noise value per freq bin.
            First calculate the frame averages, sort in ascending order and accumulate the first N% of frames.
            WARNING: This method should NOT be used for short recordings i.e LT approx 10-15 seconds long.
            </summary>
            <param name="matrix">the spectrogram whose rows=frames, cols=freq bins.</param>
            <param name="lowPercentile">The percent of lowest energy frames to be included in calculation of the noise profile.</param>
            <returns>Returns a noise profile consisting of averaged values from the selected X% of low energy frames.</returns>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseProfile.GetNoiseProfile_BinWiseFromLowestPercentileCells(System.Double[0:,0:],System.Int32)">
            <summary>
            (3) BIN-WISE LOWEST PERCENTILE CELLS METHOD
            Assumes the passed matrix is a spectrogram.
            Returns the noise profile over freq bins. i.e. one noise value per freq bin.
            IMPORTANT: This is the preferred method to estiamte a noise profile for short recordings i.e LT approx 10-15 seconds long.
            </summary>
            <param name="matrix">the spectrogram whose rows=frames, cols=freq bins.</param>
            <param name="lowPercentile">The percent of lowest energy frames to be included in calculation of the noise profile.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseProfile.CalculateModalNoiseUsingStartFrames(System.Double[0:,0:],System.Int32)">
            <summary>
            (4) FIRST N FRAMES
            IMPORTANT: this method assumes that the first N frames (N=frameCount) DO NOT contain signal.
            </summary>
            <param name="matrix">the spectrogram rotated with origin is top-left.</param>
            <param name="firstNFramesCount">the first N rows of the spectrogram.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseRemovalModal.ModalNoiseRemovalAndGetSonograms(System.Double[0:,0:],System.TimeSpan,System.TimeSpan,System.Int32,System.Int32)">
            <summary>
            This method produces four spectrograms using four different values of neighbour hood decibel threshold.
            It can be used for test purposes.
            </summary>
            <param name="deciBelSpectrogram">the noisy decibel spectrogram.</param>
            <param name="xAxisInterval">x-axis tic interval.</param>
            <param name="stepDuration">the x-axis times scale.</param>
            <param name="nyquist">max freq value.</param>
            <param name="hzInterval">y-axis frequency scale.</param>
            <returns>Image containing four sepctrograms.</returns>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseRemovalModal.CalculateNoiseUsingLamelsAlgorithm(System.Double[],System.Double@,System.Double@,System.Double@,System.Double@)">
             <summary>
             Implements the "Adaptive Level Equalisatsion" algorithm of Lamel et al, 1981 - with modifications for our signals.
             Units are assumed to be decibels.
             Returns the min and max frame dB AND the estimate MODAL or BACKGROUND noise for the signal array
             IF This modal noise is subtracted from each frame dB, the effect is to set set average background noise level = 0 dB.
             The algorithm is described in Lamel et al, 1981.
             USED TO SEGMENT A RECORDING INTO SILENCE AND VOCALISATION
             NOTE: noiseThreshold is passed as decibels. Original Lamel algorithm ONLY SEARCHES in range min to 10dB above min.
            
             This method debugged on 7 Aug 2018 using following command line arguments:
             audio2csv Y:\TheNatureConservency\Myanmar\20180517\site112\2018_02_14_Bar5\20180214_Bar5\20180214_101121_Bar5.wav Towsey.Acoustic.yml C:\Temp... -m True.
             </summary>
             <param name="dBarray">signal in decibel values.</param>
             <param name="minDb">minimum value in the passed array of decibel values.</param>
             <param name="maxDb">maximum value in the passed array of decibel values.</param>
             <param name="modeNoise">modal or background noise in decibels.</param>
             <param name="sdNoise">estimated sd of the noies - assuming noise to be guassian.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseRemovalModal.CalculateBackgroundNoise(System.Double[])">
            <summary>
            Calls the algorithm of Lamel et al, 1981.
            IMPORTANT: The passed signal envelope values are absolute amplitude values derived from the framed waveform.
            These are converted to decibels before passing to the LAMEL method.
            NOTE: The returned background noise value ignores the SD part of the Gaussian noise model.
            </summary>
            <param name="signalEnvelope">Amplitude values.</param>
            <returns>Modal noise value in decibels.</returns>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseRemoval_Briggs.NoiseReductionByDivisionAndSqrRoot(System.Double[0:,0:],System.Int32)">
             <summary>
             Assumes the passed matrix is a spectrogram. i.e. rows=frames, cols=freq bins.
             WARNING: This method should NOT be used for short recordings (i.e LT approx 10-15 seconds long)
             because it obtains a background noise profile from the passed percentile of lowest energy frames.
            
             Same method as above except take square root of the cell energy divided by the noise.
             Taking the square root has the effect of reducing image contrast.
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseRemoval_Briggs.NoiseReductionByLowestPercentileSubtraction(System.Double[0:,0:],System.Int32)">
            <summary>
            Assumes the passed matrix is a spectrogram. i.e. rows=frames, cols=freq bins,
            and that all values in data matrix are positive.
            WARNING: This method should NOT be used for short recordings (i.e LT approx 10-15 seconds long)
            Obtains a background noise profile from the passed percentile of lowest energy frames,
            Then subtracts the noise profile value from every cell.
            This method was adapted from a paper by Briggs.
            </summary>
            <param name="matrix">the passed amplitude or energy spectrogram.</param>
            <param name="percentileThreshold">Must be an integer percent.</param>
            <returns>Spectrogram data matrix with noise subtracted.</returns>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseRemoval_Briggs.NoiseReductionByLcn(System.Double[0:,0:],System.Int32,System.Int32,System.Double)">
             <summary>
             Assumes the passed matrix is a spectrogram. i.e. rows=frames, cols=freq bins.
             First obtains background noise profile calculated from lowest 20% of cells for each freq bin independently.
             Loop over freq bins (columns) - subtract noise and divide by LCN (Local Contrast Normalisation.
            
             The LCN denominator = (contrastLevelConstant + Sqrt(localVariance[y])
             Note that sqrt of variance = std dev.
             A low contrastLevel = 0.1 give more grey image.
             A high contrastLevel = 1.0 give mostly white high contrast image.
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseRemoval_Briggs.NoiseReductionByLcn(System.Double[0:,0:],System.Int32,System.Double)">
            <summary>
            THis method similar to the above BUT:
            1: it does not do initial subtraction of lowest percentile noise.
            2: it calculates local variance from local matrix andnot local frequency bin.
            Assumes the passed matrix is a spectrogram. i.e. rows=frames, cols=freq bins.
            Currently, the denominator = (contrastLevel + Math.Sqrt(localVariance[y])
            A low contrastLevel = 0.1 give more grey image.
            A high contrastLevel = 1.0 give mostly white high contrast image.
            I tried various other normalisation equations as can be seen below.
            NOTE: Taking square-root of top line results in too much background.
            The algorithm is not overly sensitive to the neighbourhood size.
            </summary>
            <param name="neighbourhood">suitable vaues are odd numbers 9 - 59.</param>
            <param name="contrastLevel">Suitable values are 0.1 to 1.0.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseRemoval_Briggs.CalculateLocalVariance1(System.Double[],System.Int32)">
            <summary>
            This was written for the local contrast normalisation (LCN) of amplitude spectrograms.
            However the contrast is calculated wrt the local part of frequency bin or column.
            Plugging up ends of the returned array as done here is a hack but it does not really matter.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseRemoval_Briggs.CalculateLocalVariance2(System.Double[0:,0:],System.Int32,System.Int32)">
            <summary>
            THis method is equivalent to the above method - CalculateLocalVariance1(),
            except that the local variance is derived from a local matrix rather than the local frequency bin.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.NoiseRemoval_Briggs.NoiseReductionByDivision(System.Double[0:,0:],System.Int32)">
            <summary>
            Assumes the passed matrix is a spectrogram. i.e. rows=frames, cols=freq bins.
            WARNING: This method should NOT be used for short recordings (i.e LT approx 10-15 seconds long)
            Obtains a background noise profile from the passed percentile of lowest energy frames,
            Then divide cell energy by the profile value.
            This method was adapted from a paper by Briggs.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.OctaveFreqScale.GetStandardOctaveScale(AudioAnalysisTools.DSP.FrequencyScale)">
            <summary>
            Calculates the parameters for a standard mixed linear-octave frequency scale.
            IMPORTANT: It assumes that the nyquist, frame size and linear bound have already been set to valid values.
            What makes this scale "standard" is that the number of octaveDivsions/tones (T) is set equal to number of linear bins.
            The remainder of the spectrum will be reduced over T-tone octaves.
            Sensible values for linearUpperBound are 125, 250, 500, 1000.
            Note that when linearUpperBound = 500, the resulting spectrogram is very similar to the default MelScale.
            When nyquist=11025 and frameSize = 512, the default MelScale has 64 frequency bins and Linear500-octave has 66 frequency bands.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.OctaveFreqScale.ConvertAmplitudeSpectrogramToFreqScaledDecibels(System.Double[0:,0:],System.Double,System.Int32,System.Double,AudioAnalysisTools.DSP.FrequencyScale)">
            <summary>
            This method is octave frequency scale equivalent of MFCCStuff.DecibelSpectra(dspOutput.AmplitudeSpectrogram, dspOutput.WindowPower, sampleRate, epsilon)
            The MFCCStuff method is the proper way to convert amplitude spectrogram to decibels.
            It converts an amplitude spectrogram to a power spectrogram having specified frequency scale.
            It transforms the amplitude spectrogram in the following steps:
            (1) It removes the DC row or bin 0 iff there is odd number of spectrogram bins. ASSUMPTION: Bin count should be power of 2 from FFT.
            (2) Then reduce the linear scale to an octave scale depending on the sr and required number of bins or filters.
            (3) It converts spectral amplitudes to power, normalising for window power and sample rate.
                The window contributes power to the signal which must subsequently be removed from the spectral power. Calculate power per sample.
                See notes in the MFCCStuff.DecibelSpectra for further exp[lanaitons. These normalisations were adapted from MatLab MFCC code.
            (4) It converts the power spectrogram to decibels.
            </summary>
            <param name="amplitudeM">The amplitude spectrogram.</param>
            <param name="windowPower">FFT window power comes from DSP_Frames.WindowPower.</param>
            <param name="sampleRate">of the original signal.</param>
            <param name="epsilon">dependson bit-rate of the original signal.</param>
            <param name="freqScale">In this case an octave frquency scale.</param>
            <returns>The decibel spectrogram.</returns>
        </member>
        <member name="M:AudioAnalysisTools.DSP.OctaveFreqScale.ConvertLinearSpectrogramToOctaveFreqScale(System.Double[0:,0:],AudioAnalysisTools.DSP.FrequencyScale)">
            <summary>
            Converts a spectrogram having linear freq scale to one having an Octave freq scale.
            TODO: SHOULD DEVELOP A SEPARATE UNIT TEST for this method.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.OctaveFreqScale.ConvertAmplitudeToPowerSpectrogram(System.Double[0:,0:],System.Double,System.Int32)">
            <summary>
            Converts Amplitude Spectrogram to Power Spectrogram.
            Square the amplitude values to get power.
            Power values must be adjusted for the power in the FFT window and also for the sample rate.
            Must divide by the window power to remove its contribution to amplitude values.
            Must divide by sample rate to get average power per signal sample.
            NOTE: Multiply by 2 to accomodate two spectral components, ie positive and neg freq.
                  BUT the last nyquist bin does not require a factor of two.
                  However this method is called only by octave reduced frequency scales where the nyquist bin is just one of several.
            </summary>
            <param name="amplitudeM">The frequency scaled amplitude spectrogram.</param>
            <param name="windowPower">Power of the FFT window.</param>
            <param name="sampleRate">The sample rate of the original recording.</param>
            <returns>The Power Spectrogram as matrix. Each spectrum is a matrix row.</returns>
        </member>
        <member name="M:AudioAnalysisTools.DSP.OctaveFreqScale.LinearToSplitLinearOctaveScale(System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Returns a matrix that is used to transform a spectrum having linear Hz scale into a spectrum having an octave freq scale.
            The returned matrix is size N x 2, where N = the length of the output spectrum.
            In fact the op spectrum has a split Herz scale - bottom part linear, top part octave scaled.
            Column 0 of the returned matrix contains the index into linear spectrum.
            Column 1 of the returned matrix contains the Hertz value of the corresponding index into the linear spectrum.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.OctaveFreqScale.GetDataReductionScale(AudioAnalysisTools.DSP.FrequencyScale)">
            <summary>
            This method assumes that the linear spectrum is derived from a 512 frame with sr = 22050.
            It is a split linear-octave scale.
            The linear part is from 0-2 kHz with reduction by factor of 8.
            The octave part is obtained by setting octave divisions or tone count = 5.
            </summary>
            <returns>a frequency scale for spectral-data reduction purposes.</returns>
        </member>
        <member name="M:AudioAnalysisTools.DSP.OctaveFreqScale.LinearToFullOctaveScale(System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Returns the index bounds for a full octave scale - from lowest freq set by user to top freq.
            </summary>
            <param name="sr">Sample rate of the source recording.</param>
            <param name="frameSize">Frame size of the source recording.</param>
            <param name="finalBinCount">Final Bin Count.</param>
            <param name="lowerFreqBound">Lower bound of the octave part of the final scale.</param>
            <param name="upperFreqBound">Upper bound of the octave scale, most likely the Nyquist.</param>
            <param name="octaveDivisions">Number of tones/divisions per octave.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.OctaveFreqScale.GetFractionalOctaveBands(System.Double,System.Int32)">
            <summary>
            Returns an array of tones in one octave.
            The units are frequency in Hertz.
            NOTE: The octave is divided geometrically.
            </summary>
            <param name="lowerBound">The lower frquency bound of the octave.</param>
            <param name="subbandCount">The number of tones or frequency bins in the octave.</param>
            <returns>The frequency of each tone in the octave.</returns>
        </member>
        <member name="T:AudioAnalysisTools.DSP.PatchSampling.SamplingMethod">
            <summary>
            sample a set of patches ("sequential" or "random" or "overlapped random") from a spectrogram
            in "sequential" mode, it generates non-overlapping patches from the whole input matrix, and
            in this case the "numOfPatches" can be simply set to zero.
            However, in "random" mode, the method requires an input for the "numOfPatches" parameter.
            </summary>
            <summary>
            The sampling method.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.DSP.PatchSampling.SamplingMethod.Sequential">
            <summary>
            Sequential patches.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.DSP.PatchSampling.SamplingMethod.Random">
            <summary>
            Random Patches.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.DSP.PatchSampling.SamplingMethod.OverlappedRandom">
            <summary>
            Overlapping Random Patches.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PatchSampling.ConvertPatches(System.Double[0:,0:],System.Int32,System.Int32,System.Int32)">
            <summary>
            converts a set of patches to a matrix of original size after applying pca.
            the assumption here is that the input matrix is a sequential non-overlapping patches.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PatchSampling.ConcatenateGridOfPatches(System.Collections.Generic.List{System.Double[0:,0:]},System.Int32,System.Int32,System.Int32)">
            <summary>
            construct the original matrix from a list of sequential patches
            all vectors in list are of the same length.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PatchSampling.GetFreqBandMatrices(System.Double[0:,0:],System.Int32)">
            <summary>
            converts a spectrogram matrix to submatrices by dividing the column of input matrix to
            different freq bands with equal size. Output submatrices have same number of rows and same number
            of columns. numberOfBands as an input parameter indicates how many output bands are needed.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PatchSampling.GetArbitraryFreqBandMatrix(System.Double[0:,0:],System.Int32,System.Int32)">
            <summary>
            outputs a matrix with arbitrary minimum and maximum frequency bins.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PatchSampling.ConcatFreqBandMatrices(System.Collections.Generic.List{System.Double[0:,0:]})">
            <summary>
            concatenate submatrices column-wise into one matrix, i.e., the number of rows for the output matrix
            is equal to the number of rows of each of the frequency band matrices.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PatchSampling.ListOf2DArrayToOne2DArray(System.Collections.Generic.List{System.Double[0:,0:]})">
            <summary>
            convert a list of patch matrices to one matrix by row
            patch matrices can have different row numbers but must have the same column number.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PatchSampling.AddRow(System.Double[0:,0:])">
            <summary>
            Adding a row of zero/one to 2D array.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PatchSampling.GetSequentialPatches(System.Double[0:,0:],System.Int32,System.Int32)">
            <summary>
            Generate non-overlapping sequential patches from a <paramref name="matrix"/>.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PatchSampling.GetRandomPatches(System.Double[0:,0:],System.Int32,System.Int32,System.Int32)">
            <summary>
            Generate non-overlapping random patches from a matrix.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PatchSampling.GetOverlappedRandomPatches(System.Double[0:,0:],System.Int32,System.Int32,System.Int32)">
            <summary>
            Generate overlapped random patches from a matrix.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PatchSampling.GetSubsegmentsSamples(AudioAnalysisTools.WavTools.AudioRecording,System.Double,System.Double)">
            <summary>
            cut audio to subsegments of desired length.
            return list of subsegments.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.DSP.PcaWhitening.Output">
            <summary>
            Outputting the Projection Matrix, whitened matrix, eigen vectors, and the number of PCA components
            that is used to to transform the data into the new feature subspace.
            in Accord.net, this matrix is called "ComponentVectors", which its columns contain the
            principle components, known as Eigenvectors.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PcaWhitening.GetProjectionMatrix(System.Double[0:,0:],System.Int32)">
            <summary>
            Build the Projection Matrix
            To do so, we need eigenVectors and the number of columns of the projected data
            which is the number of outputs (principle components) used to transform the data.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PcaWhitening.Revert(System.Double[0:,0:],System.Double[0:,0:],System.Int32)">
            <summary>
            revert a set of projected data into its original space
            the output of the "Revert(Double[][])" method in Accord did not make sense.
            however, we use its API to do so.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PcaWhitening.ReconstructSpectrogram(System.Double[0:,0:],System.Double[0:,0:],System.Double[0:,0:],System.Int32)">
            <summary>
            reconstruct the spectrogram using sequential patches and the projection matrix.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PcaWhitening.NoiseReduction(System.Double[0:,0:])">
            <summary>
            10-percentile Noise Reduction.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PowerSpectralDensity.GetEnergyValues(System.Double[0:,0:])">
            <summary>
            Square the FFT coefficients >> this gives an energy spectrogram.
            MatrixTools.SquareValues is doing the same!.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.PowerSpectralDensity.GetPowerSpectrum(System.Double[0:,0:])">
            <summary>
            Take average of the energy values in each frequency bin to obtain power spectrum or PSD.
            SpectrogramTools.CalculateAvgSpectrumFromEnergySpectrogram is doing the same!.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.DSP.SNR.MinimumDbBoundForZeroSignal">
            <summary>
            Reference dB levels for a zero signal
            Used as minimum bound when normalising dB values.
            This value was based on the observation of an actual zero signal on an SM2.
            However, SM4 has a lower noise level. Consequently this value lowered to -100 on 7th August 2018.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.DSP.SNR.MinimumDbBoundForEnvironmentalNoise">
            <summary>
            Reference dB levels for recording of very silent environment
            Used as minimum bound when normalising dB values.
            This value was based on actual recording of cold winter morning (Gympie) using an SM2.
            However, SM4 has a lower noise level. Consequently this value lowered to -90 on 7th August 2018.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.DSP.SNR.MinLogEnergyReference">
            <summary>
            Reference logEnergies for signal segmentation, energy normalisation etc
            MinLogEnergyReference was changed from -6.0 to -8.0 on 6th August 2018 to accommodate signals with extended zero values.
            Typical noise value using Jason Wimmer original handheld recorders was = -4.5 = -45dB
            Typical noise value for quiet recordings with SM4 = -8.0 or -9.0, i.e. -80 to -90 dB.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.#ctor(System.Double[],System.Int32[0:,0:])">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.DSP.SNR"/> class.
            CONSTRUCTOR
            This constructor is called once from DSP_Frames.ExtractEnvelopeAndAmplSpectrogram().
            </summary>
            <param name="signal">signal. </param>
            <param name="frameIDs">the start and end index of every frame.</param>
        </member>
        <member name="P:AudioAnalysisTools.DSP.SNR.FrameDecibels">
            <summary>
            Gets or sets the FrameDecibels array. Calculate as dB[i] = 10 x log-energy of frame[i].
            Appears only to be used to determine the fraction of high energy frames.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.SNR.Snr">
            <summary>
            Gets or sets Snr.
            SNR = max_dB - Q
            that is, max decibels minus the modal noise
            This is notation used by Lamel et al.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.SubtractBackgroundNoise_dB">
            <summary>
            subtract background noise to produce a decibels array in which zero dB = modal noise
            DOES NOT TRUNCATE BELOW ZERO VALUES.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.NormaliseDecibelArray_ZeroOne(System.Double[],System.Double)">
            <summary>
            NormaliseMatrixValues the power values using the passed reference decibel level.
            NOTE: This method assumes that the energy values are in decibels and that they have been scaled
            so that the modal noise value = 0 dB. Simply truncate all values below this to zero dB.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.RmsNormalization(System.Double[0:,0:])">
            <summary>
            Root Mean Square (RMS) Normalization
            Matrix is assumed to be a spectrogram
            Divides the spectrogram values by the RMS in order to adjust for varying levels of signal strength.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.CalculateLogEnergyOfsignalFrames(System.Double[],System.Int32[0:,0:])">
            <summary>
            Returns the log(energy) in each frame of the signal.
            The energy of a frame is the log of the summed energy of all the samples in the frame.
            Normally, if the passed frames are FFT spectra, then would multiply by 2 because spectra are symmetrical about Nyquist.
            BUT this method returns the AVERAGE sample energy, which therefore normalises for frame length / sample number.
            <para>
            Energy normalisation formula taken from Lecture Notes of Prof. Bryan Pellom
            Automatic Speech Recognition: From Theory to Practice.
            http://www.cis.hut.fi/Opinnot/T-61.184/ September 27th 2004.
            </para>
            Calculate normalised energy of frame as  energy[i] = logEnergy - maxLogEnergy;
            This is same as log10(logEnergy / maxLogEnergy) ie normalised to a fixed maximum energy value.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.CalculateLogEnergyOfsignalFrames(System.Double[0:,0:])">
            <summary>
            NOTE: This method is identical to the above one, except that the actual frames are passed
            rather than the starts and ends of the frames.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.ReduceFreqBinsInSpectrogram(System.Double[0:,0:],System.Int32)">
            <summary>
            returns a spectrogram with reduced number of frequency bins.
            </summary>
            <param name="inSpectro">input spectrogram.</param>
            <param name="subbandCount">numbre of req bands in output spectrogram.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.SubbandIntensity_NoiseReduced(System.Double[0:,0:],System.Int32,System.Int32,System.Int32,System.Double,System.Double)">
            <param name="sonogram">sonogram of signal - values in dB.</param>
            <param name="minHz">min of freq band to sample.</param>
            <param name="maxHz">max of freq band to sample.</param>
            <param name="nyquist">signal nyquist - used to caluclate hz per bin.</param>
            <param name="smoothDuration">window width (in seconds) to smooth sig intenisty.</param>
            <param name="framesPerSec">time scale of the sonogram.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.CalculateFreqBandAvIntensity(System.Double[0:,0:],System.Int32,System.Int32,System.Int32)">
            <summary>
            Calculates the mean intensity in a freq band defined by its min and max freq.
            THis method averages dB log values incorrectly but it is faster than doing many log conversions.
            This method is used to find acoustic events and is accurate enough for the purpose.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.CalculateFreqBandAvIntensityMinusBufferIntensity(System.Double[0:,0:],System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Calculates the average intensity in a freq band having min and max freq,
            AND then subtracts average intensity in the side/buffer bands, below and above.
            THis method adds dB log values incorrectly but it is faster than doing many log conversions.
            This method is used to find acoustic events and is accurate enough for the purpose.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.CalculateWhistleIntensity(System.Double[0:,0:],System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Calculates the average intensity in a freq band having min and max freq,
            AND then subtracts average intensity in the side/buffer bands, below and above.
            THis method adds dB log values incorrectly but it is faster than doing many log conversions.
            This method is used to find acoustic events and is accurate enough for the purpose.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.CalculateSnrInFreqBand(System.Double[0:,0:],System.Int32,System.Int32,System.Int32,System.Int32,System.Double)">
            <summary>
            The calculation of SNR in this method assumes that background noise has already been removed.
            That is, the maximum value is with respect to zero.
            SNR should be calculated based on power values in decibel units.
                i.e. SNR = 10log(PowerOfSignal / PowerOfNoise);
                or   SNR = 20log(Signal amplitude) - 20log(Noise amplitude);
                If the passed sonogram data is amplitude or energy values (rather than decibel values) then the returned SNR value needs to be appropriately corrected.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.CalculateSnrInFreqBand(AudioAnalysisTools.StandardSpectrograms.BaseSonogram,System.TimeSpan,System.TimeSpan,System.Int32,System.Int32,System.Double)">
            <summary>
            Calculates the matrix row/column bounds given the real world bounds.
            Axis scales are obtained form the passed sonogram instance.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.Calculate_SNR_ShortRecording(System.IO.FileInfo,System.Collections.Generic.Dictionary{System.String,System.String},System.TimeSpan,System.TimeSpan,System.Int32,System.Int32,System.Double)">
            <summary>
            This method written 18-09-2014 to process Xueyan's query recordings.
            Calculate the SNR statistics for each recording and then write info back to csv file.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.SubtractBackgroundNoiseFromWaveform_dB(System.Double[],System.Double)">
             <summary>
             Calls method to implement the "Adaptive Level Equalisatsion" algorithm of (Lamel et al, 1981)
             It has the effect of setting background noise level to 0 dB.
             Passed signal array MUST be in deciBels.
             ASSUMES an ADDITIVE MODEL with GAUSSIAN NOISE.
             Calculates the average and standard deviation of the noise and then calculates a noise threshold.
             Then subtracts threshold noise from the signal - so now zero dB = threshold noise
             Sets default values for min dB value and the noise threshold. 10 dB is a default used by Lamel et al.
             RETURNS: 1) noise reduced decibel array; 2) Q - the modal BG level; 3) min value 4) max value; 5) snr; and 6) SD of the noise.
             </summary>
            
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.SubtractBackgroundNoiseFromSignal(System.Double[],System.Double)">
            <summary>
            Calculates and subtracts the background noise value from an array of double.
            Used for calculating and removing the background noise and setting baseline = zero.
            Implements a MODIFIED version of Lamel et al. They only search in range 10dB above min dB whereas
            this method sets upper limit to 66% of range of intensity values.
            ASSUMES ADDITIVE MODEL with GAUSSIAN NOISE.
            Values below zero set equal to zero.
            This method can be called for any array of signal values but is PRESUMED TO BE A WAVEFORM or FREQ BIN OF HISTOGRAM.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.GetModeAndOneStandardDeviation(System.Double[],System.Int32@,System.Int32@)">
            <summary>
            This is the important part of Lamel's algorithm.
            It assumes an additive noise model. That is, it assumes that the passed histogram represents the distribution of values
            in a waveform consisting of a signal plus added Gaussian noise.
            This method estimates the mean and SD of the noise.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.KeyToNoiseReductionType(System.String)">
            <summary>
            Converts a string interpreted as a key to a NoiseReduction Type.
            </summary>
            <param name="key">The string to convert.</param>
            <returns>A NoiseReductionType enumeration.</returns>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.NoiseReduce(System.Double[0:,0:],AudioAnalysisTools.DSP.NoiseReductionType,System.Double)">
            <summary>
            Removes noise from a spectrogram. Choice of methods.
            Make sure that do MelScale reduction BEFORE applying noise filter.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.NoiseReduce_Standard(System.Double[0:,0:])">
            <summary>
            expects a spectrogram in dB values
            IMPORTANT: Mel scale conversion should be done before noise reduction
            Uses default values for severity of noise reduction and neighbourhood threshold.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.NoiseReduce_Standard(System.Double[0:,0:],System.Double[],System.Double)">
            <summary>
            expects a spectrogram in dB values.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.NoiseReduce_FixedRange(System.Double[0:,0:],System.Double,System.Double)">
            <summary>
            IMPORTANT: Mel scale conversion should be done before noise reduction.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.NoiseReduce_Mean(System.Double[0:,0:],System.Double)">
            <summary>
            The passed matrix is the decibel spectrogram.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.NoiseReduce_Median(System.Double[0:,0:],System.Double)">
            <summary>
            The passed matrix is the decibel spectrogram.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.SubtractAndTruncateNoiseProfile(System.Double[0:,0:],System.Double[],System.Double)">
            <summary>
            Subtracts the supplied noise profile from spectorgram AND sets values less than backgroundThreshold to ZERO.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.TruncateBgNoiseFromSpectrogram(System.Double[0:,0:],System.Double[])">
            <summary>
            Subtracts the supplied noise profile from spectorgram AND sets negative values to ZERO.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.SubtractBgNoiseFromSpectrogram(System.Double[0:,0:],System.Double[])">
            <summary>
            Subtracts the supplied modal noise value for each freq bin BUT DOES NOT set negative values to zero.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.SetDynamicRange(System.Double[0:,0:],System.Double,System.Double)">
            <summary>
            sets the dynamic range in dB for a sonogram.
            All intensity values are shifted so that the max intensity value = maxDB parameter.
            All values which fall below the minDB parameter are then set = to minDB.
            </summary>
            <param name="m">The spectral sonogram passes as matrix of doubles.</param>
            <param name="minDb">minimum decibel value.</param>
            <param name="maxDb">maximum decibel value.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.SetLocalBounds(System.Double[0:,0:],System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            SetLocalBounds.
            </summary>
            <param name="m">The spectral sonogram passes as matrix of doubles.</param>
            <param name="minPercentileBound">minimum decibel value.</param>
            <param name="maxPercentileBound">maximum decibel value.</param>
            <param name="temporalNh">buffer in temporal dimension.</param>
            <param name="freqBinNh">buffer in frequency dimension.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.SNR.RemoveNeighbourhoodBackgroundNoise(System.Double[0:,0:],System.Double)">
            <summary>
            This method sets a sonogram pixel value = minimum value in sonogram if average pixel value in its neighbourhood is less than min+threshold.
            Typically would expect min value in sonogram = zero.
            </summary>
            <param name="matrix">the sonogram.</param>
            <param name="nhThreshold">user defined threshold. Typically in range 2-4 dB.</param>
        </member>
        <member name="T:AudioAnalysisTools.DSP.SNR.SnrStatistics">
            <summary>
            used to store info about the SNR in a signal using db units.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.SNR.SnrStatistics.ExtractDuration">
            <summary>
            Gets or sets duration of the event under consideration.
            It may be shorter or longer than the actual recording we have.
            If longer then the event, then duration := recording duration.
            Rest was truncated in original data extraction.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.SNR.SnrStatistics.Threshold">
            <summary>
            Gets or sets decibel threshold used to calculate cover and average SNR.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.SNR.SnrStatistics.Snr">
            <summary>
            Gets or sets maximum dB value in the signal or spectrogram - relative to zero dB background.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.SNR.SnrStatistics.FractionOfFramesExceedingThreshold">
            <summary>
            Gets or sets fraction of frames in the call where the average energy exceeds the user specified threshold.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.SNR.SnrStatistics.FractionOfFramesExceedingOneThirdSnr">
            <summary>
            Gets or sets fraction of frames in the call where the average energy exceeds half the calculated SNR.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.DSP.WavInfo">
            <summary>
            Wav Info.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.WavInfo.Channels">
            <summary>
            Gets or sets Number of channels.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.WavInfo.SampleRate">
            <summary>
            Gets or sets Sample rate of audio.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.WavInfo.BitsPerSample">
            <summary>
            Gets or sets Bits per sample.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.WavInfo.BytesPerSample">
            <summary>
            Gets or sets bytes Per Sample / Block Align.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.WavInfo.CompressionCode">
            <summary>
            Gets or sets.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.WavInfo.BytesPerSecond">
            <summary>
            Gets or sets.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.WavInfo.Samples">
            <summary>
            Gets or sets.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.WavInfo.SamplesSplit">
            <summary>
            Gets or sets.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.WavInfo.Duration">
            <summary>
            Gets or sets.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.DSP.WavInfo.Epsilon">
            <summary>
            Gets.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.WavInfo.#ctor(System.Double,System.Double,System.Double,System.TimeSpan,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.DSP.WavInfo"/> class.
            Create a sine wave.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.WavInfo.#ctor(System.Double[],System.Double,System.Double,System.TimeSpan,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.DSP.WavInfo"/> class.
            Create a Sine wav with multiple frequencies.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.WavInfo.#ctor(System.Double[],System.Int16,System.Int16,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.DSP.WavInfo"/> class.
            Create a wav info using data, channels, bits per sample and sample rate.
            </summary>
            <param name="rawData">Raw samples.</param>
            <param name="channels">Number of channels.</param>
            <param name="bitsPerSample">Bits per sample.</param>
            <param name="sampleRate">Sample rate.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.WavInfo.SubSample(AudioAnalysisTools.DSP.WavInfo,System.Int32)">
            <summary>
            Subsamples audio.
            </summary>
            <param name="interval">
            Keeps every <paramref name="interval"/> sample.
            </param>
            <param name="wavInfo">Wav info.</param>
        </member>
        <member name="M:AudioAnalysisTools.DSP.WavInfo.CalculateMaximumAmplitude(AudioAnalysisTools.DSP.WavInfo)">
             <summary>
            
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.DSP.WavWriter.WriteWavFileViaFfmpeg(System.IO.FileInfo,Acoustics.Tools.Wav.WavReader)">
            <summary>
            This is a _slow_ but reliable way to write a Wav file by using ffmpeg to do all
            the hard work.
            This method assumes all signal values are in [-1, 1].
            </summary>
            <remarks>This overload assumes a mono signal is supplied in a WavReader.</remarks>
        </member>
        <member name="M:AudioAnalysisTools.DSP.WavWriter.WriteWavFileViaFfmpeg(System.IO.FileInfo,System.Double[][],System.Int32,System.Int32,System.IO.DirectoryInfo)">
            <summary>
            This is a _slow_ but reliable way to write a Wav file by using ffmpeg to do all
            the hard work.
            This method assumes all signal values are in [-1, 1].
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.EventStatistics.EventStatistics">
            <summary>
            The data class that holds event statistics.
            </summary>
            <remarks>
            Note that EventBase already has getters/setters for:
            TimeSpan SegmentStartOffset
            double Score
            double EventStartSeconds
            double? MinHz
            ..
            NOTE: When MinHz equals null, this indicates that the event is broad band or has undefined frequency. The event is an instant.
                  When MinHz has a value, this indicates the event is a point in time/frequency space.
            </remarks>
        </member>
        <member name="P:AudioAnalysisTools.EventStatistics.EventStatistics.TemporalMaxRelative">
            <summary>
            Gets or sets the relative location of the temporal max within the acoustic event.
            E.g. if temporal max is half way through the event then TemporalMaxRelative = 0.5.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.EventStatistics.EventStatistics.HighFrequencyHertz">
            <summary>
            Gets or sets the top frequency bound of the acoustic event in Hertz
            Note: MinHz implemented in base class.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.EventStatistics.EventStatistics.SpectralCentroid">
            <summary>
            Gets or sets the SpectralCentroid.
            The SpectralCentroid is a measure of the "brightness" of a sound event, that is, the relative amount of high freq content compared to low freq content.
            Note that this SpectralCentroid is calculated from a weighted average of decibel values and NOT power values.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.EventStatistics.EventStatistics.TemporalEnergyDistribution">
            <summary>
            Gets or sets a measure of the distribution of energy over the time frames of the event.
            TemporalEnergyDistribution = 1 - Ht, where Ht is the temporal entropy calculated as for acoustic indices.
            Minimum value = 0.0, when energy is unifrom over all time frames.
            Maximum value = 1.0, when all the acoustic energy is concentrated in a single time frame.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.EventStatistics.EventStatistics.SpectralEnergyDistribution">
            <summary>
            Gets or sets a measure of the distribution of energy over the frequency bins of the event.
            SpectralEnergyDistribution = 1 - Hf, where Hf is the spectral entropy calculated as for acoustic indices.
            Minimum value = 0.0, when energy is unifrom over all frequency bins.
            Maximum value = 1.0, when all the acoustic energy is concentrated in a single frequency bin.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.EventStatistics.EventStatistics.SnrDecibels">
            <summary>
            Gets or sets the event's signal-to-noise ratio in decibels.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.EventStatistics.EventStatistics.Order">
            <summary>
            Gets or sets a metadata field used for sorting results. Not serialized in CSV output.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.EventStatistics.EventStatistics.CompareTo(AnalysisBase.ResultBases.ResultBase)">
            <inheritdoc />
            <summary>
            Sorts the results by their <see cref="P:AudioAnalysisTools.EventStatistics.EventStatistics.Order" /> property if it is available otherwise reverts to the base
            class comparison.
            </summary>
            <param name="other">An object to compare with this instance.</param>
            <returns>A value that indicates the relative order of the objects being compared.</returns>
        </member>
        <member name="M:AudioAnalysisTools.EventStatistics.EventStatisticsCalculate.AnalyzeAudioEvent(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.Interval{System.TimeSpan},Acoustics.Shared.Interval{System.Double},AudioAnalysisTools.EventStatistics.EventStatisticsConfiguration,System.TimeSpan)">
            <summary>
            Calculate summary statistics for supplied temporal and spectral targets.
            </summary>
            <remarks>
            The acoustic statistics calculated in this method are based on methods outlined in
            "Acoustic classification of multiple simultaneous bird species: A multi-instance multi-label approach",
            by Forrest Briggs, Balaji Lakshminarayanan, Lawrence Neal, Xiaoli Z.Fern, Raviv Raich, Sarah J.K.Hadley, Adam S. Hadley, Matthew G. Betts, et al.
            The Journal of the Acoustical Society of America v131, pp4640 (2012); doi: http://dx.doi.org/10.1121/1.4707424
            ..
            The Briggs feature are calculated from the column (freq bin) and row (frame) sums of the extracted spectrogram.
            1. Gini Index for frame and bin sums. A measure of dispersion. Problem with gini is that its value is dependent on the row or column count.
               We use entropy instead because value not dependent on row or column count because it is normalized.
            For the following meausres of k-central moments, the freq and time values are normalized in 0,1 to width of the event.
            2. freq-mean
            3. freq-variance
            4. freq-skew and kurtosis
            5. time-mean
            6. time-variance
            7. time-skew and kurtosis
            8. freq-max (normalized)
            9. time-max (normalized)
            10. Briggs et al also calculate a 16 value histogram of gradients for each event mask. We do not do that here although we could.
            ...
            NOTE 1: There are differences between our method of noise reduction and Briggs. Briggs does not convert to decibels
            and instead works with power values. He obtains a noise profile from the 20% of frames having the lowest energy sum.
            NOTE 2: To NormaliseMatrixValues for noise, they divide the actual energy by the noise value. This is equivalent to subtraction when working in decibels.
                    There are advantages and disadvantages to Briggs method versus ours. In our case, we hve to convert decibel values back to
                    energy values when calculating the statistics for the extracted acoustic event.
            NOTE 3: We do not calculate the higher central moments of the time/frequency profiles, i.e. skew and kurtosis.
                    Ony mean and standard deviation.
            ..
            NOTE 4: This method assumes that the passed event occurs totally within the passed recording,
            AND that the passed recording is of sufficient duration to obtain reliable BGN noise profile
            BUT not so long as to cause memory constipation.
            </remarks>
            <param name="recording">as type AudioRecording which contains the event.</param>
            <param name="temporalTarget">Both start and end bounds - relative to the supplied recording.</param>
            <param name="spectralTarget">both bottom and top bounds in Hertz.</param>
            <param name="config">parameters that determine the outcome of the analysis.</param>
            <param name="segmentStartOffset">How long since the start of the recording this event occurred.</param>
            <returns>an instance of EventStatistics.</returns>
        </member>
        <member name="M:AudioAnalysisTools.EventStatistics.EventStatisticsCalculate.CalculateSpectralCentroid(System.Double[])">
            <summary>
            Returns the id of the bin which contains the spectral centroid.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.Drawing.EventDrawer.DrawScoreIndicator(AudioAnalysisTools.Events.SpectralEvent,SixLabors.ImageSharp.Processing.IImageProcessingContext,AudioAnalysisTools.Events.Drawing.EventRenderingOptions)">
            <summary>
            Draws a "score" indicator on the left edge of an event.
            </summary>
            <param name="event">The event for which to draw the score indicator.</param>
            <param name="graphics">The image context to draw to.</param>
            <param name="options">The event rendering options to use.</param>
        </member>
        <member name="P:AudioAnalysisTools.Events.Drawing.EventRenderingOptions.Converters">
            <summary>
            Gets the unit coverters that will be used to convert
            events from real units to the target image's pixels.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Drawing.EventRenderingOptions.Border">
            <summary>
            Gets or sets the default border color for an event.
            </summary>
            <remarks>
            Defaults to Red, 1px.
            </remarks>
        </member>
        <member name="P:AudioAnalysisTools.Events.Drawing.EventRenderingOptions.Fill">
            <summary>
            Gets or sets the default fille color for an event.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Drawing.EventRenderingOptions.FillOptions">
            <summary>
            Gets or sets the graphics options that should be used with the
            <see cref="P:AudioAnalysisTools.Events.Drawing.EventRenderingOptions.Fill"/> brush for rendering the contents of an event.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Drawing.EventRenderingOptions.Score">
            <summary>
            Gets or sets the Pen used to draw a "score" indicator
            on the left edge of the event.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Drawing.EventRenderingOptions.Label">
            <summary>
            Gets or sets the color to use when rendering labels.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Drawing.EventRenderingOptions.TargetImageIsSpectral">
            <summary>
            Gets a value indicating whether the image to draw onto represents a spectrogram.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.Drawing.IDrawableEvent.Draw(SixLabors.ImageSharp.Processing.IImageProcessingContext,AudioAnalysisTools.Events.Drawing.EventRenderingOptions)">
            <summary>
            Draw this event on an image.
            </summary>
            <param name="graphics">The image prcessing context to draw an event on.</param>
            <param name="options">The options associated with this render request.</param>
        </member>
        <member name="P:AudioAnalysisTools.Events.EventCommon.Name">
            <summary>
            Gets or sets the name for this event.
            The name should be a friendly name.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.EventCommon.Profile">
            <summary>
            Gets or sets the profile used to create this event.
            If a profile was not used this value should be null.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.EventCommon.DecibelDetectionThreshold">
            <summary>
            Gets or sets the Decibel threshold at which the event was detected.
            This is used during post-processing to group events according to the threshold of their detection..
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.EventCommon.ComponentName">
            <summary>
            Gets the component name for this event.
            The component name should indicate what type of event this.
            E.g. a click, a whistle, a stacked harmonic, ...
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.EventCommon.Score">
            <summary>
            Gets or sets the event score.
            This is a score in absolute units as determined by context.
            <see cref="P:AudioAnalysisTools.Events.EventCommon.ScoreRange"/> determines the scale.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.EventCommon.ScoreRange">
            <summary>
            Gets or sets a min-max range of values for the score for this event.
            This is used to establish a score scale and thereby normalize the score.
            By default the minimum value of range = zero.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.EventCommon.ScoreNormalized">
            <summary>
            Gets a score in the range [0, 1].
            Up to user to determine a suitable range maximum.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.EventCommon.Draw(SixLabors.ImageSharp.Processing.IImageProcessingContext,AudioAnalysisTools.Events.Drawing.EventRenderingOptions)">
            <summary>
            Draw this event on an image.
            </summary>
            <param name="graphics">The image prcessing context to draw an event on.</param>
            <param name="options">The options associated with this render request.</param>
        </member>
        <member name="M:AudioAnalysisTools.Events.Types.CompositeEvent.EventsOverlapInFrequency(AudioAnalysisTools.Events.SpectralEvent,AudioAnalysisTools.Events.SpectralEvent)">
            <summary>
            Determines if two events overlap in frequency.
            </summary>
            <param name="event1">event one.</param>
            <param name="event2">event two.</param>
            <returns>true if events overlap.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Events.Types.CompositeEvent.EventsOverlapInTime(AudioAnalysisTools.Events.SpectralEvent,AudioAnalysisTools.Events.SpectralEvent)">
            <summary>
            Determines if two events overlap in time.
            </summary>
            <param name="event1">event one.</param>
            <param name="event2">event two.</param>
            <returns>true if events overlap.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Events.Types.CompositeEvent.CombineOverlappingEvents(System.Collections.Generic.List{AudioAnalysisTools.Events.EventCommon})">
            <summary>
            Combines overlapping events in the passed List of events and returns a reduced list.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.Types.CompositeEvent.CombineProximalEvents(System.Collections.Generic.List{AudioAnalysisTools.Events.SpectralEvent},System.TimeSpan,System.Int32)">
            <summary>
            Combines events that have similar bottom and top frequency bounds and whose start times are within the passed time range.
            NOTE: Proximal means (1) that the event starts are close to one another and (2) the events occupy a SIMILAR frequency band.
            NOTE: SIMILAR frequency band means the difference between two top Hertz values and the two low Hertz values are less than hertzDifference.
            NOTE: This method is used to combine events that are likely to be a syllable sequence within the same call.
            NOTE: Allow twice the tolerance for the upper Hertz difference because upper bounds tend to be more flexible. This is may need to be reversed if it proves to be unhelpful.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.Types.CompositeEvent.CombineStackedEvents(System.Collections.Generic.List{AudioAnalysisTools.Events.SpectralEvent},System.TimeSpan,System.Int32)">
            <summary>
            Combines events that are possible stacked harmonics or formants.
            Two conditions apply:
            (1) the events are coincident (have similar start and end times)
            (2) the events are stacked (their minima and maxima are within the passed frequency gap).
            NOTE: The difference between this method and CombineProximalEvents() is that stacked events should have similar start AND similar end times.
                  Having similar start and end times means the events are "stacked" (like pancakes!) in the spectrogram.
                  How closely stacked is determined by the hertzDifference argument. Typicaly, the formant spacing is not large, ~100-200Hz.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.Types.CompositeEvent.CombineVerticalEvents(System.Collections.Generic.List{AudioAnalysisTools.Events.SpectralEvent},System.TimeSpan,System.Int32)">
            <summary>
            Combines events that are possible stacked harmonics or formants.
            Two conditions apply:
            (1) the events are coincident (have similar start and end times)
            (2) the events are stacked (their minima and maxima are within the passed frequency gap).
            NOTE: The difference between this method and CombineProximalEvents() is that stacked events should have similar start AND similar end times.
                  Having similar start and end times means the events are "stacked" (like pancakes!) in the spectrogram.
                  How closely stacked is determined by the hertzDifference argument. Typicaly, the formant spacing is not large, ~100-200Hz.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.Types.CompositeEvent.CombineTwoEvents(AudioAnalysisTools.Events.SpectralEvent,AudioAnalysisTools.Events.SpectralEvent)">
            <summary>
            Merges two spectral events into one event.
            </summary>
            <param name="e1">first event.</param>
            <param name="e2">second event.</param>
            <returns>a composite event.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Events.Types.CompositeEvent.RemoveEnclosedEvents(System.Collections.Generic.List{AudioAnalysisTools.Events.EventCommon})">
            <summary>
            Removes from a list of events, those events that are enclosed by another event in the list.
            Returns a reduced list.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.Types.EventPostProcessing.PostProcessingOfSpectralEvents(System.Collections.Generic.List{AudioAnalysisTools.Events.EventCommon},AudioAnalysisTools.Events.Types.EventPostProcessing.PostProcessingConfig,AudioAnalysisTools.StandardSpectrograms.BaseSonogram,System.TimeSpan)">
            <summary>
            This method post-processes a set of acoustic events that have been detected by all profiles at the passed decibel threshold.
            </summary>
            <param name="newEvents">A list of events before post-processing.</param>
            <param name="postprocessingConfig">The config file to be used for post-processing.</param>
            <param name="decibelThreshold">Decibel threshold used to detect the passed events.</param>
            <param name="spectrogram">A spectrogram of the events.</param>
            <param name="segmentStartOffset">Time  in seconds since beginning of the recording.</param>
            <returns>A list of events after post-processing.</returns>
        </member>
        <member name="T:AudioAnalysisTools.Events.Types.EventPostProcessing.PostProcessingConfig">
            <summary>
            The properties in this config class are required to combine a sequence of similar syllables into a single event.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.PostProcessingConfig.CombineOverlappingEvents">
            <summary>
            Gets or sets a value indicating Whether or not to combine overlapping events.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.PostProcessingConfig.SyllableSequence">
            <summary>
            Gets or sets the parameters required to combine and filter syllable sequences.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.PostProcessingConfig.CombineVerticalSyllables">
            <summary>
            Gets or sets the parameters required to combine syllables vertically.
            </summary>
            <remarks>
            Useful for when you have two different profiles for detecting a lower and upper portion of an event.
            </remarks>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.PostProcessingConfig.Duration">
            <summary>
            Gets or sets the parameters required to filter events on their duration.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.PostProcessingConfig.Bandwidth">
            <summary>
            Gets or sets the parameters required to filter events on their bandwidth.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.PostProcessingConfig.SidebandAcousticActivity">
            <summary>
            Gets or sets the parameters required to filter events on the acoustic activity in their sidebands.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.PostProcessingConfig.RemoveEnclosedEvents">
            <summary>
            Gets or sets a value indicating Whether or not to remove temporally enclosed/nested events.
            Running profiles with multiple dB thresholds can produce sets of enclosed or temporally nested events.
            Russian doll events!
            Setting this boolean true removes all but the outermost of any set of encloseed events.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.PostProcessingConfig.PostProcessInDecibelGroups">
            <summary>
            If true (the default) post-processing of events will be done in groups based on their decibel threshold detection value.
            For example, all events at 3dB will be post-processed seperately from all events at 6dB.
            If false will process ebents as if they were all detected at the same decibel threshold.
            </summary>
            <value>
            <c>true</c> will enable grouping, <c>false</c> will disable grouping. Defaults to <c>true</c>.
            </value>
        </member>
        <member name="T:AudioAnalysisTools.Events.Types.EventPostProcessing.DurationConfig">
            <summary>
            The two properties in this class determine filtering of events based on their duration.
            The filter removes events whose duration lies outside three standard deviations (SDs) of an expected value.
            Assuming the duration is normally distributed, three SDs sets hard upper and lower duration bounds that includes 99.7% of instances.
            The filtering algorithm calculates these hard (3 SD) bounds and removes acoustic events that fall outside the bounds.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.DurationConfig.ExpectedDuration">
            <summary>
            Gets or sets a value indicating the Expected duration of an event.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.DurationConfig.DurationStandardDeviation">
            <summary>
            Gets or sets a value indicating the standard deviation of the expected duration.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.Events.Types.EventPostProcessing.BandwidthConfig">
            <summary>
            The next two properties determine filtering of events based on their bandwidth.
            This filter removes events whose bandwidth lies outside three standard deviations (SDs) of an expected value.
            Assuming the bandwidth is normally distributed, three SDs sets hard upper and lower bandwidth bounds that includes 99.7% of instances.
            The filtering algorithm calculates these hard bounds and removes acoustic events that fall outside the bounds.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.BandwidthConfig.ExpectedBandwidth">
            <summary>
            Gets or sets a value indicating the Expected bandwidth of an event.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.BandwidthConfig.BandwidthStandardDeviation">
            <summary>
            Gets or sets a value indicating the standard deviation of the expected bandwidth.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.Events.Types.EventPostProcessing.SidebandConfig">
            <summary>
            The properties in this config class are required to filter events based on the amount of acoustic activity in their sidebands.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.SidebandConfig.UpperSidebandWidth">
            <summary>
            Gets or sets a value indicating Whether or not to filter events based on acoustic conctent of upper buffer zone.
            If value = 0, the upper sideband is ignored.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.SidebandConfig.LowerSidebandWidth">
            <summary>
            Gets or sets a value indicating Whether or not to filter events based on the acoustic content of their lower buffer zone.
            If value = 0, the lower sideband is ignored.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.SidebandConfig.MaxBackgroundDecibels">
            <summary>
            Gets or sets a value indicating the maximum permissible value of background acoustic activity in the upper and lower sidebands of an event.
            The background is claculated as the average decibel value over all spectrogram cells in each sideband.
            This value is used only if LowerHertzBuffer > 0 OR UpperHertzBuffer > 0.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.SidebandConfig.MaxActivityDecibels">
            <summary>
            Gets or sets a value indicating the maximum decibel value in a sideband frequency bin or timeframe.
            The decibel value is an average over all spectrogram cells in any frame or bin.
            This value is used only if LowerHertzBuffer > 0 OR UpperHertzBuffer > 0.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.Events.Types.EventPostProcessing.SyllableSequenceConfig">
            <summary>
            The properties in this config class are required to combine a sequence of similar syllables into a single event.
            The first three properties concern the combining of syllables into a sequence or stroph.
            The next four properties concern the filtering/removal of sequences that do not satisfy expected properties.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.SyllableSequenceConfig.SyllableStartDifference">
            <summary>
            Gets or sets a value indicating the maximum allowable start time gap (seconds) between events within the same strophe.
            The gap between successive syllables is the "period" of the sequence.
            This value is used only where CombinePossibleSyllableSequence = true.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.SyllableSequenceConfig.SyllableHertzGap">
            <summary>
            Gets or sets a value indicating the maximum allowable difference (in Hertz) between the frequency bands of two events. I.e. events should be in similar frequency band.
            NOTE: SIMILAR frequency band means the differences between two top Hertz values and the two low Hertz values are less than hertzDifference.
            This value is used only where CombinePossibleSyllableSequence = true.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.SyllableSequenceConfig.FilterSyllableSequence">
            <summary>
            Gets or sets a value indicating Whether or not to remove/filter sequences having incorrect properties.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.SyllableSequenceConfig.SyllableMaxCount">
            <summary>
            Gets or sets a value indicating the maximum allowable number of syllables in a sequence.
            This value is used only where FilterSyllableSequence = true.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.SyllableSequenceConfig.ExpectedPeriod">
            <summary>
            Gets or sets a value indicating the expected periodicity in seconds.
            This value is used only where FilterSyllableSequence = true.
            Important Note: This property interacts with SyllableStartDifference.
            When setting ExpectedPeriod, you are actually setting a permissible range of values for the Period.
            The maximum permitted period will be the value assigned to SyllableStartDifference.
            The minimum period will be the ExpectedPeriod minus (SyllableStartDifference - ExpectedPeriod).
            For example: if SyllableStartDifference = 3 seconds and ExpectedPeriod = 2.5 seconds, then the minimum allowed period will be 2 seconds.
            THese bounds are hard bounds.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.SyllableSequenceConfig.PeriodStandardDeviation">
            <summary>
            Gets a value indicating the stadndard deviation of the expected period in seconds.
            This value is used only where FilterSyllableSequence = true.
            Important Note: This property is derived from two of the above properties.
                            SD of the period = (SyllableStartDifference - ExpectedPeriod) / 3.
                            The intent is that the maximum allowable syllable period is the expected value plus three times its standard deviation.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.Events.Types.EventPostProcessing.SyllableStackConfig">
            <summary>
            These parameters define the limits for combining stacked events - that is, events that are above or
            below each other with some spectral gap between them.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.SyllableStackConfig.MaxGapHertz">
            <summary>
            The maximum allowed gap between the top of the lower event and the bottom of the higher event.
            Any events that are closer than this gap will be combined.
            </summary>
            <value>The allowable gap in Hertz.</value>
        </member>
        <member name="P:AudioAnalysisTools.Events.Types.EventPostProcessing.SyllableStackConfig.MaxDifferenceSeconds">
            <summary>
            Controls how much variance is allowed in the temporal bounds of the event.
            If the events are part of the same large event, then they should start and end at the same time.
            </summary>
            <value>The allowable difference in seconds</value>
        </member>
        <member name="M:AudioAnalysisTools.Events.EventExtentions.GetDecibelArrayFromEvent(AudioAnalysisTools.Events.SpectralEvent,System.Double[0:,0:],AudioAnalysisTools.UnitConverters)">
            <summary>
            Returns the average of the maximum decibel value in each frame of an event.
            </summary>
            <param name="ev">The event.</param>
            <param name="spectrogramData">The spectrogramin decibels.</param>
            <param name="converter">Converter between real values and spectrogram frames/bins.</param>
            <returns>The average decibel value.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Events.EventExtentions.GetCompositeTrack``1(System.Collections.Generic.IEnumerable{``0})">
            <summary>
            Combines all the tracks in all the events in the passed list into a single track.
            Each frame in the composite event is assigned the spectral point having maximum amplitude.
            The points in the returned array are in temporal order.
            </summary>
            <param name="events">List of spectral events.</param>
        </member>
        <member name="M:AudioAnalysisTools.Events.EventFilters.FilterOnBandwidth(System.Collections.Generic.List{AudioAnalysisTools.Events.EventCommon},System.Double,System.Double,System.Double)">
            <summary>
            Filters lists of spectral events based on their bandwidth.
            Note: The typical sigma threshold would be 2 to 3 sds.
            </summary>
            <param name="events">The list of events.</param>
            <param name="average">The expected value of the bandwidth.</param>
            <param name="sd">The standard deviation of the bandwidth.</param>
            <param name="sigmaThreshold">THe sigma value which determines the max and min thresholds.</param>
            <returns>The filtered list of events.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Events.EventFilters.FilterShortEvents(System.Collections.Generic.List{AudioAnalysisTools.Events.SpectralEvent},System.Double)">
            <summary>
            Filters list of events to remove short events.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.EventFilters.FilterLongEvents(System.Collections.Generic.List{AudioAnalysisTools.Events.SpectralEvent},System.Double)">
            <summary>
            Filters list of events to remove long events.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.EventFilters.FilterOnDecibelDetectionThreshold(System.Collections.Generic.List{AudioAnalysisTools.Events.EventCommon},System.Double)">
            <summary>
            Filters lists of events based on their DecibelDetectionThreshold.
            </summary>
            <param name="events">The list of events.</param>
            <param name="threshold">The Decibel Detection Threshold.</param>
            <returns>The filtered list of events.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Events.EventFilters.FilterOnDuration(System.Collections.Generic.List{AudioAnalysisTools.Events.EventCommon},System.Double,System.Double,System.Double)">
            <summary>
            Filters lists of events based on their duration.
            Note: The typical sigma threshold would be 2 to 3 sds.
            </summary>
            <param name="events">The list of events.</param>
            <param name="average">The expected value of the duration.</param>
            <param name="sd">The standard deviation of the duration.</param>
            <param name="sigmaThreshold">THe sigma value which determines the max and min thresholds.</param>
            <returns>The filtered list of events.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Events.EventFilters.FilterOnDuration(System.Collections.Generic.List{AudioAnalysisTools.Events.EventCommon},System.Double,System.Double)">
            <summary>
            Remove events from a list of events whose time duration is either too short or too long.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.EventFilters.FilterEventsOnComponentCount(System.Collections.Generic.List{AudioAnalysisTools.Events.EventCommon},System.Int32)">
            <summary>
            Removes composite events from a list of EventCommon that contain more than the specfied number of SpectralEvent components.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.EventFilters.FilterEventsOnSyllableCountAndPeriodicity(System.Collections.Generic.List{AudioAnalysisTools.Events.EventCommon},System.Int32,System.Double,System.Double)">
            <summary>
            Removes composite events from a list of EventCommon where the component syllables do not have the correct periodicity.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.EventFilters.FilterEventsOnSidebandActivity(System.Collections.Generic.List{AudioAnalysisTools.Events.SpectralEvent},AudioAnalysisTools.StandardSpectrograms.BaseSonogram,System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Double},System.Nullable{System.Double},System.TimeSpan)">
            <summary>
            Removes events from a list of events that contain excessive noise in the lower and/or upper neighbourhood.
            Excess noise can indicate that this is not a legitimate event.
            This method measures noise as the average decibel value in the buffer zones above and below the events.
            </summary>
            <param name="events">A list of spectral events.</param>
            <param name="spectrogram">A matrix of the spectrogram in which event occurs.</param>
            <param name="lowerHertzBuffer">The band width of the required lower buffer. 100-200Hz is often appropriate.</param>
            <param name="upperHertzBuffer">The band width of the required upper buffer. 300-500Hz is often appropriate.</param>
            <param name="thresholdForBackgroundDecibels">The max allowed value for the average decibels value (over all spectrogram cells) in an event's sideband.</param>
            <param name="thresholdForMaxSidebandActivity">The max allowed value for the decibels value in a sideband timeframe or freq bin.</param>
            <param name="segmentStartOffset">Start time of the current recording segment.</param>
            <returns>A list of filtered events.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Events.EventFilters.IsSidebandActivityBelowThreshold(System.Double[0:,0:],System.String,System.Nullable{System.Double},System.Nullable{System.Double})">
            <summary>
            This method determines the acoustic activity in a portion of a spectrogram.
            The passed matrix represents the sideband of an acoustic event.
            The sideband is subject to two tests:.
            Test 1: Tests whether the average or background decibel value in the sideband is below the user supplied threshold?
            Test 2: This test covers the possibility that there is much acoustic activity concentrated in one or two freq bins or time frames.
                    Therefore, also require that there be at most one sideband bin or frame containing acoustic activity greater than the supplied decibel threshold.
            </summary>
            <param name="sidebandMatrix">A matrix that represents a portion of spectrogram which is actually the sideband of an acoustic event.</param>
            <param name="thresholdForBackgroundDecibels">Decibel threshold for the background test.</param>
            <param name="thresholdForActivityDecibels">Decibel threshold for the activity test.</param>
            <returns>A boolean determining whether the sideband is accepoted or rejected.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Events.EventFilters.GetLowerEventSideband(AudioAnalysisTools.Events.SpectralEvent,System.Double[0:,0:],System.Double,System.Int32,AudioAnalysisTools.UnitConverters)">
            <summary>
            Returns the matrix of neighbourhood values below an event.
            </summary>
            <param name="ev">The event.</param>
            <param name="spectrogramData">The spectrogram data as matrix with origin top/left.</param>
            <param name="bufferHertz">THe bandwidth of the buffer zone in Hertz.</param>
            <param name="converter">A converter to convert seconds/Hertz to frames/bins.</param>
            <returns>The sideband as a matrix.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Events.EventFilters.GetUpperEventSideband(AudioAnalysisTools.Events.SpectralEvent,System.Double[0:,0:],System.Double,System.Int32,AudioAnalysisTools.UnitConverters)">
            <summary>
            Returns the matrix of neighbourhood values above an event.
            </summary>
            <param name="ev">The event.</param>
            <param name="spectrogramData">The spectrogram data as matrix with origin top/left.</param>
            <param name="bufferHertz">The bandwidth of the buffer zone in Hertz.</param>
            <param name="converter">A converter to convert seconds/Hertz to frames/bins.</param>
            <returns>The neighbourhood as a matrix.</returns>
        </member>
        <member name="P:AudioAnalysisTools.Events.Interfaces.ISpectralBand.LowFrequencyHertz">
            <summary>
            Gets the bottom frequency bound of the acoustic event.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.Events.SpectralEvent.EventDurationSeconds">
            DIMENSIONS OF THE EVENT
            <summary>Gets the event duration in seconds.</summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.SpectralPoint.CompareTo(System.Object)">
            <summary>
            Compare all seconds and frequency values.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.Events.Tracks.TrackType.OneBinTrack">
            <summary>
            Sounds like single tone whistle.
            Each track point advances one time step.
            All points remain in the same frequency bin.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.Events.Tracks.TrackType.ForwardTrack">
            <summary>
            Sounds like fluctuating tone/chirp.
            Each track point advances one time step.
            Points may move up or down two frequency bins.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.Events.Tracks.TrackType.UpwardTrack">
            <summary>
            Sounds like whip.
            Each track point ascends one frequency bin.
            Points may move forwards or back one frame step.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.Events.Tracks.TrackType.OneFrameTrack">
            <summary>
            Sounds like click.
            Each track point ascends one frequency bin.
            All points remain in the same time frame.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.Events.Tracks.TrackType.MixedTrack">
            <summary>
            A track containing segments of two or more of the above.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.Tracks.Track.#ctor(AudioAnalysisTools.UnitConverters,AudioAnalysisTools.Events.Tracks.TrackType)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.Events.Tracks.Track"/> class.
            Constructor.
            </summary>
            <param name="converter">
            A reference to unit conversions this track class should use to
            convert spectrogram data to real units.
            </param>
            <param name="trackType"> The type of track.</param>
        </member>
        <member name="M:AudioAnalysisTools.Events.Tracks.Track.#ctor(AudioAnalysisTools.UnitConverters,AudioAnalysisTools.Events.Tracks.TrackType,System.ValueTuple{System.Int32,System.Int32,System.Double}[])">
            <inheritdoc cref="M:AudioAnalysisTools.Events.Tracks.Track.#ctor(AudioAnalysisTools.UnitConverters,AudioAnalysisTools.Events.Tracks.TrackType)"/>
            <param name="initialPoints">
            A set of initial points to add into the point data collection.
            </param>
        </member>
        <member name="P:AudioAnalysisTools.Events.Tracks.Track.StartFrequency">
            <summary>
            Gets the frequency of the first point in the track.
            Where there is more than one frequency in this first frame, returns the lowest frequency.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.Tracks.Track.SetPoint(System.Int32,System.Int32,System.Double)">
            <summary>
            Adds a new point to track given the fram, freq bin and amplitude.
            </summary>
            <param name="frame">The frame number.</param>
            <param name="bin">The freq bin number.</param>
            <param name="amplitude">The amplitude at given point.</param>
        </member>
        <member name="M:AudioAnalysisTools.Events.Tracks.Track.CheckPoint(System.Int32,System.Int32)">
            <summary>
            Does a sanity check on the conversion of frame/bins to real values and back again.
            </summary>
            <param name="frame">The frame number.</param>
            <param name="bin">The freq bin number.</param>
        </member>
        <member name="M:AudioAnalysisTools.Events.Tracks.Track.GetTrackAsSequenceOfHertzValues">
            <summary>
            Returns an array that has the same number of time frames as the track.
            Each element contains the highest frequency (Hertz) for that time frame.
            NOTE: For tracks that include extreme frequency modulation (e.g. clicks and vertical tracks),
                  this method returns the highest frequency value in each time frame.
            </summary>
            <returns>An array of Hertz values.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Events.Tracks.Track.GetTrackFrequencyProfile">
            <summary>
            Returns an array of Hertz difference values.
            The array has length one less than the number of dicrete time frames in the track.
            THis array can be used to compare simularity bewteen the shapes of tracks even if absolute frequency values are not similar.
            </summary>
            <returns>An array of Hertz difference values.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Events.Tracks.Track.GetAmplitudeOverTimeFrames">
            <summary>
            Returns the maximum amplitude in each time frame.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.Tracks.Track.GetAverageTrackAmplitude">
            <summary>
            Returns the maximum amplitude in each time frame.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Events.Tracks.Track.Draw(SixLabors.ImageSharp.Processing.IImageProcessingContext,AudioAnalysisTools.Events.Drawing.EventRenderingOptions)">
            <summary>
            Draws the track on an image given by its processing context.
            </summary>
            <remarks>
            Implementation is fairly simple. It sorts all points by the default IComparable method
            which sorts points by time (ascending), frequency (ascending) and finally value.
            The sorted collection is then used as a set of points to connect lines to.
            </remarks>
        </member>
        <member name="P:AudioAnalysisTools.IPointData.Points">
            <summary>
            Gets a collection of spectral points.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.BlobEvent">
            <summary>
            An acoustic event that also includes data about the content identified by the event.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ChirpEvent.#ctor(AudioAnalysisTools.Events.Tracks.Track,Acoustics.Shared.Interval{System.Double})">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.ChirpEvent"/> class.
            </summary>
            <remarks>
            MaxScore establishes a scale for the chirp score. Typically the amplitude of track points is decibels.
            A satisfactory maxScore is 12.0 decibels, since this is a high SNR in enviornmental recordings.
            The normalised score is a linear conversion from 0 - maxScore to [0, 1].
            </remarks>
            <param name="chirp">A chirp track consisting of a sequence of spectral points.</param>
            <param name="interval">A min and maximum score used to normalise the track score.</param>
        </member>
        <member name="P:AudioAnalysisTools.ChirpEvent.FrequencyProfileScore">
            <summary>
            Gets or sets the score for the frequency profile of the contained track.
            This score is used as a measure of how close the shape of a track matches a desired shape.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.ChirpEvent.Score">
            <summary>
            Gets the average track amplitude.
            </summary>
            <remarks>
            Thevent score is an average value of the track score.
            </remarks>
        </member>
        <member name="P:AudioAnalysisTools.ClickEvent.Score">
            <summary>
            Gets the average track amplitude.
            </summary>
            <remarks>
            Thevent score is an average value of the track score.
            </remarks>
        </member>
        <!-- Badly formed XML comment ignored for member "P:AudioAnalysisTools.HarmonicEvent.HarmonicInterval" -->
        <member name="P:AudioAnalysisTools.OscillationEvent.Periodicity">
            <summary>
            Gets or sets the period in seconds between consecutive high points in an oscillation event.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.OscillationEvent.Draw(SixLabors.ImageSharp.Processing.IImageProcessingContext,AudioAnalysisTools.Events.Drawing.EventRenderingOptions)">
            <summary>
            Draws a border around this oscillation event.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.OscillationEvent.TrimEvent(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Extracts an event from a spectrogram given its bounds.
            Then trims the event because oscillation events do not typically start where the DCT places them.
            It a;sp returns the periodicity of the oscillation event.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.WhipEvent.Score">
            <summary>
            Gets the average track amplitude.
            </summary>
            <remarks>
            Thevent score is an average value of the track score.
            </remarks>
        </member>
        <member name="P:AudioAnalysisTools.WhistleEvent.Score">
            <summary>
            Gets the average track amplitude.
            </summary>
            <remarks>
            Thevent score is an average value of the track score.
            </remarks>
        </member>
        <member name="M:AudioAnalysisTools.WhistleEvent.MergeTwoWhistleEvents(AudioAnalysisTools.WhistleEvent,AudioAnalysisTools.WhistleEvent)">
            <summary>
            Merges two whistle events into one whistle event.
            This is useful because a typical bird whistle contains side bands and therefore covers more than one frequency bin.
            The Whistle detection algorithm detects whistle content in the side bins but puts each bin content in a different event.
            THis method merges events that belong to the same whistle call.
            </summary>
            <param name="e1">first event.</param>
            <param name="e2">second event.</param>
            <returns>a new whistle event .</returns>
        </member>
        <member name="M:AudioAnalysisTools.FindMatchingEvents.Execute_Bi_or_TrinaryMatch(System.Double[0:,0:],AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.Collections.Generic.List{AudioAnalysisTools.AcousticEvent},System.Int32,System.Int32,System.Double)">
            <summary>
            Use this method to find match in sonogram to a symbolic definition of a bird call.
            That is, the template should be matrix of binary or trinary values.
            </summary>
            <param name="dBThreshold">Not used in calculation. Only used to speed up loop over the spectrogram.</param>
        </member>
        <member name="M:AudioAnalysisTools.FindMatchingEvents.Execute_Spr_Match(System.Char[0:,0:],AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.Collections.Generic.List{AudioAnalysisTools.AcousticEvent},System.Int32,System.Int32,System.Double)">
            <summary>
            Use this method to find match in sonogram to a symbolic definition of a bird call.
            That is, the template should be matrix of binary or trinary values.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.FindMatchingEvents.NormaliseBiTrinaryMatrix(System.Double[0:,0:])">
            <summary>
            Normalises a binary matrix of -1,+1 or trinary matrix of -1,0,+1 so that the sum of +1 cells = sum of -1 cells.
            Change the -1 cells by a ratio.
            The purpose is to use the normalised matrix for pattern matching such that the matrix returns a zero value for uniform background noise.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.FindMatchingEvents.Execute_StewartGage(System.Double[0:,0:],System.Double,AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.Collections.Generic.List{AudioAnalysisTools.AcousticEvent},System.Int32,System.Int32,System.Double)">
            <summary>
            Use this method when want to match defined shape in target using cross-correlation.
            This was the method used by Stewart Gage.
            First set target and source to same dynamic range.
            Then NormaliseMatrixValues target and source to unit-length.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.HarmonicAnalysis.Execute(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.Int32,System.Int32,System.Int32,System.Double)">
            <summary>
            Returns a tuple consisting of:
            1) an array of scores over the entire recording
            2) a list of acoustic events
            3) a matrix of hits corresonding to the spectrogram.
            </summary>
            <param name="sonogram">sonogram derived from the recording.</param>
            <param name="minHz">min bound freq band to search.</param>
            <param name="maxHz">max bound freq band to search.</param>
            <param name="harmonicCount">expected number of harmonics in the frequency band.</param>
            <param name="amplitudeThreshold">ignore harmonics with an amplitude less than this minimum dB.</param>
            <param name="maxDuration">look for events of this duration.</param>
        </member>
        <member name="M:AudioAnalysisTools.HarmonicAnalysis.CountHarmonicTracks(System.Double[],System.Int32)">
            <summary>
            Counts the number of spectral tracks or harmonics in the passed ferquency band.
            Also calculates the average amplitude of the peaks to each succeeding trough.
            </summary>
            <param name="values">Spectral values in the frequency band.</param>
            <param name="row">This argument is NOT used. Is included only for debugging purposes.</param>
        </member>
        <member name="M:AudioAnalysisTools.HarmonicAnalysis.DetectHarmonicsUsingFormantGap(System.Double[0:,0:],System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Double)">
            <summary>
            This method did not work much better than the DCT method - see below.
            Looks for a series of harmonic tracks at fixed freq intervals.
            Problem is that the harmonic tracks are not necessarily at fixed intervals.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.HarmonicAnalysis.DetectHarmonicsUsingDCT(System.Double[0:,0:],System.Int32,System.Int32,System.Int32,System.Boolean,System.Int32,System.Int32,System.Double)">
            <summary>
            THIS METHOD NO LONGER IN USE.
            NOT USEFUL FOR ANIMAL CALLS.
            Tried this but it is suitable only when there is guarantee of numerous spectral tracks as in the vowels of human speech.
            It yields SPURIOUS RESULTS where there is only one whistle track.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.SpectralCentroid">
             <summary>
             Calculates the spectral centroid of a spectrum, or a recording segment.
             The spectral centroid is a considred to be a reliable estimate of the brightness of a recording.
             Bright recordings contain more high frequency content.
             It is included here as a summary index because it was found to be correlated with degree of "naturalness" of a bush soundscape.
             See recent papers from Sussex University (Alice Eldridge and colleagues)
             (1) Eldridge, Alice and Guyot, Patrice and Moscoso, Paola and Johnston, Alison and Eyre-Walker, Ying and Peck, Mika
             "Sounding out ecoacoustic metrics: Avian species richness is predicted by acoustic indices in temperate but not tropical habitats."
             (2018) Ecological Indicators, 95 (1). 939-952. ISSN 1470-160X
             (2) Carruthers-Jones, Jonathan, Eldridge, Alice, Guyot, Patrice, Hassal, Christopher and Holmes, George
             "The call of the wild: investigating the potential for ecoacoustic methods in mapping wilderness areas."
             (2019) Science of The Total Environment, 695. p. 133797. ISSN 0048-9697
            
             See following for good intro to calculating the Spectral Centroid:
             https://www.cs.cmu.edu/~music/icm/slides/05-algorithmic-composition.pdf
             Also Wikipedia entry: https://en.wikipedia.org/wiki/Spectral_centroid
             The spectral centroid is derived from the values in the AMPLITUDE spectrogram.
             A single spectral centroid is calculated for each time frame.
             If a summary value is required for a longer signal, i.e. one second or one minute, then the centroid values for each frame are averaged over the time period.
             Note that the frequency value for a bin is located at the centre of the bin. For a typical bin width of 43 Hz, the centre will be at 21.5 Hz above bin minimum.
             The steps in the calculation are:
             1: Normalise the spectrum: normalized_spectrum = spectrum / sum(spectrum)  # like a probability mass function
             2: Normalise the frequency values in [0,1], where the nyquist freq = 1.0.
             3: spectral_centroid = sum(normalized_frequencies* normalized_spectrum)
             Note: When calculated this way the Spectral centroid is a ratio.  Multiply this value by the Nyquist (maximum frequency) to get the centroid in Hertz.
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralCentroid.CalculateSpectralCentroid(System.Double[],System.Int32)">
            <summary>
            Calculates the spectral centroid of the given amplitude spectrum.
            See notes above.
            </summary>
            <param name="spectrum">Amplitude spectrum.</param>
            <returns>Centroid.</returns>
        </member>
        <member name="M:AudioAnalysisTools.SpectralCentroid.CalculateSpectralCentroids(System.Double[0:,0:],System.Int32)">
            <summary>
            This method assumes that the rows of the passed matrix are spectra and the columns are frequency bins.
            </summary>
            <param name="spectra">As a matrix.</param>
            <param name="nyquist">The maximum frequency.</param>
            <returns>An array of spectral centroids.</returns>
        </member>
        <member name="M:AudioAnalysisTools.SpectralCentroid.CalculateSpectralCentroids(AudioAnalysisTools.StandardSpectrograms.AmplitudeSpectrogram)">
            <summary>
            Calculates the spectral centroid for each frame of an amplitude spectrogram.
            </summary>
            <param name="spectrogram">As AmplitudeSpectrogram.</param>
            <returns>An array of spectral centroids.</returns>
        </member>
        <member name="M:AudioAnalysisTools.SpectralCentroid.CalculateSpectralCentroidsInOneSecondSegments(AudioAnalysisTools.StandardSpectrograms.AmplitudeSpectrogram)">
            <summary>
            Calculates the spectral centroid for each one-second segment of an amplitude spectrogram.
            </summary>
            <param name="spectrogram">As AmplitudeSpectrogram.</param>
            <returns>An array of spectral centroids.</returns>
        </member>
        <member name="T:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogram3D">
            <summary>
            This class generates false-colour spectrograms of long duration audio recordings.
            Important properties are:
            1) the colour map which maps three acoutic indices to RGB.
            2) The scale of the x and y axes which are dtermined by the sample rate, frame size etc.
            In order to create false colour spectrograms, copy the method
                    public static void DrawFalseColourSpectrograms(LDSpectrogramConfig configuration)
            All the arguments can be passed through a config file.
            Create the config file throu an instance of the class LDSpectrogramConfig
            and then call config.WritConfigToYAML(FileInfo path).
            Then pass that path to the above static method.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogram3D.Main(AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogram3D.Arguments)">
            <summary>
            This method used to construct slices out of implicit 3-D spectrograms.
            As of December 2014 it contains hard coded variables just to get it working.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogram3D.GetDaySlice(System.IO.DirectoryInfo,System.Int32,System.Int32)">
            <summary>
            This method reads a single file containg a single day of index values.
            The method assumes that the file name has following structure:  XXXXX_YYYYMMDD.SpectralIndices.PivotTable.csv.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramClusters">
             <summary>
             This class contains two methods:  (1) StitchPartialSpectrograms()   and    (2) ConcatenateSpectralIndexFiles()
            
             (1) StitchPartialSpectrograms()
             This method stitches together images and/or indices derived from a sequence of short recordings with gaps between them.
             It was written to deal with a set of recordings with protocol of Gianna Pavan (10 minutes every 30 minutes).
            
             The following Powershell command was constructed by Anthony to do the analysis and join the sequence of images so derived:
             Y:\Italy_GianniPavan\Sassofratino1day | % { &amp; "C:\Work\GitHub\audio-analysis\AudioAnalysis\AnalysisPrograms\bin\Release\AnalysisPrograms.exe" audio2csv -so ($_.FullName) -o "Y:\Italy_GianniPavan\output" -c "C:\Work\GitHub\audio-analysis\AudioAnalysis\AnalysisConfigFiles\Towsey.Acoustic.Parallel.yml" }
             where:
                     Y:\Italy_GianniPavan\Sassofratino1day   is the directory containing recordings
                     | = a pipe
                     % = foreach{}  = perform the operation in curly brackets on each item piped from the directory.
                      &amp; "C:\Work\GitHub\audio-analysis\AudioAnalysis\AnalysisPrograms\bin\Release\AnalysisPrograms.exe"  = runs an executable
                     audio2csv = first command line argument which determines the "activity" performed
                     -so ($_.FullName)  = the input file
                     -o "Y:\Italy_GianniPavan\output" = the output directory
                     -c "PATH\Towsey.Acoustic.Parallel.yml" is the config file
            
             The following PowerShell command was used by Anthony to stitch together a sequence of spectrogam images without any gap between them.
             It requires ImageMagick software to be installed: i.e. C:\Program Files\ImageMagick-6.8.9-Q16\montage.exe
             Y:\Italy_GianniPavan\output\Towsey.Acoustic>  &amp; "C:\Program Files\ImageMagick-6.8.9-Q16\montage.exe" -mode concatenate -tile x1 *2MAP* "..\..\merge.png"
            
            
             (2) ConcatenateSpectralIndexFiles()
             This method was written to deal with a new recording protocol in which 24 hours of recording are made in 4 blocks of 6 hours each.
             It merges all files of acoustic indices derived from a sequence of consecutive 6 hour recording, into one file. It then creates the images.
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramClusters.ExtractSOMClusters1">
            <summary>
            This method rearranges the content of a false-colour spectrogram according to the acoustic cluster or acoustic state to which each minute belongs.
            The time scale is added in afterwards - must overwrite the previous time scale and title bar.
            THis method was writtent to examine the cluster content of recordings analysed by Mangalam using a 10x10 SOM.
            The output image was used in the paper presented by Mangalam to BDVA2015 in Tasmania. (Big data, visual analytics).
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramClusters.ExtractSOMClusters2">
            <summary>
            This method rearranges the content of a false-colour spectrogram according to the acoustic cluster or acoustic state to which each minute belongs.
            The time scale is added in afterwards - must overwrite the previous time scale and title bar.
            THis method was writtent to examine the cluster content of recordings analysed by Mangalam using a 10x10 SOM.
            The output image was used in the paper presented by Michael Towsey to Ecoacoustics Congress 2016, at Michigan State University.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig">
            <summary>
            CONFIG CLASS FOR the class LDSpectrogramRGB.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig"/> class.
            CONSTRUCTOR.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig.FreqScale">
            <summary>
            Gets or sets the type of freq scale.
            # Eventual options will be: Linear, Mel, Linear62Octaves31Nyquist11025, Linear125Octaves30Nyquist11025, Octaves24Nyquist32000, Linear125Octaves28Nyquist32000
            # Only "Linear", "Linear125Octaves6Tones28Nyquist11025", "Linear125Octaves7Tones28Nyquist32000" work at present.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig.ColorMap1">
            <summary>
            Gets or sets parameter to manipulate the color map and appearance of the false-colour spectrogram.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig.ColorMap2">
            <summary>
            Gets or sets parameter to manipulate the colour map and appearance of the false-colour spectrogram
            Pass two color maps because two maps convey more information.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig.ColourFilter">
            <summary>
            Gets or sets value of the color filter.
            Its value must be less than 1.0. Good value is 0.75.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig.BlueEnhanceParameter">
            <summary>
            Gets or sets value of the blue enhancement parameter.
            Its value must be in 0.0 to 1.0. Current suggested value is 0.5.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig.ImageChrome">
            <summary>
            Gets or sets a value indicating whether or not to render chrome around the FCS.
            Chrome is all the decoration around the data; axes, grids, titles, etc.
            </summary>
            <value>If <c>true</c> will render image chrome.</value>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig.XAxisTicInterval">
            <summary>
            Gets or sets the default XAxisTicInterval.
            The default assumes one minute spectra i.e. 60 per hour
            But as of January 2015, this is not fixed. The user can adjust
             the tic interval to be appropriate to the time scale of the spectrogram.
            May 2017: XAxisTicIntervalSeconds is the new configuration option!.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig.XAxisTicIntervalSeconds">
            <summary>
            Gets or sets the default XAxisTicIntervalSeconds.
            The default assumes one minute spectra i.e. 60 per hour
            But as of January 2015, this is not fixed. The user can adjust
             the tic interval to be appropriate to the time scale of the spectrogram.
            May 2017: Now measured in seconds and usage XAxisTicIntervalSeconds is preferred.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig.YAxisTicInterval">
            <summary>
            Gets or sets YAxisTicInterval in Hertz.
            The vertical spacing between horizontal grid lines for the y-Axis
            mark 1 kHz intervals.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig.CalculateYAxisTickInterval(System.Double,System.Double)">
            <summary>
            In seconds, the horizontal spacing between vertical grid lines for the x-Axis.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig.ReadYamlToConfig(System.IO.FileInfo)">
            <summary>
            READS A YAML CONFIG FILE into a Config variable and then transfers all values into the appropriate config class.
            </summary>
            <returns>
            The <see cref="T:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig"/>.
            </returns>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig.GetDefaultConfig">
            <summary>
            NOTE: As of August 2015, we are using EVN (event count) in both spectrograms because CVR (cover) is too highly correlated with POW.
            NOTE: As of May 2017, PMN replaces POW.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig.GetDefaultConfig(System.String,System.String)">
            <summary>
            Gets a default config for long-duration false-color spectrograms.
            But allows caller to substitute custom color maps.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramDifference.DrawDifferenceSpectrogram(System.IO.DirectoryInfo,System.IO.FileInfo,System.IO.FileInfo,System.IO.DirectoryInfo)">
            <summary>
            This method compares the acoustic indices derived from two different long duration recordings of the same length.
            It takes as input six csv files of acoustic indices in spectrogram columns, three csv files for each of the original recordings to be compared.
            The method produces one spectrogram image files:
            1) A false-colour difference spectrogram, where the difference is shown as a plus/minus departure from grey.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramDiscreteColour.DiscreteColourSpectrograms">
            <summary>
            Experiments with false colour images - discretising the colours
            SEEMED LIKE A GOOD IDEA AT THE TIME!
            Not sure it is any use but worthwhile preserving the code.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramDistance.DrawDistanceSpectrogram(System.IO.DirectoryInfo,System.IO.FileInfo,System.IO.FileInfo,System.IO.DirectoryInfo)">
            <summary>
            This method compares the acoustic indices derived from two different long duration recordings of the same length.
                It takes as input any number of csv files of acoustic indices in spectrogram columns.
                Typically there will be at least three indices csv files for each of the original recordings to be compared.
                The method produces four spectrogram image files:
                1) A negative false-color spectrogram derived from the indices of recording 1.
                2) A negative false-color spectrogram derived from the indices of recording 2.
                3) A spectrogram of euclidean distances between the two input files.
                4) The above three spectrograms combined in one image.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB">
            <summary>
            This class generates false-color spectrograms of long duration audio recordings.
            Important properties are:
            1) the color map which maps three acoustic indices to RGB.
            2) The scale of the x and y axes which are determined by the sample rate, frame size etc.
            In order to create false color spectrograms, copy the method
                    public static void DrawFalseColorSpectrograms(LDSpectrogramConfig configuration)
            All the arguments can be passed through a config file.
            Create the config file through an instance of the class LDSpectrogramConfig
            and then call config.WritConfigToYAML(FileInfo path).
            Then pass that path to the above static method.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.spectralIndexProperties">
            <summary>
            Index properties - conatins user defined min and max values for index normalisation - required when drawing images.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB"/> class.
            No Arguments CONSTRUCTOR.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.#ctor(System.TimeSpan,System.Int32,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB"/> class.
            CONSTRUCTOR.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.#ctor(System.TimeSpan,System.TimeSpan,System.Int32,System.Int32,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB"/> class.
            CONSTRUCTOR
            WARNING: Ths will create a linear Hertz scale spectrogram.
            </summary>
            <param name="minuteOffset">minute of day at which the spectrogram starts.</param>
            <param name="xScale">time scale : pixels per hour.</param>
            <param name="sampleRate">recording sample rate which also determines scale of Y-axis.</param>
            <param name="frameWidth">frame size - which also determines scale of Y-axis.</param>
            <param name="colorMap">acoustic indices used to assign  the three color mapping.</param>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.RecordingStartDate">
            <summary>
            Gets or sets the date and time at which the current LDspectrogram starts
            This can be used to correctly.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.StartOffset">
            <summary>
            Gets or sets the time at which the current LDFC spectrogram starts.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.IndexCalculationDuration">
            <summary>
            Gets or sets the temporal duration of one sub-segment interval for which indices are calculated.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.FrameWidth">
            <summary>
            Gets or sets the frame width. Used only to calculate scale of Y-axis to draw grid lines.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.SampleRate">
            <summary>
            Gets or sets the sample rate.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.FreqScale">
            <summary>
            Gets or sets the ColorMap within current recording.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.GetYinterval">
            <summary>
            Gets the 1 kHz intervals.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.ColorMap">
            <summary>
            Gets or sets the ColorMap within current recording.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.ColorMode">
            <summary>
            Gets or sets POSITIVE or NEGATIVE.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.SampleCount">
            <summary>
            Gets or sets used where the spectrograms are derived from averages and want to do t-test of difference.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.IndexStats">
            <summary>
            Gets index distribution statistics are now calulated after the indices have been calculated.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.SunriseDataFile">
            <summary>
            Gets or sets a file from which can be obtained information about sunrise and sunset times for the recording site.
            The csv file needs to be in the correct format and typically should contain 365 lines.
            Have not attempted to deal with leap years!.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.SetSpectralIndexProperties(System.Collections.Generic.Dictionary{System.String,AudioAnalysisTools.Indices.IndexProperties})">
            <summary>
            This method sets default indices to use if passed Dictionary = null.
            This may not be a good idea. Trying it out. Maybe better to crash!.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.LoadSpectrogramDictionary(System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]})">
            <summary>
            Call this method if already have a dictionary of Matrix spectorgrams and wish to load directly
            For example, call this method from AnalyseLongRecordings.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.GetMatrix(System.String)">
            <summary>
            Call this method to access a spectrogram matrix.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.GetNormalisedSpectrogramMatrix(System.String)">
            <summary>
            returns a matrix of acoustic indices whose values are normalised.
            In addition, small background values are reduced as per filter coefficient. 1.0 = unchanged.
            NOTE: The matrix is oriented as it would appear in the spectrogram image; i.e. rows = freq bins.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.DrawGreyScaleSpectrograms(System.IO.DirectoryInfo,System.String,System.String[],Acoustics.Shared.ImageChrome)">
            <summary>
            draws only those spectrograms in the passed array of keys.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.DrawGreyscaleSpectrogramOfIndex(System.String,Acoustics.Shared.ImageChrome)">
            <summary>
            Assume calling method has done all the reality checks.</summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.DrawFalseColorSpectrogramChromeless(System.String,System.String,System.Double)">
            <summary>
            Draw a chromeless false colour spectrogram.
            Chromeless means WITHOUT all the trimmings, such as title bar axis labels, grid lines etc.
            However it does add in notated error segments.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.FrameFalseColourSpectrogram(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB)">
            <summary>
            Frames a false-colourspectrogram.
            That is, it creates the title bar and the time scale. Also adds frequency grid lines to the image.
            Note that to call this method, the field cs.Freqscale MUST NOT = null.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.FrameLDSpectrogram(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB,System.Int32,System.Int32)">
            <summary>
            Frames a false-color spectrogram.
            Creates the title bar and the time scale. Also adds frequency grid lines to the image.
            Note that the 'nyquist' and 'hertzGridInterval' arguments are used ONLY if the cs.FreqScale field==null.
            Also note that in this case, the frequency scale will be linear.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.DrawGreyscaleSpectrogramOfIndex(System.String,System.Double[0:,0:])">
            <summary>
            Assume calling method has done all the reality checks.
            Assume the Index Calculation Duration = 60 seconds.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.DrawRgbColorMatrix(System.Double[0:,0:],System.Double[0:,0:],System.Double[0:,0:],System.Boolean,System.Double)">
            <summary>
            This method assumes that all the passed matrices are normalised and of the same dimensions.
            The method implements a hack to enhance the blue color because the human eye is less sensitive to blue.
            If there is a problem with one or more of the three rgb values, a gray pixel is substituted not a black pixel.
            Black is a frequent color in LDFC spectrograms, but gray is highly unlikely,
            and therefore its presence stands out as indicating an error in one or more of the rgb values.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.DrawFourColorSpectrogram(System.Double[0:,0:],System.Double[0:,0:],System.Double[0:,0:],System.Double[0:,0:],System.Boolean)">
            <summary>
            A technique to derive a spectrogram from four different indices
            same as above method but multiply index value by the amplitude value instead of squaring the value.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.DrawColourScale(System.Int32,System.Int32)">
            <summary>
            Returns an image of an array of color patches.
            It shows the three primary colors and pairwise combinations.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.DrawSpectrogramsFromSpectralIndices(System.IO.DirectoryInfo,System.IO.DirectoryInfo,AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig,System.IO.FileInfo,AudioAnalysisTools.Indices.IndexGenerationData,System.String,System.String,System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]},AnalysisBase.ResultBases.SummaryIndexBase[],System.Collections.Generic.Dictionary{System.String,AudioAnalysisTools.Indices.IndexDistributions.SpectralStats},AudioAnalysisTools.SiteDescription,System.IO.FileInfo,System.Collections.Generic.List{AudioAnalysisTools.Indices.GapsAndJoins})">
            <summary>
            This IS THE MAJOR STATIC METHOD FOR CREATING LD SPECTROGRAMS
            IT CAN BE COPIED AND APPROPRIATELY MODIFIED BY ANY USER FOR THEIR OWN PURPOSE.
            WARNING: Make sure the parameters in the CONFIG file are consistent with the CSV files.
            </summary>
            <param name="inputDirectory">inputDirectory.</param>
            <param name="outputDirectory">outputDirectory.</param>
            <param name="ldSpectrogramConfig">config for drawing FCSs.</param>
            <param name="indexPropertiesConfigPath">The indices Config Path. </param>
            <param name="indexGenerationData">indexGenerationData.</param>
            <param name="basename">stem name of the original recording.</param>
            <param name="analysisType">will usually be "Towsey.Acoustic".</param>
            <param name="indexSpectrograms">Optional spectra to pass in. If specified the spectra will not be loaded from disk.</param>
            <param name="summaryIndices">an array of summary index results.</param>
            <param name="indexStatistics">Info about the distributions of the spectral statistics.</param>
            <param name="siteDescription">Optionally specify details about the site where the audio was recorded.</param>
            <param name="sunriseDataFile">This is only available for locations near Brisbane, Austalia.</param>
            <param name="segmentErrors">Note that these segment errors were derived from previous analysis of the summary indices.</param>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB.SpectrogramFraming(AudioAnalysisTools.LongDurationSpectrograms.LDSpectrogramRGB,SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24})">
            <summary>
            This method CHROMES the passed spectrogram.
            Chroming means to add all the trimmings, title bar axis labels, grid lines, cinnamon powder, etc.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramRibbons.ReadSpectralIndicesFromTwoFalseColourSpectrogramRibbons(SixLabors.ImageSharp.Image,SixLabors.ImageSharp.Image)">
            <summary>
            Reads the entire length of spectral ribbon images into a matrix of spectral indices.
            IMPORTANT: Assume that the two images both have the same time scale, that is, one pixel = one minute AND
                       ASSUME they have the same pixel width i.e. span the same number of minutes.
            </summary>
            <param name="image1">spectrogram ribbon 1.</param>
            <param name="image2">spectrogram ribbon 2.</param>
            <returns>matrix of normalised spectral indices corresponding to those used to construct the ribbon images.</returns>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramRibbons.ReadSpectralIndicesFromTwoFalseColourSpectrogramRibbons(SixLabors.ImageSharp.Image,SixLabors.ImageSharp.Image,System.TimeSpan,System.TimeSpan)">
            <summary>
            This method assumes that the ribbon spectrograms are composed using the following five indices for RGB
            string[] colourKeys1 = { "ACI", "ENT", "EVN" };.
            string[] colourKeys2 = { "BGN", "PMN", "EVN" };.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramRibbons.ReadSpectralIndicesFromFalseColourSpectrogram(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},System.Int32,System.Int32)">
            <summary>
            Read in a false colour spectrogram ribbon and recover the normalised indices from the pixel values.
            </summary>
            <param name="image">a false colour spectrogram ribbon.</param>
            <param name="startMinute">start reading from this row.</param>
            <param name="endMinute">end reading from this row.</param>
            <returns>an array of three index matrices, from red, green, blue components of each pixel.</returns>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramRibbons.GetSpectrogramRibbon(System.Double[0:,0:],System.Double[0:,0:],System.Double[0:,0:])">
            <summary>
            returns a Long Duration spectrogram of same image length as the full-scale LdSpectrogram but the frequency scale reduced to the passed vlaue of height.
            This produces a LD spectrogram "ribbon" which can be used in circumstances where the full image is not appropriate.
            Note that if the height passed is a power of 2, then the full frequency scale (also a power of 2 due to FFT) can be scaled down exactly.
            A height of 32 is quite good - small but still discriminates frequency bands.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramRibbons.GetSummaryIndexArray(System.Double[0:,0:])">
            <summary>
            Returns an array of summary indices, where each element of the array (one element per minute) is a single summary index
            derived by averaging the spectral indices for that minute.
            The returned matrices have spectrogram orientation.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramStitching">
             <summary>
             This class used to contain only two methods:  (1) StitchPartialSpectrograms()   and    (2) ConcatenateSpectralIndexFiles()
             Now it contains several versions to concatenate Index files. This is because there are now several use cases.
            
            
             Here are the original two methods:
             (1) StitchPartialSpectrograms()
             This method stitches together images and/or indices derived from a sequence of short recordings with gaps between them.
             It was written to deal with a set of recordings with protocol of Gianna Pavan (10 minutes every 30 minutes).
            
             The following Powershell command was constructed by Anthony to do the analysis and join the sequence of images so derived:
             <code><![CDATA[
             Y:\Italy_GianniPavan\Sassofratino1day | % {& "C:\Work\GitHub\audio-analysis\AudioAnalysis\AnalysisPrograms\bin\Release\AnalysisPrograms.exe" audio2csv -so ($_.FullName) -o "Y:\Italy_GianniPavan\output" -c "C:\Work\GitHub\audio-analysis\AudioAnalysis\AnalysisConfigFiles\Towsey.Acoustic.Parallel.yml" }
             where:
                     Y:\Italy_GianniPavan\Sassofratino1day   is the directory containing recordings
                     | = a pipe
                     % = foreach{}  = perform the operation in curly brackets on each item piped from the directory.
                     & "C:\Work\GitHub\audio-analysis\AudioAnalysis\AnalysisPrograms\bin\Release\AnalysisPrograms.exe"  = runs an executable
                     audio2csv = first command line argument which determines the "activity" performed
                     -so ($_.FullName)  = the input file
                     -o "Y:\Italy_GianniPavan\output" = the output directory
                     -c "PATH\Towsey.Acoustic.Parallel.yml" is the config file
            
             The following PowerShell command was used by Anthony to stitch together a sequence of spectrogam images without any gap between them.
             It requires ImageMagick software to be installed: i.e. C:\Program Files\ImageMagick-6.8.9-Q16\montage.exe
             Y:\Italy_GianniPavan\output\Towsey.Acoustic> & "C:\Program Files\ImageMagick-6.8.9-Q16\montage.exe" -mode concatenate -tile x1 *2MAP* "..\..\merge.png"
             ]]></code>
            
             (2) ConcatenateSpectralIndexFiles()
             This method was written to deal with a new recording protocol in which 24 hours of recording are made in 4 blocks of 6 hours each.
             It merges all files of acoustic indices derived from a sequence of consecutive 6 hour recording, into one file. It then creates the images.
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramStitching.DrawSpectralIndexFiles(System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]},AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig,AudioAnalysisTools.Indices.IndexGenerationData,System.IO.FileInfo,System.IO.DirectoryInfo,AudioAnalysisTools.SiteDescription,System.IO.FileInfo,System.Collections.Generic.List{AudioAnalysisTools.Indices.GapsAndJoins})">
            <summary>
            ONLY Use this concatenation method when you want to concatenate the files for a fixed single day.
            The files to be concatenated must be somewhere in the subdirectory structure of the passed list of data directories
            Read them into a dictionary
            MOST RECENT METHOD TO CONCATENATE Spectral INDEX.CSV FILES - Early September 2015.
            It is designed to deal with Yvonne's case where want to concatenate files distributed over arbitrary directories.
            It only merges files for the passed fixed date. i.e only 24 hours.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramStitching.ConcatenateAllSpectralIndexFiles(System.IO.DirectoryInfo[],System.String[],AudioAnalysisTools.Indices.IndexGenerationData)">
            <summary>
            RECENT METHOD TO CONCATENATE Spectral INDEX.CSV FILES - August 2015. Revised Septermber 2016
            Was written to deal with  EDDIE GAME PNG data where the files to be concatenated are all in one top level directory.
            This method merges all files of spectral indices in the passed directories.
            The total length of the concatenated files can exceed 24 hours - limited by memory!.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramStitching.ConcatenateAllSummaryIndexFiles(System.IO.FileInfo[],System.IO.DirectoryInfo,AudioAnalysisTools.Indices.IndexGenerationData,System.String)">
            <summary>
            Joins summary indices csv files together.
            This method merges ALL the passed files of acoustic indices
            It is assumed you are concatenating a sequence of consecutive short recordings.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramStitching.StitchPartialSpectrograms">
             <summary>
             This method stitches together spectrogram images derived from consecutive shorter recordings over a 24 hour period.
             Currently set for the recording protocol of Gianna Pavan (10 minutes every 30 minutes).
            
             Call this method from Sandpit or where ever!
            
             IMPORTANT NOTE: This method does NOT check to see if the images are in temporal order.
                             A SORT line should be inserted somewhere.
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramTStatistic.DrawTStatisticThresholdedDifferenceSpectrograms(System.IO.DirectoryInfo,System.IO.FileInfo,System.IO.FileInfo,System.IO.FileInfo,System.IO.FileInfo,System.IO.DirectoryInfo)">
            <summary>
            This method compares the acoustic indices derived from two different long duration recordings of the same length.
            It takes as input six csv files of acoustic indices in spectrogram columns, three csv files for each of the original recordings to be compared.
            The method produces four spectrogram image files:
            1) A triple image. Top:    The spectrogram for index 1, recording 1.
                               Middle: The spectrogram for index 1, recording 2.
                               Bottom: A t-statistic thresholded difference spectrogram for INDEX 1 (derived from recordings 1 and 2).
            2) A triple image. Top:    The spectrogram for index 2, recording 1.
                               Middle: The spectrogram for index 2, recording 2.
                               Bottom: A t-statistic thresholded difference spectrogram for INDEX 2 (derived from recordings 1 and 2).
            3) A triple image. Top:    The spectrogram for index 3, recording 1.
                               Middle: The spectrogram for index 3, recording 2.
                               Bottom: A t-statistic thresholded difference spectrogram for INDEX 3 (derived from recordings 1 and 2).
            4) A double image. Top:    A t-statistic thresholded difference spectrogram (t-statistic is positive).
                               Bottom: A t-statistic thresholded difference spectrogram (t-statistic is negative).
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramTStatistic.DrawTStatisticSpectrogram(System.Double[0:,0:])">
            <summary>
            double tStatThreshold = 1.645; // 0.05% confidence @ df=infinity
            double[] table_df_inf = { 0.25, 0.51, 0.67, 0.85, 1.05, 1.282, 1.645, 1.96, 2.326, 2.576, 3.09, 3.291 };
            double[] table_df_15 =  { 0.26, 0.53, 0.69, 0.87, 1.07, 1.341, 1.753, 2.13, 2.602, 2.947, 3.73, 4.073 };
            double[] alpha =        { 0.40, 0.30, 0.25, 0.20, 0.15, 0.10,  0.05,  0.025, 0.01, 0.005, 0.001, 0.0005 }.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.TimeOffsetSingleLayerSuperTile.DurationToPreviousTileBoundaryAtUnitScale">
            <summary>
            Gets the duration between the start of the visualization and the start of the recording.
            When the recording start date aligns perfectly with an tile, this value should be zero.
            In all other cases, it is the closest, previous, tile boundary, at the unit scale
            (the most zoommed out scale). This is the represents the time that is rendered with
            transparency (for low resolutions) or just not rendered (for high resolutions).
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.TimeOffsetSingleLayerSuperTile.TimeOffset">
            <summary>
            Gets the duration between this super tile and the start of the recording.
            For the first super tile it should be 0.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.Zooming.SpectrogramZoomingConfig.LdSpectrogramConfig">
            <summary>
            Gets or sets an optional reference to a config that defines
            the style for drawing LD spectrograms.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.Zooming.SpectrogramZoomingConfig.UseDistributionsForNormalization">
            <summary>
            Gets or sets a value indicating whether or not to render images using distributions (rather than index properties).
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.Zooming.SpectrogramZoomingConfig.MaxTilesPerSuperTile">
            <summary>
            Gets or sets MaxTilePerSuperTile.
            Controls how large the super tiles are.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.Zooming.SpectrogramZoomingConfig.SpectralFrameScale">
            <summary>
            Gets or sets get or sets the number of zoom levels to render for standard FFT spectrogram images.
            Should contain about 1-3 steps following an inverse base-2 power distribution.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.LongDurationSpectrograms.Zooming.SpectrogramZoomingConfig.SpectralIndexScale">
            <summary>
            Gets or sets get or sets the number of zoom levels for index based images.
            Should contain about 11-12 steps following an inverse base-2 power distribution.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.Zooming.ZoomParameters.CheckNeededFilesExist(System.IO.DirectoryInfo)">
            <summary>
            Read in required files.
            We expect a valid indices output directory (the input directory in this action)
            to contain a SpectralIndexStatistics.json and a IndexGenerationData.json file.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.Zooming.ZoomTiledSpectrograms.DrawTiles(Acoustics.Shared.AnalysisIoInputDirectory,AudioAnalysisTools.LongDurationSpectrograms.Zooming.ZoomParameters,System.String)">
            <summary>
            THIS IS ENTRY METHOD FOR TILING SPECTROGRAMS.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.Zooming.ZoomTiledSpectrograms.GenerateIndexSpectrogramTiles(System.Double[],AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig,System.Collections.Generic.Dictionary{System.String,AudioAnalysisTools.Indices.IndexProperties},AudioAnalysisTools.LongDurationSpectrograms.Zooming.SpectrogramZoomingConfig,System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]},AudioAnalysisTools.Indices.IndexGenerationData,System.String,AudioAnalysisTools.TileImage.TilingProfile,AudioAnalysisTools.TileImage.Tiler,System.TimeSpan)">
            <summary>
            Derives false colour varying-resolution multi-index spectrograms from provided spectral indices.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.Zooming.ZoomTiledSpectrograms.CombineFrameDataWithIndexData(System.Double[0:,0:],System.Double[0:,0:],System.Double,System.Double)">
            <summary>
            THis method is a way of getting the acoustic index data at 0.2 second resolution to have some influence on the
                frame spectrograms at 0.02s resolution.
                We cannot assume that the two matrices will have the same number of columns i.e. same temporal duration.
                The frame data has been padded to one minute duration. But the last index matrix will probably NOT be the full one
                minute duration.
                Therefore assume that indexData matrix will be shorter and take its column count.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.Zooming.ZoomTiledSpectrograms.DrawSuperTilesAtScaleFromIndexSpectrograms(AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig,System.Collections.Generic.Dictionary{System.String,AudioAnalysisTools.Indices.IndexProperties},AudioAnalysisTools.LongDurationSpectrograms.Zooming.SpectrogramZoomingConfig,System.TimeSpan,System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]},AudioAnalysisTools.Indices.IndexGenerationData,System.String,Acoustics.Shared.ImageChrome,System.TimeSpan)">
            <summary>
            Draws FC index spectrograms for an entire row.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.Zooming.ZoomTiledSpectrograms.DrawSuperTilesFromSingleFrameSpectrogram(System.IO.DirectoryInfo,AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig,System.Collections.Generic.Dictionary{System.String,AudioAnalysisTools.Indices.IndexProperties},AudioAnalysisTools.LongDurationSpectrograms.Zooming.SpectrogramZoomingConfig,System.Int32,System.Double[],System.String,AudioAnalysisTools.Indices.IndexGenerationData,Acoustics.Shared.ImageChrome,System.TimeSpan)">
            <summary>
            Assume that we are processing data for one minute only.
                From this one minute of data, we produce images at three scales.
                A one minute recording framed at 20ms should yield 3000 frames.
                But to achieve this where sr= 22050 and frameSize=512, we need an overlap of 71 samples.
                Consequently only 2999 frames returned per minute.
                Therefore have to pad end to get 3000 frames.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.Zooming.ZoomTiledSpectrograms.PadEndOfListOfFrames(System.Collections.Generic.List{System.Double[]},System.Int32)">
            <summary>
            THis method pads the end of a list of frames read from a csv file.
                The frame count will be one less than expected for the recording segment because of frame overlap
                Therefore pad the end of the list of frames with the last frame.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.Zooming.ZoomTiledSpectrograms.TrimEndOfListOfFrames(System.Collections.Generic.List{System.Double[]},System.Int32)">
            <summary>
            THis method trims the end of a list of frames read from a csv file.
                Sometimes inaccuracies in cutting audio produced frame counts that are too long.
                Therefore too many columns are rendered. Simply remove the end frames and issue a warning.
            TODO: a better solution would be to interpolate the extra frames... but too hard at the moment.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.ZoomFocusedSpectrograms.DrawIndexSpectrogramAtScale(AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig,AudioAnalysisTools.Indices.IndexGenerationData,System.Collections.Generic.Dictionary{System.String,AudioAnalysisTools.Indices.IndexProperties},System.TimeSpan,System.TimeSpan,System.TimeSpan,System.Int32,System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]},System.String)">
            <summary>
            This method can add in absolute time if you want.
            Currently commented out - see below.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.ZoomFocusedSpectrograms.DrawFrameSpectrogramAtScale(AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig,AudioAnalysisTools.Indices.IndexGenerationData,System.TimeSpan,System.Int32,System.Collections.Generic.List{System.Double[]},System.Double[0:,0:],System.TimeSpan,System.TimeSpan,System.Int32)">
            <summary>
            This method can add in the absolute recording start time. However currently disabled.
            </summary>
            <param name="config">v.</param>
            <param name="indexGenerationData">indexGenerationData.</param>
            <param name="startTimeOfData">startTimeOfData.</param>
            <param name="compressionFactor">compressionFactor.</param>
            <param name="frameData">frameData.</param>
            <param name="indexData">indexData.</param>
            <param name="focalTime">focalTime.</param>
            <param name="frameScale">frameScale.</param>
            <param name="imageWidth">imageWidth.</param>
        </member>
        <member name="M:AudioAnalysisTools.LongDurationSpectrograms.ZoomFocusedSpectrograms.DrawStandardSpectrogramInFalseColour(System.Double[0:,0:])">
            <summary>
            A FALSE-COLOUR VERSION OF DECIBEL SPECTROGRAM
                    Taken and adapted from Spectrogram Image 5 in the method of CLASS Audio2InputForConvCNN.cs:.
            </summary>
            <param name="dbSpectrogramData">the sonogram data (NOT noise reduced). </param>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2010.Execute(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.Boolean,System.Int32,System.Int32,System.Double,System.Double,System.Boolean,System.Int32,System.Int32,System.Double,System.Double,System.Double,System.Double[]@,System.Collections.Generic.List{AudioAnalysisTools.AcousticEvent}@,System.Double[0:,0:]@,System.Double[]@,System.TimeSpan@)">
            <summary>
            FINDS OSCILLATIONS IN A SONOGRAM
            But first it segments the sonogram based on acoustic energy in freq band of interest.
            </summary>
            <param name="sonogram">sonogram derived from the recording.</param>
            <param name="minHz">min bound freq band to search.</param>
            <param name="maxHz">max bound freq band to search.</param>
            <param name="dctDuration">duration of DCT in seconds.</param>
            <param name="dctThreshold">minimum amplitude of DCT. </param>
            <param name="minOscilFreq">ignore oscillation frequencies below this threshold.</param>
            <param name="maxOscilFreq">ignore oscillation frequencies greater than this. </param>
            <param name="scoreThreshold">used for FP/FN.</param>
            <param name="minDuration">ignore hits whose duration is shorter than this.</param>
            <param name="maxDuration">ignore hits whose duration is longer than this.</param>
            <param name="scores">return an array of scores over the entire recording.</param>
            <param name="events">return a list of acoustic events.</param>
            <param name="hits">a matrix that show where there is an oscillation of sufficient amplitude in the correct range.
                               Values in the matrix are the oscillation rate. i.e. if OR = 2.0 = 2 oscillations per second. </param>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2010.DetectOscillationsInSonogram(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.Int32,System.Int32,System.Double,System.Double,System.Boolean,System.Double,System.Double,System.Collections.Generic.List{AudioAnalysisTools.AcousticEvent})">
            <summary>
            Detects oscillations in a given freq bin.
            there are several important parameters for tuning.
            a) dctDuration: Good values are 0.25 to 0.50 sec. Do not want too long because DCT requires stationarity.
                Do not want too short because too small a range of oscillations
            b) dctThreshold: minimum acceptable value of a DCT coefficient if hit is to be accepted.
                The algorithm is sensitive to this value. A lower value results in more oscillation hits being returned.
            c) Min and Max Oscillaitons: Sets lower &amp; upper bound for oscillations of interest.
                Array has same length as the length of the DCT. Low freq oscillations occur more often by chance. Want to exclude them.
            </summary>
            <param name="minHz">min freq bin of search band.</param>
            <param name="maxHz">max freq bin of search band.</param>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2010.DetectOscillationsInSonogram(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.Int32,System.Int32,System.Double,System.Double,System.Boolean,System.Int32,System.Int32,System.Collections.Generic.List{AudioAnalysisTools.AcousticEvent})">
            <summary>
            Calls the above method but converts integer oscillations rate to doubles.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2010.FillScoreArray(System.Double[],System.Double,System.Double)">
            <summary>
             fills the gaps in an array of scores.
            </summary>
            <param name="fillDuration">duration in seconds.</param>
            <param name="timeScale">frames per Second.</param>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2010.RemoveIsolatedOscillations(System.Double[0:,0:])">
            <summary>
            Removes single lines of hits from Oscillation matrix.
            </summary>
            <param name="matrix">the Oscillation matrix.</param>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2010.GetOscillationScores(System.Double[0:,0:],System.Int32,System.Int32,System.Double)">
            <summary>
            Converts the hits in the "hit matrix" derived from the oscilation detector into a score for each frame.
            Score is normalised - the fraction of bins in the correct frequncy band that have an oscilation hit.
            </summary>
            <param name="hits">sonogram as matrix showing location of oscillation hits.</param>
            <param name="minHz">lower freq bound of the acoustic event.</param>
            <param name="maxHz">upper freq bound of the acoustic event.</param>
            <param name="freqBinWidth">the freq scale required by AcousticEvent class.</param>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2010.GetOscillationFrequency(System.Double[0:,0:],System.Int32,System.Int32,System.Double)">
            <summary>
            for each frame, returns the average oscilation rate for those freq bins that register a hit.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2010.ConvertODScores2Events(System.Double[],System.Double[],System.Int32,System.Int32,System.Double,System.Double,System.Int32,System.Double,System.Double,System.Double,System.String,System.TimeSpan)">
            <summary>
            Converts the Oscillation Detector score array to a list of AcousticEvents.
            NOTE: Method assumes passed score array was normalised.
            See the CousticEvent class for a generic version of this method.
            </summary>
            <param name="scores">the array of OD scores.</param>
            <param name="minHz">lower freq bound of the acoustic event.</param>
            <param name="maxHz">upper freq bound of the acoustic event.</param>
            <param name="framesPerSec">the time scale required by AcousticEvent class.</param>
            <param name="freqBinWidth">the freq scale required by AcousticEvent class.</param>
            <param name="scoreThreshold">OD score must exceed this threshold to count as an event.</param>
            <param name="minDuration">duration of event must exceed this to count as an event.</param>
            <param name="maxDuration">duration of event must be less than this to count as an event.</param>
            <param name="fileName">name of source file to be added to AcousticEvent class.</param>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2010.PeriodicityAnalysis(System.Double[])">
            <summary>
            returns the periodicity in an array of values.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.Oscillations2012">
             <summary>
             NOTE: 21st June 2012.
            
             This class contains methods to detect oscillations in a the sonogram of an audio signal.
             The method Execute() returns all info about oscillations in the passed sonogram.
             This method should be called in preference to those in the class OscillationAnalysis.
             (The latter should be deprecated.)
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2012.DetectOscillations(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.Int32,System.Int32,System.Double,System.Int32,System.Int32,System.Double)">
            <summary>
            Detects oscillations in a given freq bin.
            there are several important parameters for tuning.
            a) DCTLength: Good values are 0.25 to 0.50 sec. Do not want too long because DCT requires stationarity.
                Do not want too short because too small a range of oscillations
            b) DCTindex: Sets lower bound for oscillations of interest. Index refers to array of coefficient returned by DCT.
                Array has same length as the length of the DCT. Low freq oscillations occur more often by chance. Want to exclude them.
            c) MinAmplitude: minimum acceptable value of a DCT coefficient if hit is to be accepted.
                The algorithm is sensitive to this value. A lower value results in more oscillation hits being returned.
            </summary>
            <param name="sonogram">A spectrogram.</param>
            <param name="minHz">min freq bin of search band.</param>
            <param name="maxHz">max freq bin of search band.</param>
            <param name="dctDuration">number of values.</param>
            <param name="minOscilFreq">minimum oscillation freq.</param>
            <param name="maxOscilFreq">maximum oscillation freq.</param>
            <param name="dctThreshold">threshold - do not accept a DCT coefficient if its value is less than this threshold.</param>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2012.RemoveIsolatedOscillations(System.Double[0:,0:])">
            <summary>
            Removes single lines of hits from Oscillation matrix.
            </summary>
            <param name="matrix">the Oscillation matrix.</param>
            <returns>a matrix.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2012.GetOscillationScores(System.Double[0:,0:],System.Int32,System.Int32,System.Double)">
            <summary>
            Converts the hits derived from the oscillation detector into a score for each frame.
            NOTE: The oscillation detector skips every second row, so score must be adjusted for this.
            </summary>
            <param name="hits">sonogram as matrix showing location of oscillation hits.</param>
            <param name="minHz">lower freq bound of the acoustic event.</param>
            <param name="maxHz">upper freq bound of the acoustic event.</param>
            <param name="freqBinWidth">the freq scale required by AcousticEvent class.</param>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2012.ConvertOscillationScores2Events(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.Double[],System.Int32,System.Int32,System.Double,System.Double,System.Double,System.TimeSpan)">
            <summary>
            Converts the Oscillation Detector score array to a list of Oscillation Events.
            </summary>
            <param name="scores">the array of OD scores.</param>
            <param name="minHz">lower freq bound of the acoustic event.</param>
            <param name="maxHz">upper freq bound of the acoustic event.</param>
            <param name="scoreThreshold">threshold.</param>
            <param name="minDurationThreshold">min threshold.</param>
            <param name="maxDurationThreshold">max threshold.</param>
            <param name="segmentStartOffset">time offset.</param>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2012.CalculateRequiredFrameOverlap(System.Int32,System.Int32,System.Double)">
            <summary>
            Calculates the optimal frame overlap for the given sample rate, frame width and max oscillation or pulse rate.
            Pulse rate is determined using a DCT and efficient use of the DCT requires that the dominant pulse sit somewhere 3.4 along the array of coefficients.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.Oscillations2014">
             <summary>
             This is the latest of three implementations to detect oscillations in a spectrogram.
             This implementation is generic, that is, it attempts to find any and all oscillations in each of the
             frequency bins of a short duration spectorgram.
            
             There are three versions of the generic algorithm implemented in three different methods:
             1) uses auto-correlation, then FFT
             2) uses auto-correlation, then singular value decomposition, then FFT
             3) uses wavelets
            
             I gave up on wavelets after some time. Might work with persistence!
             Singular value decomposition is used as a filter to select the dominant oscillations in the audio segment against noise.
            
             The Oscillations2012 class uses the DCT to find oscillations. It works well when the sought oscillation rate is known
             and the DCT can be tuned to find it. It works well, for example, to find canetoad calls.
             However it did not easily extend to finding generic oscillations.
            
             Oscillations2014 therefore complements the Oscillations2012 class but does not replace it.
            
             </summary>
        </member>
        <member name="T:AudioAnalysisTools.Oscillations2014.FreqVsOscillationsResult">
            <summary>
            In line class used to return results from the static method Oscillations2014.GetFreqVsOscillationsDataAndImage().
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2014.TESTMETHOD_GetSpectralIndex_Osc">
            <summary>
            test method for getting a spectral index of oscillation values.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2014.GenerateOscillationDataAndImages(System.IO.FileInfo,System.Collections.Generic.Dictionary{System.String,System.String},System.Boolean)">
            <summary>
            Generates the FREQUENCY x OSCILLATIONS Graphs and csv
            I have experimented with five methods to search for oscillations:
             1: string algorithmName = "Autocorr-FFT";
                use this if want more detailed output - but not necessrily accurate!
             2: string algorithmName = "Autocorr-SVD-FFT";
                use this if want only dominant oscillations
             3: string algorithmName = "Autocorr-Cwt";
                a Wavelets option but could not get it to work well
             4: string algorithmName = "Autocorr-WPD";
                another Wavelets option but could not get it to work well
             5: Discrete Cosine Transform
                The DCT only works well when you know which periodicity you are looking for. e.g. Canetoad.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2014.GetFreqVsOscillationsDataAndImage(AudioAnalysisTools.StandardSpectrograms.BaseSonogram,System.String)">
            <summary>
            Only call this method for short recordings.
            If accumulating data for long recordings then call the method for long recordings - i.e.
            double[] spectralIndex = GenerateOscillationDataAndImages(FileInfo audioSegment, Dictionary configDict, false, false).
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2014.GetFreqVsOscillationsImage(System.Double[0:,0:],System.Double,System.Double,System.Int32,System.String)">
            <summary>
            Creates an image from the frequency/oscillations matrix.
            The y-axis scale = frequency bins as per normal spectrogram.
            The x-axis scale is oscillations per second.
            </summary>
            <param name="freqOscilMatrix">the input frequency/oscillations matrix.</param>
            <param name="framesPerSecond">to give the time scale.</param>
            <param name="freqBinWidth">to give the frequency scale.</param>
            <param name="sampleLength">to allow calculation of the oscillations scale.</param>
            <param name="algorithmName">the algorithm used to compute the oscillations.</param>
            <returns>bitmap image.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2014.GetXcorrByTimeMatrix(System.Double[],System.Int32)">
            <summary>
            Returns a matrix whose columns consist of autocorrelations of freq bin samples.
            The columns are non-overlapping.
            </summary>
            <param name="signal">an array corresponding to one frequency bin.</param>
            <param name="sampleLength">the length of a sample or patch (non-overllapping) for which xcerrelation is obtained.</param>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2014.GetOscillationArrayUsingSvdAndFft(System.Double[0:,0:],System.Double,System.Int32)">
            <summary>
             reduces the sequence of Xcorrelation vectors to a single summary vector.
             Does this by:
             (1) do SVD on the collection of XCORRELATION vectors
             (2) select the dominant ones based on the eigen values - 90% threshold
                 Typically there are 1 to 10 eigen values depending on how busy the bin is.
             (3) Do an FFT on each of the returned SVD vectors to pick the dominant oscillation rate.
             (4) Accumulate the oscillations in a freq by oscillation rate matrix.
                 The amplitude value for the oscillation is the eigenvalue.
            #
             NOTE: There should only be one dominant oscillation in any one freq band at one time.
                   Birds with oscillating calls do call simultaneously, but this technique will only pick up the dominant call.
            #.
            </summary>
            <param name="xCorrByTimeMatrix">double[,] xCorrelationsByTime = new double[sampleLength, sampleCount]. </param>
            <param name="sensitivity">can't remember what this does.</param>
            <param name="binNumber">only used when debugging.</param>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2014.GetOscillationArrayUsingFft(System.Double[0:,0:],System.Double)">
            <summary>
            returns an oscillation array for a single frequency bin.
            </summary>
            <param name="xCorrByTimeMatrix">derived from single frequency bin.</param>
            <param name="sensitivity">a threshold used to ignore low ascillation intensities.</param>
            <returns>vector of oscillation values.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2014.GetOscillationUsingDct(System.Double[],System.Double,System.Double[0:,0:],System.Double@,System.Double@,System.Double@)">
            <summary>
            returns oscillations using the DCT.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2014.AdjustSampleSize(System.Int32,System.Int32)">
            <summary>
             Adjusts sample length i.e. patch size for short recordings.
            </summary>
            <param name="framecount">number of frames in the frequency bin to be processed.</param>
            <param name="sampleLength">the number of frames to be included in each patch.</param>
            <returns>appropriately reduced patch size.</returns>
        </member>
        <member name="T:AudioAnalysisTools.Oscillations2019">
             <summary>
             NOTE: 26th October 2019.
            
             This class contains methods to detect oscillations in a the spectrogram of an audio signal.
             The method Execute() returns all info about oscillations in the passed spectrogram.
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.Oscillations2019.DetectOscillations(System.Double[],System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double[]@,System.Double[]@)">
            <summary>
            Currently this method is called by only one species recognizer - LitoriaCaerulea.
            </summary>
            <param name="ipArray">an array of decibel values.</param>
            <param name="framesPerSecond">the frame rate.</param>
            <param name="decibelThreshold">Ignore frames below this threshold.</param>
            <param name="dctDuration">Duration in seconds of the required DCT.</param>
            <param name="minOscFreq">minimum oscillation frequency.</param>
            <param name="maxOscFreq">maximum oscillation frequency.</param>
            <param name="dctThreshold">Threshold for the maximum DCT coefficient.</param>
            <param name="dctScores">an array of dct scores.</param>
            <param name="oscFreq">an array of oscillation frequencies.</param>
        </member>
        <member name="T:AudioAnalysisTools.PointOfInterest">
            <summary>
            The point of interest.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.PointOfInterest.TemplateColor">
            <summary>
            The anchor color.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.PointOfInterest.DefaultBorderColor">
            <summary>
            The default border color.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.PointOfInterest.HitsColor">
            <summary>
            The hits color.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.PointOfInterest.#ctor(SixLabors.ImageSharp.Point)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.PointOfInterest"/> class.
            </summary>
            <param name="point">
            The point to represent.
            </param>
        </member>
        <member name="P:AudioAnalysisTools.PointOfInterest.Point">
            <summary>
            Gets or sets the point.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.PointOfInterest.TimeLocation">
            <summary>
            Gets or sets the X-axis timescale seconds per pixel.
            </summary>
            <summary>
            Gets or sets the time of the point of interest from beginning of recording.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.PointOfInterest.Hertz">
            <summary>
            Gets or sets the frequency location of point of interest.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.PointOfInterest.TimeScale">
            <summary>
            Gets or sets the X-axis timescale seconds per pixel.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.PointOfInterest.HerzScale">
            <summary>
            Gets or sets the Y-axis scale herz per pixel.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.PointOfInterest.fftMatrix">
            <summary>
            Gets or sets the matrix of fft.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.PointOfInterest.DrawColor">
            <summary>
            Gets or sets the draw color.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.PointOfInterest.Intensity">
            <summary>
            Gets or sets the spectral intensity at the given point.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.PointOfInterest.RidgeMagnitude">
            <summary>
            Gets or sets the Ridge Magnitude at the given point.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.PointOfInterest.RidgeOrientation">
            <summary>
            Gets or sets the Local Ridge Orientation.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.PointOfInterest.OrientationCategory">
            <summary>
            Gets or sets the Local Ridge Orientation.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.PointOfInterest.IsLocalMaximum">
            <summary>
            Gets or sets a value indicating whether gets or sets boolean - is POI a local maximum?.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.PointOfInterest.DrawBox(SixLabors.ImageSharp.Processing.IImageProcessingContext,System.Collections.Generic.IEnumerable{AudioAnalysisTools.PointOfInterest},System.Int32)">
            <summary>
            Draw a box from a point at top left with radius width and radius length.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.PointOfInterest.DrawRefinedOrientationPoint(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},System.Int32)">
            <summary>
            Currently, I can only refine the ridge orientation up to 12 possibilities.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.Scales.LinearScale">
            <summary>
            A class that converts between two linear ranges.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Scales.LinearScale.#ctor(System.ValueTuple{System.Double,System.Double},System.ValueTuple{System.Double,System.Double})">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.Scales.LinearScale"/> class.
            </summary>
            <remarks>
            Should be able to handle mapping a domain where x1 â‰¤ x &lt; x2
            to a range where y1 > y â‰¥ y2 (an inverted mapping).
            </remarks>
            <param name="domain">The range to consider the domain (the input).</param>
            <param name="range">The range to consider the range (the output).</param>
        </member>
        <member name="M:AudioAnalysisTools.Scales.LinearScale.#ctor(System.ValueTuple{System.Double,System.Double},System.ValueTuple{System.Double,System.Double},System.Boolean)">
            <inheritdoc cref="!:LinearScale.LinearScale((double Low, double High), (double Low, double High))"/>
            <remarks>
            If <paramref name="clamp"/> is <value>true</value> then round-tripping of values is not supported.
            </remarks>
            <param name="clamp">Whether or not to clamp the values to the end points.</param>
        </member>
        <member name="M:AudioAnalysisTools.Scales.LinearScale.To(System.Double)">
            <summary>
            Converts a value from the domain into its range equivalent.
            </summary>
            <param name="x">The domain value.</param>
            <returns>The equivalent range value.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Scales.LinearScale.ToMagnitude(System.Double)">
            <summary>
            Converts a domain magnitude into a range magnitude.
            </summary>
            <param name="xMagnitude">The domain magnitude.</param>
            <returns>The equivalent range magnitude.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Scales.LinearScale.From(System.Double)">
            <summary>
            Converts a value from the range into its domain equivalent.
            </summary>
            <param name="y">The range value.</param>
            <returns>The equivalent domain value.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Scales.LinearScale.FromMagnitude(System.Double)">
            <summary>
            Converts a range magnitude into a domain magnitude.
            </summary>
            <param name="yMagnitude">The range magnitude.</param>
            <returns>The equivalent domain magnitude.</returns>
        </member>
        <member name="T:AudioAnalysisTools.ISignalToImage">
            <summary>
            Interface for converting signal represented by bytes into an image.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ISignalToImage.Waveform(System.Byte[],System.Int32,System.Int32)">
            <summary>
            Generate a Waveform.
            </summary>
            <param name="bytes">
            The bytes.
            </param>
            <param name="width">
            The width.
            </param>
            <param name="height">
            The height.
            </param>
            <returns>
            Waveform image.
            </returns>
        </member>
        <member name="M:AudioAnalysisTools.ISignalToImage.Spectrogram(System.Byte[])">
            <summary>
            Generate a Spectrogram.
            </summary>
            <param name="bytes">
            The bytes.
            </param>
            <returns>
            Spectrogram image.
            </returns>
        </member>
        <member name="T:AudioAnalysisTools.TowseySignalToImage">
            <summary>
            Mike Towsey's implementation.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.TowseySignalToImage.Waveform(System.Byte[],System.Int32,System.Int32)">
            <summary>
            Generate a Waveform.
            </summary>
            <param name="bytes">
            The bytes.
            </param>
            <param name="width">
            The width.
            </param>
            <param name="height">
            The height.
            </param>
            <returns>
            Waveform image.
            </returns>
        </member>
        <member name="M:AudioAnalysisTools.TowseySignalToImage.Spectrogram(System.Byte[])">
            <summary>
            Generate a Spectrogram.
            </summary>
            <param name="bytes">
            The bytes.
            </param>
            <returns>
            Spectrogram image.
            </returns>
            <exception cref="T:System.NotSupportedException"><c>NotSupportedException</c>.</exception>
        </member>
        <member name="T:AudioAnalysisTools.WebSignalToImage">
            <summary>
            Signal to Image used by web site.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.WebSignalToImage.WindowOverlap">
            <summary>
            Window overlap of 0, framesize of 512, samplerate of 22050.
            1 pixel for every 23.22 ms.
            </summary>
        </member>
        <member name="F:AudioAnalysisTools.WebSignalToImage.Hamming">
            <summary>
            Hamming window function.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.Waveform(System.Byte[],System.Int32,System.Int32)">
            <summary>
            Generate a Waveform.
            </summary>
            <param name="bytes">
            The bytes.
            </param>
            <param name="width">
            The width.
            </param>
            <param name="height">
            The height.
            </param>
            <returns>
            Waveform image.
            </returns>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.Spectrogram(System.Byte[])">
            <summary>
            Generate a Spectrogram.
            </summary>
            <param name="bytes">
            The bytes.
            </param>
            <returns>
            Spectrogram image.
            </returns>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.GetSpectrogram(Acoustics.Tools.Wav.IWavReader,System.Int32)">
            <summary>
            Get a spectrogram.
            Channel must be > 0.
            </summary>
            <param name="reader">Wav Reader.</param>
            <param name="channel">Channel number.</param>
            <returns>Spectrogram image.</returns>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.SubSample(System.Double[],System.Int32,System.Int32)">
            <summary>
            Subsamples audio.
            </summary>
            <param name="samples">
            The samples.
            </param>
            <param name="currentSampleRate">
            The current Sample Rate.
            </param>
            <param name="targetSampleRate">
            The target Sample Rate.
            </param>
            <returns>
            The sub sample.
            </returns>
            <exception cref="T:System.InvalidOperationException">
            <c>InvalidOperationException</c>.
            </exception>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.FrameStartEnds(System.Int32,System.Int32,System.Double)">
            <summary>
            Returns the start and end index of all frames in a long audio signal.
            </summary>
            <param name="dataLength">
            The data Length.
            </param>
            <param name="windowSize">
            The window Size.
            </param>
            <param name="windowOverlap">
            The window Overlap.
            </param>
            <exception cref="T:System.ArgumentException">
            Signal must produce at least two frames!.
            </exception>
            <returns>
            The frame start ends.
            </returns>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.CalcuateWindowWeights(System.Int32,System.Func{System.Int32,System.Int32,System.Double})">
            <summary>
            Calcuate window weights.
            </summary>
            <param name="windowSize">
            The window Size.
            </param>
            <param name="windowFunction">
            The window Function.
            </param>
            <exception cref="T:System.ArgumentNullException">
            <paramref name="windowFunction"/> is <c>null</c>.
            </exception>
            <exception cref="T:System.ArgumentException">
            WindowSize must be a power of 2.
            </exception>
            <returns>
            The window weights.
            </returns>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.IsPowerOf2(System.Int32)">
            <summary>
            Is <paramref name="number"/> a power of 2.
            </summary>
            <param name="number">
            The number.
            </param>
            <returns>
            True if <paramref name="number"/> is a power of 2.
            </returns>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.InvokeDotNetFft(System.Double[],System.Int32,System.Int32,System.Double[])">
            <summary>
            This .NET FFT library was downloaded from  http://www.mathdotnet.com/Iridium.aspx.
            The documentation and various examples of code are available at http://www.mathdotnet.com/doc/IridiumFFT.ashx.
            </summary>
            <param name="data">
            signal samples.
            </param>
            <param name="windowSize">
            The window Size.
            </param>
            <param name="coeffCount">
            The coeff Count.
            </param>
            <param name="windowWeights">
            The window Weights.
            </param>
            <returns>
            Transformed samples.
            </returns>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.DecibelSpectra(System.Double[0:,0:],System.Double,System.Int32,System.Double)">
            <summary>
            Converts spectral amplitudes directly to dB, normalising for window power and sample rate.
            NOTE 1: The window contributes power to the signal which must subsequently be removed from the spectral power.
            NOTE 2: Spectral power must be normaliesd for sample rate. Effectively calculate freq power per sample.
            NOTE 3: The power in all freq bins except f=0 must be doubled because the power spectrum is an even function about f=0;
                    This is due to the fact that the spectrum actually consists of 512 + 1 values, the centre value being for f=0.
            NOTE 4: The decibels value is a ratio. Here the ratio is implied.
                    dB = 10*log(amplitude ^2) but in this method adjust power to account for power of Hamming window and SR.
            NOTE 5: THIS METHOD ASSUMES THAT THE LAST BIN IS THE NYQUIST FREQ BIN.
            </summary>
            <param name="amplitudeM">the amplitude spectra.</param>
            <param name="windowPower">value for window power normalisation.</param>
            <param name="sampleRate">to NormaliseMatrixValues for the sampling rate.</param>
            <param name="epsilon">small value to avoid log of zero.</param>
            <returns>Decibel Spectra.</returns>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.CalculateModalNoise(System.Double[0:,0:])">
             <summary>
             Calculates the modal noise value for each freq bin.
             Does so using a series of overlapped matrices.
             TODO!!!! COULD SIMPLY THIS METHOD. JUST CALCULATE MODE FOR EACH FREQ BIN WITHOUT OVERLAP ....
             .... AND THEN APPLY MORE SEVERE SMOOTHING TO THE MODAL NOISE PROFILE IN PREVIOUS METHOD.
            
             COMPARE THIS METHOD WITH SNR.SubtractModalNoise().
             </summary>
             <param name="matrix">Audio sample matrix.</param>
             <returns>Modal noise values.</returns>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.Submatrix(System.Double[0:,0:],System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Returns the submatrix of passed matrix.
            Assume that RowTop less than RowBottom, ColumnLeft less than ColumnRight.
            Row, column indices start at 0.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.Histo(System.Double[0:,0:],System.Int32,System.Double,System.Double,System.Double)">
             <summary>
            
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.FilterMovingAverage(System.Double[],System.Int32)">
            <summary>
            Filter Moving Average.
            </summary>
            <param name="signal">Audio signal.</param>
            <param name="width">Given width.</param>
            <returns>Filtered moving average.</returns>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.FilterMovingAverage(System.Int32[],System.Int32)">
            <summary>
            wrapper so one can call moving average filter with array of int.
            </summary>
            <param name="signal">Audio signal.</param>
            <param name="width">Given Width.</param>
            <returns>filtered signal.</returns>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.GetMaxIndex(System.Double[],System.Int32@)">
            <summary>
            returns the index of max value in an array of doubles.
            array index starts at zero.
            </summary>
            <param name="data">audio data.</param>
            <param name="indexMax">maximum index.</param>
        </member>
        <member name="M:AudioAnalysisTools.WebSignalToImage.GetImage(System.Double[0:,0:])">
            <summary>
            Get image.
            </summary>
            <param name="data">
            transformed data.
            </param>
            <returns>
            the image.
            </returns>
        </member>
        <member name="P:AudioAnalysisTools.SiteDescription.SiteName">
            <summary>
            Gets or sets site name.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.SiteDescription.ProjectName">
            <summary>
            Gets or sets site name.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.SiteDescription.Latitude">
            <summary>
            Gets or sets latitude of the site.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.SiteDescription.Longitude">
            <summary>
            Gets or sets longitude of the site.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralClustering.GetTrainingDataForClustering(System.Double[0:,0:],AudioAnalysisTools.SpectralClustering.ClusteringParameters)">
            <summary>
            First convert spectrogram to Binary using threshold. An amplitude threshold of 0.03 = -30 dB.   An amplitude threhold of 0.05 = -26dB.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralClustering.ClusterAnalysis(System.Collections.Generic.List{System.Double[]},System.Double,System.Int32,System.Boolean[])">
            <summary>
            Clusters the spectra in a spectrogram. USED to determine the spectral diversity and persistence of spectral types.
            The spectrogram is passed as a matrix. Note that the spectrogram is in amplitude values in [0, 1].
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralClustering.AssembleClusterSpectrogram(System.Double[0:,0:],System.Int32,AudioAnalysisTools.ClusterInfo,AudioAnalysisTools.SpectralClustering.TrainingDataInfo)">
            <summary>
            this method is used only to visualize the clusters and which frames they hit.
            Create a new spectrogram of same size as the passed spectrogram.
            Later on it is superimposed on a detailed spectrogram.
            </summary>
            <param name="spectrogram">spectrogram used to derive spectral richness indices. Orientation is row=frame.</param>
            <param name="lowerBinBound">bottom N freq bins are excluded because likely to contain traffic and wind noise.</param>
            <param name="clusterInfo">information about accumulated clusters.</param>
            <param name="data">training data.</param>
        </member>
        <member name="M:AudioAnalysisTools.SpectralClustering.OutputClusterAndWeightInfo(System.Int32[],System.Collections.Generic.List{System.Double[]},System.String)">
            <summary>
            displays a histogram of cluster counts.
            the argument clusters is an array of integer. Indicates cluster assigned to each binary frame.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralClustering.ClusterTheSpectra(System.Double[0:,0:],System.Int32,System.Int32,System.Double)">
            <summary>
            This CLUSTERING method is called only from IndexCalculate.cs
               and TESTMETHOD_SpectralClustering(string wavFilePath, string outputDir, int frameSize)
            It estimates the number of spectral clusters in a spectrogram,
            and outputs two summary indices: cluster count (also called spectral diversity) and the threegram count.
            IMPORTANT NOTE: The passed spectrogram MUST be already noise reduced.
            This clustering algorithm is a highly reduced version of binary ART, Adaptive resonance Theory, designed for speed.
            </summary>
            <param name="spectrogram">a collection of spectra that are to be clustered.</param>
            <param name="lowerBinBound">lower end of the bird-band.</param>
            <param name="upperBinBound">upper end of the bird-band.</param>
            <param name="binaryThreshold">used to convert real value spectrum to binary.</param>
        </member>
        <member name="M:AudioAnalysisTools.SpectralClustering.TESTMETHOD_SpectralClustering(System.String,System.String,System.Int32)">
            <summary>
            This method was set up as a TESTMETHOD in May 2017 but has not yet been debugged.
            It was transferred from Sandpit.cls. It is several years old.
            Updated May 2017.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralClustering.DrawClusterSpectrogram(AudioAnalysisTools.StandardSpectrograms.BaseSonogram,AudioAnalysisTools.ClusterInfo,AudioAnalysisTools.SpectralClustering.TrainingDataInfo,System.Int32)">
            <summary>
            Overlays the spectral cluster IDs on a spectrogram from which the clusters derived.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.ClusterInfo.#ctor(System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.ClusterInfo"/> class.
            CONSTRUCTOR
            The default or zero cluster info.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SprTools.SymbolDifference(System.Char,System.Char)">
            <summary>
            returns the angle difference between two angle symbols.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SprTools.CleanSymbolicTracks(System.Char[0:,0:])">
            <summary>
            Cleans up a symbolic matrix.
            Removes a symbol if it is isolated.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SprTools.CountTemplateChars(System.Char[0:,0:])">
            <summary>
            counts the symbols in an SPR template. Exclude the '-' char which is just background instaed of space.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.StandardSpectrograms.AmplitudeSonogram">
            <summary>
            This class is designed to produce a full-bandwidth spectrogram of spectral amplitudes
            The constructor calls the three argument BaseSonogram constructor.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.AmplitudeSonogram.Make(System.Double[0:,0:])">
            <summary>
            This method does nothing because do not want to change the amplitude sonogram in any way.
            Actually the constructor of this class calls the BaseSonogram constructor that does NOT include a call to Make().
            Consequently this method should never be called. Just a place filler.
            </summary>
            <param name="amplitudeM">amplitude sonogram.</param>
        </member>
        <member name="T:AudioAnalysisTools.StandardSpectrograms.AmplitudeSpectrogram">
            <summary>
            This class is designed to produce a full-bandwidth amplitude spectrogram.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.AmplitudeSpectrogram.#ctor(AudioAnalysisTools.StandardSpectrograms.SpectrogramSettings,Acoustics.Tools.Wav.WavReader)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.AmplitudeSpectrogram"/> class.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.AmplitudeSpectrogram.Data">
            <summary>
            Gets or sets the spectrogram data matrix of doubles.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.StandardSpectrograms.BaseSonogram">
            <summary>
            Base Sonogram.
            </summary>
            <summary>
            Partial class of BaseSonogram. This part of the class deals with drawing the sonogram.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.Configuration">
            <summary>
            Gets or sets the config information.
            The Configuration object should contain all the parameters required to construct an amplitude spectrogram given a recording.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.FreqScale">
            <summary>
            Gets or sets the frequency scale information.
            The FreqScale object should contain all the parameters required to convert the linear frquency scale of the amplitude spectrogram
            into any reduced or non-linear frequency scale required.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.SnrData">
            <summary>
            Gets or sets instance of class SNR that stores info about signal energy and dB per frame.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.DecibelsPerFrame">
            <summary>
            Gets or sets decibels per signal frame. i.e. log frame energy.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.DecibelsNormalised">
            <summary>
            Gets or sets the array of frame log-energy values normalised 0,1.
            This is derived from the array variable DecibelsPerFrame[].
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.ModalNoiseProfile">
            <summary>
            Gets or sets the Noise profile in decibels.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.DecibelReference">
            <summary>
            Gets or sets decibel reference with which to NormaliseMatrixValues the dB values for MFCCs.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.SigState">
            <summary>
            Gets or sets integer coded signal state ie  0=non-vocalisation, 1=vocalisation, etc.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.Data">
            <summary>
            Gets or sets the spectrogram data matrix of doubles.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.#ctor(AudioAnalysisTools.StandardSpectrograms.SonogramConfig)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.BaseSonogram"/> class.
            BASE CONSTRUCTOR: Use this when want to extract time segment of existing sonogram.
            </summary>
            <param name="config">config file to use.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.#ctor(AudioAnalysisTools.StandardSpectrograms.SonogramConfig,Acoustics.Tools.Wav.WavReader)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.BaseSonogram"/> class.
            BASE CONSTRUCTOR.
            </summary>
            <param name="config">config file to use.</param>
            <param name="wav">wav.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.#ctor(AudioAnalysisTools.StandardSpectrograms.SonogramConfig,AudioAnalysisTools.DSP.FrequencyScale,Acoustics.Tools.Wav.WavReader)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.BaseSonogram"/> class.
            BASE CONSTRUCTOR.
            </summary>
            <param name="config">config file to use.</param>
            <param name="wav">wav.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.#ctor(AudioAnalysisTools.StandardSpectrograms.SonogramConfig,System.Double[0:,0:])">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.BaseSonogram"/> class.
            Use this BASE CONSTRUCTOR when already have the amplitude spectrogram in matrix.
            Init normalised signal energy array but do nothing with it. This has to be done from outside.
            </summary>
            <param name="config">the spectrogram config.</param>
            <param name="amplitudeSpectrogramData">data of an amplitude Spectrogram.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.InitialiseSpectrogram(Acoustics.Tools.Wav.WavReader)">
            <summary>
            This method creates the amplitude spectrogram.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.CalculateSnrData(System.Double)">
            <summary>
            Calculates SNR, ENERGY PER FRAME and NORMALISED dB PER FRAME.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.GetImageFullyAnnotated(System.String,System.Nullable{SixLabors.ImageSharp.Color})">
            <summary>
            This method assumes that the spectrogram has linear Herz scale.
            </summary>
            <param name="title">title to be added to spectrogram.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.GetImageFullyAnnotated(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},System.String,System.Int32[0:,0:],System.Nullable{SixLabors.ImageSharp.Color})">
            <summary>
            This method fully annotates a short-time scale spectrogram.
            The grid-lines are drawn according to indices in gridLineLocations.
            Therefore the method will accept spectrograms with octave or any frequency scale.
            The time scale is calculated from recording duration and width of image.
            </summary>
            <param name="image">The raw spectrogram image.</param>
            <param name="title">To go on the title bar.</param>
            <param name="gridLineLocations">A matrix of values.</param>
            <param name="tag">Used to identify images??.</param>
            <returns>The annotated spectrogram.</returns>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.Data2ImageData(System.Double[0:,0:])">
            <summary>
            converts the dB data in sonogram.Data to grey scale image of spectrogram.
            </summary>
            <param name="matrix">matrix of sonogram values.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.GetSonogramImage(System.Double[0:,0:],System.Int32,System.Int32)">
            <summary>
            Returns an image of the data matrix.
            Normalises the values from min->max according to passed rank values.
            Therefore pixels in the normalised grey-scale image will range from 0 to 255.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.GetImageAnnotatedWithLinearHertzScale(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},System.Int32,System.Int32,System.String,System.Nullable{SixLabors.ImageSharp.Color})">
            <summary>
            Draws Frame around image of spectrogram.
            </summary>
            <param name="image">Image of Spectrogram.</param>
            <param name="sampleRate">sample rate of recording. Necessary for both time scale and Hertz scale.</param>
            <param name="frameStep">frame step allows correct time scale to be drawn.</param>
            <param name="title">Descriptive title of the spectrogram.</param>
            <returns>The framed spectrogram image.</returns>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.FrameSonogram(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},System.TimeSpan,System.TimeSpan,System.TimeSpan,System.TimeSpan)">
            <summary>
            This method draws only top and bottom time scales and adds the title bar.
            It does NOT include the frequency grid lines.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.FrameSonogram(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},System.TimeSpan,System.TimeSpan,System.TimeSpan,System.TimeSpan,System.Int32,System.Int32)">
            <summary>
            This method assumes that the height of the passed sonogram image is half of the original frame size.
            This assumption allows the frequency scale grid lines to be placed at the correct intervals.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.BaseSonogram.SaveDebugSpectrogram(SixLabors.ImageSharp.Image,System.IO.DirectoryInfo,System.String)">
            <summary>
            This method is called by unit tests that want to draw simple spectorgram images.
            It can be modified to do something non-standard with the output spectrogram.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.SonogramConfig.Channel">
            <summary>
            Gets or sets the channel to extract from the WavReader.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.SonogramConfig.FreqBinCount">
            <summary>
            Gets for linear frequency scale assume that the freq bin count = half the frame size.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.SonogramConfig.MelBinCount">
            <summary>
            Gets or sets for linear frequency scale assume that the freq bin count = half the frame size.
            But with Mel scale, the user can set arbitrary number of mel bins.
            By default, MelBincount can be set = FreqBinCount.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SonogramConfig.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.SonogramConfig"/> class.
            Default Constructor - initialises a configuration with the default values.
            This sets the default values for most spectrogram types, including Mel-scale and MFCC spectrograms.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SonogramConfig.#ctor(TowseyLibrary.ConfigDictionary)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.SonogramConfig"/> class.
            CONSTRUCTOR
            Initialises sonogram config with key-value-pairs in the passed ConfigDictionary.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SonogramConfig.#ctor(System.Collections.Generic.Dictionary{System.String,System.String})">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.SonogramConfig"/> class.
            CONSTRUCTOR
            Initialises sonogram config with key-value-pairs in the passed dictionary.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SonogramConfig.Initialize(TowseyLibrary.ConfigDictionary)">
            <summary>
            DoSnr = true;
            DoFullBandwidth = false.
            </summary>
            <param name="config">read from file.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SonogramConfig.Initialize(System.Collections.Generic.Dictionary{System.String,System.String})">
            <summary>
            DoSnr = true;
            DoFullBandwidth = false.
            </summary>
            <param name="configDict">Dictionary of config values.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SonogramConfig.GetFrameDuration(System.Int32)">
            <summary>
            returns duration of a full frame or window in seconds
            Assumes that the Window size is already available.
            </summary>
            <returns>seconds.</returns>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SonogramConfig.GetFrameOffset">
            <summary>
            returns the duration of that part of frame not overlapped with follwoing frame.
            Duration is given in seconds.
            Assumes that the sample rate, window size and overlap fraction are already known.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SonogramConfig.GetFrameOffset(System.Int32)">
            <summary>
            returns the duration of that part of frame not overlapped with follwoing frame.
            Duration is given in seconds.
            Assumes window size and overlap fraction already known.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.StandardSpectrograms.DecibelSpectrogram">
            <summary>
            There are two constructors.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.DecibelSpectrogram.#ctor(AudioAnalysisTools.StandardSpectrograms.SpectrogramSettings,Acoustics.Tools.Wav.WavReader)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.DecibelSpectrogram"/> class.
            This constructor requires config and audio objects
            It creates an amplitude spectrogram.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.DecibelSpectrogram.#ctor(AudioAnalysisTools.StandardSpectrograms.AmplitudeSpectrogram)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.DecibelSpectrogram"/> class.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.DecibelSpectrogram.Data">
            <summary>
            Gets or sets the spectrogram data matrix of doubles.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.DecibelSpectrogram.SnrData">
            <summary>
            Gets or sets instance of class SNR that stores info about signal energy and dB per frame.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.DecibelSpectrogram.DecibelsPerFrame">
            <summary>
            Gets or sets decibels per signal frame.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.DecibelSpectrogram.DecibelReference">
            <summary>
            Gets or sets decibel reference with which to NormaliseMatrixValues the dB values for MFCCs.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.DecibelSpectrogram.SigState">
            <summary>
            Gets or sets integer coded signal state ie  0=non-vocalisation, 1=vocalisation, etc.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.StandardSpectrograms.EnergySpectrogram">
            <summary>
            There are two CONSTRUCTORS.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.EnergySpectrogram.#ctor(AudioAnalysisTools.StandardSpectrograms.SpectrogramSettings,Acoustics.Tools.Wav.WavReader)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.EnergySpectrogram"/> class.
            Use this constructor when you have config and audio objects.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.EnergySpectrogram.Data">
            <summary>
            Gets or sets the spectrogram data matrix of doubles
            Note matrix orientation: ROWS = spectra;  COLUMNS = frequency bins.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.#ctor(AudioAnalysisTools.StandardSpectrograms.TrackType,System.Int32[])">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.ImageTrack"/> class.
            CONSTRUCTOR.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.#ctor(AudioAnalysisTools.StandardSpectrograms.TrackType,System.Double[],System.Double[])">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.ImageTrack"/> class.
            used for showing the singal envelope track.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawSyllablesTrack(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24})">
            <summary>
            paints a track of symbol colours derived from symbol ID.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawScoreArrayTrack(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24})">
            <summary>
            Displays a score track, normalised to min and max of the data. max=approx 8-16.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawScoreArrayTrack(System.Double[],System.Double,System.Int32)">
            <summary>
            Displays a score track, normalised to min and max of the data. max=approx 8-16.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawSimilarityScoreTrack(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24})">
            <summary>
            Displays a score track, normalised to min and max of the data. max=approx 8-16.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawScoreMatrixTrack(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24})">
            <summary>
            This method assumes that the passed data array is of values, min=0.0, max = approx 8-16.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawWaveEnvelopeTrack(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24})">
            <summary>
            assumes that max signal value = 1.0 and min sig value = -1.0 i.e. wav file values.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawTimeTrack(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24})">
            <summary>
            adds time track to a sonogram at the vertical position determined by topOffset.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawSegmentationTrack(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24})">
            <summary>
            This method assumes that the passed decibel array has been normalised.
            Also requires values to be set for SegmentationThreshold_k1 and SegmentationThreshold_k2.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawWaveEnvelopeTrack(System.Double[0:,0:])">
            <summary>
            assumes that max signal value = 1.0 and min sig value = -1.0 i.e. wav file values.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawDecibelTrack(System.Double[],System.Int32,System.Double,System.Double)">
            <summary>
            This method assumes that the passed decibel array has been normalised.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.GetDecibelTrack(AudioAnalysisTools.StandardSpectrograms.BaseSonogram)">
            <summary>
            ASSUME that passed decibel array has been normalised.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.GetSegmentationTrack(AudioAnalysisTools.StandardSpectrograms.BaseSonogram)">
            <summary>
            ASSUME that passed decibel array has been normalised.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawScoreTrack(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},System.Double[],System.Int32,System.Int32,System.Double,System.Double,System.Double,System.String)">
            <summary>
            used to draw richness indices.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawGrayScaleScoreTrack(System.Double[],System.Double,System.Double,System.Double,System.String)">
            <summary>
            used to draw score track or any array of values.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawBarScoreTrack(System.Double[],System.Double[],System.Int32,System.Double,System.String)">
            <summary>
            used to draw score track of an array of values
            The values in array MUST lie in [0,1].
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawColourScoreTrack(System.Double[],System.Double[],System.Int32,System.Int32,System.Double,System.String)">
            <summary>
            used to draw coloured score track or any array of values.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawTimeTrack(System.TimeSpan,System.Nullable{System.DateTimeOffset},System.Int32,System.Int32)">
             <summary>
             IMPORTANT: THIS TIME SCALE METHOD WAS REWORKED ON 23 June 2015 and on 3 August 2015.
             IT POSSIBLY CONTAINS BUGS THAT WILL NEED TO BE FIXED FOR ZOOMING SPECTROGRAMS
             It is possible that rounding the tic marks to 'nice' numbers is not a good idea.
            
             Returns a bitmap of a time scale.
             Interval between tic marks is calculated automatically.
             This method is used for long duration spectrograms.
             It could be generalised for any time track.
             </summary>
             <param name="fullDuration">time span of entire time track to be drawn.</param>
             <param name="dateTime">date and time at start of the track. </param>
             <param name="trackWidth">X pixel dimension.</param>
             <param name="trackHeight">Y pixel dimension.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawTimeTrack(System.TimeSpan,System.TimeSpan,System.TimeSpan,System.Int32,System.Int32,System.String)">
            <summary>
            Like the above method but adds a label at end displaying units of time.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.GetXaxisTicLocations(System.Int32,System.TimeSpan)">
            <summary>
            returns array of bytes that is the gray scale color to use.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawTimeTrack(System.TimeSpan,System.Int32)">
            <summary>
            Draws time track with labels to indicate hh:mm:ss.
            </summary>
            <param name="duration">Duration of the time scale.</param>
            <param name="width">pixel width of the time scale.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.ImageTrack.DrawShortTimeTrack(System.TimeSpan,System.TimeSpan,System.TimeSpan,System.TimeSpan,System.Int32,System.String)">
            <summary>
            This time track is labeled to be convenient for time durations around 1-20 minutes.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.Image_MultiTrack.#ctor(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24})">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.Image_MultiTrack"/> class.
            CONSTRUCTOR.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.Image_MultiTrack.Save(System.String)">
            <summary>
            WARNING: This method calls Image_MultiTrack.GetImage().
            In some circumstances GetImage() cannot manage images with an area larger than 10,385,000 pixels.
            This means it cannot handle recording sonograms longer than 2 minutes.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.Image_MultiTrack.GetImage">
            <summary>
            WARNING: graphics.DrawImage() or GDI cannot draw an image that is too big, typically
            with an area larger than 10,385,000 pixels (Jiro estimated > 40000 pixels).
            This means it cannot handle recording sonograms longer than 2 minutes.
            Therefore call a recursive method to draw the image.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.Image_MultiTrack.OverlayMatrix(SixLabors.ImageSharp.Processing.IImageProcessingContext)">
            <summary>
            superimposes a matrix of scores on top of a sonogram.
            Only draws lines on every second row so that the underling sonogram can be discerned.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.Image_MultiTrack.OverlayMatrix(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24})">
            <summary>
            superimposes a matrix of scores on top of a sonogram.
            Only draws lines on every second row so that the underling sonogram can be discerned.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.Image_MultiTrack.OverlayRedTransparency(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24})">
            <summary>
            superimposes a matrix of scores on top of a sonogram.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.Image_MultiTrack.OverlayScoresAsRedTransparency(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},System.Double[0:,0:])">
            <summary>
            It is assumed that the spectrogram image is grey scale.
            NOTE: The score matrix must consist of reals in [0.0, 1.0].
            NOTE: The image and the score matrix must have the same number of rows and columns.
            In case of a spectrogram, it is assumed that the rows are frequency bins and the columns are individual spectra.
            </summary>
            <param name="bmp">the spectrogram image.</param>
            <param name="hits">the matrix of scores or hits.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.Image_MultiTrack.OverlayScoresAsRedTransparency(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},System.Int32[0:,0:])">
            <summary>
            Overlays a matrix of scores on an image, typically a spectrogram image.
            It is assumed that the spectrogram image is grey scale.
            NOTE: The score matrix must consist of integers from 0 to 255.
            NOTE: The image and the score matrix must have the same number of rows and columns.
            In case of a spectrogram, it is assumed that the rows are frequency bins and the columns are individual spectra.
            </summary>
            <param name="bmp">the spectrogram image.</param>
            <param name="hits">the matrix of scores or hits.</param>
            <returns>The new image with overlay of scores as red transparency.</returns>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.Image_MultiTrack.OverlayRainbowTransparency(SixLabors.ImageSharp.Processing.IImageProcessingContext,SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24})">
            <summary>
            WARNING: THis method is yet to be debugged and tested following move to SixLabors drawing libraries.
            superimposes a matrix of scores on top of a sonogram.
            USES A PALLETTE of ten RAINBOW colours.
            ASSUME MATRIX is NORMALIZED IN [0,1].
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.Image_MultiTrack.OverlayDiscreteColorMatrix(SixLabors.ImageSharp.Processing.IImageProcessingContext)">
            <summary>
            superimposes a matrix of scores on top of a sonogram. USES RAINBOW PALLETTE.
            ASSUME MATRIX consists of integers >=0.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramCepstral.Make(System.Double[0:,0:])">
            <summary>
            Converts amplitude matrix to cepstral sonogram.
            </summary>
            <param name="amplitudeM">Matrix of amplitude values.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramCepstral.MakeCepstrogram(AudioAnalysisTools.StandardSpectrograms.SonogramConfig,System.Double[0:,0:],System.Double[],System.Int32)">
            <summary>
            Returns a cepstrogram matrix of mfcc values from a spectrogram matrix of amplitude values.
            This was revised May/June 2021 in light of more recent literature on mfcc's.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramMelScale.Make(System.Double[0:,0:])">
            <summary>
            Converts amplitude matrix to mel-frequency scale spectrogram.
            IMPORTANT NOTE: The conversion to Mel-scale is done BEFORE noise reduction.
                            And conversion to decibels is done after noise reduction.
            </summary>
            <param name="amplitudeM">Matrix of amplitude values.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramMelScale.MakeMelScaleSpectrogram(AudioAnalysisTools.StandardSpectrograms.SonogramConfig,System.Double[0:,0:],System.Int32)">
            <summary>
            Converts an amplitude spectrogram to mel-scale spectrogram.
            NOTE 1: This method assumes that the entire spectrum ispassed to filter bank.
            NOTE 2: The decibel array has been normalised in 0 - 1.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramMelScale.GetStandardMelScale(AudioAnalysisTools.DSP.FrequencyScale)">
            <summary>
            WARNING: This method assigns DEFAULT parameters for MEL FREQUENCY SCALE.
                      It works only for "standard" recordings, i.e. sr = 22050 and frame = 512.
            The default MelScale has 64 frequency bins.
            The Linear500-octave scale is almost similar and has 66 frequency bands.
            Currently, the MEL scale is implemented directly in MakeMelScaleSpectrogram() method.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramMelScale.GetMelGridLineLocations(System.Int32,System.Int32,System.Int32)">
            <summary>
            THIS METHOD NEEDS TO BE DEBUGGED.  HAS NOT BEEN USED IN YEARS!
            Use this method to generate grid lines for mel scale image
            Currently this method is only called from BaseSonogram.GetImage() when bool doMelScale = true;
            Frequencyscale.Draw1kHzLines(Image{Rgb24} bmp, bool doMelScale, int nyquist, double freqBinWidth).
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramOctaveScale.Make(System.Double[0:,0:])">
            <summary>
            Converts amplitude matrix to octave frequency scale spectrogram.
            IMPORTANT: DOES NOISE REDUCTION after conversion.
            </summary>
            <param name="amplitudeM">Matrix of amplitude values.</param>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.SpectrogramSettings.SourceFileName">
            <summary>
            Gets or sets SourceFileName
            Although this is not a setting, we need to store it right at the beginning.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.SpectrogramSettings.WindowSize">
            <summary>
            Gets or sets the window or frame size. 512 is usually a suitable choice for recordings of the environment.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.SpectrogramSettings.WindowStep">
            <summary>
            Gets or sets exact frame step in samples - an alternative to overlap
            Note that the default setting should be same as WindowSize i.e. no overlap.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.SpectrogramSettings.WindowFunction">
            <summary>
            Gets or sets the default FFT Window function to the Hanning window.
            THe Hanning window was made default in March 2020 because it was found to produce better spectrograms
            in cases where the recording is resampled up or down.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.SpectrogramSettings.SmoothingWindow">
            <summary>
            Gets or sets the smoothing window.
            Following the FFT, each spectrum is smoothed with a moving average filter to reduce its variance.
            We do the minimum smoothing in order to retain spectral definition.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.SpectrogramSettings.MelBinCount">
            <summary>
            Gets or sets MelBinCount
            This is used only if DoMelScale = true.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.SpectrogramAttributes.NyquistFrequency">
            <summary>
            Gets or sets the maximum frequency that can be represented given the signals sampling rate.
            The Nyquist is half the SR.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.SpectrogramAttributes.FrameDuration">
            <summary>
            Gets or sets duration of full frame or window in seconds.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.SpectrogramAttributes.Epsilon">
            <summary>
            Gets or sets the real value difference between two adjacent values of the 16, 24 bit signed integer,
            used to represent the signal amplitude in the range -1 to +1.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.StandardSpectrograms.SpectrogramAttributes.WindowPower">
            <summary>
            Gets or sets the signal power added by using the chosen FFT window function.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramAttributes.GetFrameOffset(System.Int32,System.Double,System.Int32)">
            <summary>
            returns the duration of that part of frame not overlapped with following frame.
            Duration is given in seconds.
            Assumes window size and overlap fraction already known.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard.#ctor(AudioAnalysisTools.StandardSpectrograms.SonogramConfig)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard"/> class.
            Use this constructor when you want to init a new Spectrogram but add the data later.
            Useful for when constructing artificial spectrograms.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard.#ctor(AudioAnalysisTools.StandardSpectrograms.SonogramConfig,AudioAnalysisTools.DSP.FrequencyScale,Acoustics.Tools.Wav.WavReader)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard"/> class.
            Use this constructor when want to increase or decrease the linear frquency scale.
            </summary>
            <param name="config">Other info to construct the spectrogram.</param>
            <param name="scale">The required new frequency scale.</param>
            <param name="wav">The recording.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard.#ctor(AudioAnalysisTools.StandardSpectrograms.SonogramConfig,System.Double[0:,0:])">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard"/> class.
            Use this constructor when you want to init a new Spectrogram by extracting portion of an existing sonogram.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard.#ctor(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.Double,System.Double)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard"/> class.
            use this constructor to cut out a portion of a spectrum from start to end time.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramTools.NormaliseSpectrogramMatrix(System.Double[0:,0:],System.Double,System.Double,System.Double)">
            <summary>
            Used to normalise a spectrogram in 0,1.
            </summary>
            <param name="matrix">the spectrogram data.</param>
            <param name="truncateMin">set all values above to 1.0.</param>
            <param name="truncateMax">set all values below to zero.</param>
            <param name="backgroundFilterCoeff">used to de-emphisize the background.</param>
            <returns>a normalised matrix of spectrogram data.</returns>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramTools.RescaleSpectrumUsingFilterbank(System.Int32[0:,0:],System.Double[])">
            <summary>
            Converts a single linear frequency scale spectrum to a reduced linear or non-linear frequency scale spectrum.
            The scale conversion is defined in the transformMatrix variable.
            The transformMatrix defines a filter bank.
            Strictly speaking the input spectrum can be any vector of values but typically it should be linear spectrum.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramTools.FilterbankIntegral(System.Double[],System.Int32,System.Int32,System.Int32)">
            <summary>
            Implements the integral for a single filter in a filterbank.
            </summary>
            <param name="spectrum">THe input (linear) spectrum.</param>
            <param name="lowIndex">The lower bound of the filter.</param>
            <param name="centreIndex">Centre index of the filter.</param>
            <param name="highIndex">Upper bound of the filter.</param>
            <returns>The integral of the filter.</returns>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramTools.GetSonogramPlusCharts(AudioAnalysisTools.StandardSpectrograms.BaseSonogram,System.Collections.Generic.List{AudioAnalysisTools.Events.EventCommon},System.Collections.Generic.List{TowseyLibrary.Plot},System.Double[0:,0:],System.String)">
            <summary>
            This method draws a spectrogram with other useful information attached.
            </summary>
            <param name="sonogram">of BaseSonogram class.</param>
            <param name="events">a list of acoustic events.</param>
            <param name="plots">a list of plots relevant to the spectrogram scores.</param>
            <param name="hits">not often used - can be null.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramTools.GetSonogramPlusCharts(AudioAnalysisTools.StandardSpectrograms.BaseSonogram,System.Collections.Generic.List{AudioAnalysisTools.AcousticEvent},System.Collections.Generic.List{TowseyLibrary.Plot},System.Double[0:,0:],System.String)">
            <summary>
            This method draws a spectrogram with other useful information attached.
            </summary>
            <param name="sonogram">of BaseSonogram class.</param>
            <param name="events">a list of acoustic events.</param>
            <param name="plots">a list of plots relevant to the spectrogram scores.</param>
            <param name="hits">not often used - can be null.</param>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramTools.CreateFalseColourDecibelSpectrogram(System.Double[0:,0:],System.Double[0:,0:],System.Byte[0:,0:])">
            <summary>
            TODO: This method needs a unit test.
            This is experimental method to explore colour rendering of standard spectrograms
            Used to convert a standard decibel spectrogram into a colour version using
            a colour rendering for three separate properties.
            </summary>
            <param name="dbSpectrogramData">the raw decibel spectrogram data - assigned to red channel.</param>
            <param name="nrSpectrogramData">the noise reduced decibel spectrogram data - assigned to green channel.</param>
            <param name="hits">assigned to ridge colours.</param>
            <returns>coloured-rendered spectrogram as image.</returns>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramTools.CreateFalseColourDecibelSpectrogramForZooming(System.Double[0:,0:],System.Double[0:,0:],System.Byte[0:,0:])">
            <summary>
            Creates a false-coloured spectrogram from spectral frame data.
            That is, uses normal spectrogram data but draws the raw data in red and then superimposes the noise reduced decibel data
            Also uses the spectral "hits" data for highlighting the spectrogram.
            ### IMPORTANT WARNING!!!! THIS METHOD ASSUMES THAT BOTH SPECTRAL MATRICES HAVE BEEN NORMALISED IN [0,1].
            </summary>
            <param name="dbSpectrogramNorm">the raw decibel spectrogram data - assigned to red channel.</param>
            <param name="nrSpectrogramNorm">the noise reduced decibel spectrogram data - assigned to green channel.</param>
            <param name="hits">assigned to ridge colours.</param>
            <returns>coloured-rendered spectrogram as image.</returns>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramTools.CreateFalseColourAmplitudeSpectrogram(System.Double[0:,0:],System.Double[0:,0:],System.Byte[0:,0:])">
            <summary>
            Another experimental method to colour render spectrograms, this time amplitude spectrograms.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramTools.CalculateAvgSpectrumFromEnergySpectrogram(System.Double[0:,0:])">
            <summary>
            NOTE: This method should not be used to average a decibel spectrogram.
            Use only for power spectrograms.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramTools.CalculateAvgDecibelSpectrumFromDecibelSpectrogram(System.Double[0:,0:])">
            <summary>
            Use this method to average a decibel spectrogram.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramTools.AverageAnArrayOfDecibelValues(System.Double[])">
            <summary>
            Here is some test data for this method: array = new[] { 96.0, 100.0, 90.0, 97.0 };
            The return value should = 96.988 dB
            First need to calculate the original value i.e. exponential or antilog.
            See also DataTools.AntiLogBase10(double value).
            </summary>
            <param name="array">an array of decibel values.</param>
            <returns>a decibel value.</returns>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramTools.CalculateAvgSpectrumAndVarianceSpectrumFromAmplitudeSpectrogram(System.Double[0:,0:])">
             <summary>
             Returns AVERAGE POWER SPECTRUM (PSD) and VARIANCE OF POWER SPECTRUM.
             Have been passed the amplitude spectrum but square amplitude values to get power or energy.
            
             This method assumes that the passed amplitude spectrogram has been prepared according to method of P.D. Welch.
             It is the standard method used now to calculate a PSD.
             Welch's method splits time series into overlapping segments and windows them.
             It is the windowing that makes Welche's method different. Normally overlap windows because windows decay at edges and therefore loss of info.
             Can now do FFT. Does not need to be FFT, but if so then window must be power of 2.
             Square the FFT coefficients >>>> energy. Then take average in each frquncy bin. Averaging reduces the variance.
             Welch's method is an improvement on the standard periodogram spectrum estimating method and on Bartlett's method,
             in that it reduces noise in the estimated power spectra in exchange for reducing the frequency resolution.
             The end result is an array of power measurements vs. frequency "bin".
            
             As well as calculating the av power spectrum, this method also returns a variance spectrum and a spectrum of the Coeff of Variation = var/mean.
             </summary>
             <param name="amplitudeSpectrogram">this is an amplitude spectrum. Must square values to get power.</param>
             <returns>three spectral indices.</returns>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramTools.CalculateNdsi(System.Double[],System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Calculates Stuart Gage's NDSI acoustic index from the Power Spectrum derived from a spectrogram.
            This method assumes P.D. Welch's method has been used to calculate the PSD.
            See method above: CalculateAvgSpectrumAndVarianceSpectrumFromAmplitudeSpectrogram().
            </summary>
            <param name="psd">power spectral density.</param>
            <param name="samplerate">original sample rate of the recording. Only used to get nyquist.</param>
            <param name="lowBound">low ndsi bound.</param>
            <param name="midBound">mid ndsi bound.</param>
            <param name="topBound">top ndsi bound.</param>
            <returns>ndsi.</returns>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramTools.HistogramOfSpectralPeaks(System.Double[0:,0:])">
            <summary>
            Returns a HISTORGRAM OF THE DISTRIBUTION of SPECTRAL maxima.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.StandardSpectrograms.SpectrogramTools.DrawGridLinesOnImage(SixLabors.ImageSharp.Image{SixLabors.ImageSharp.PixelFormats.Rgb24},System.TimeSpan,System.TimeSpan,System.TimeSpan,AudioAnalysisTools.DSP.FrequencyScale)">
            <summary>
            Only calls method to draw frequency lines but may in future want to add the times scale.
            </summary>
            <param name="bmp">the spectrogram image.</param>
            <param name="startOffset">start Offset.</param>
            <param name="fullDuration">full Duration.</param>
            <param name="xAxisTicInterval">xAxis Tic Interval.</param>
            <param name="freqScale">freq Scale.</param>
        </member>
        <member name="M:AudioAnalysisTools.SunAndMoon.GetPhaseOfMoon(System.DateTimeOffset)">
             <summary>
             The data for establishing the exact startDTO for the phase of moon in 2010 was obtained at the folowing website:
             http://www.timeanddate.com/moon/phases/australia/brisbane.
            
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.SunAndMoon.ConvertMoonPhaseToString(System.Double)">
            <summary>
            the moon phsae value is assumed to be between 0 and 1. 0 = new moon. 1 = newmoon. 0.5 = full moon.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SunAndMoon.AddSunTrackToImage(System.Int32,System.Nullable{System.DateTimeOffset},System.IO.FileInfo)">
            <summary>
            TODO TODO  work on this method using website and javascript referred to by Anthony. (suncalc.net)
            This method requires a properly formatted csv file containing sunrise/sunset data.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SunAndMoon.AddSunTrackToImage(System.Int32,System.IO.FileInfo,System.Int32,System.Int32,System.String)">
            <summary>
            This method assumes that the argument "dayValue" will not take zero value i.e. dayValue=1 represents January 1st.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SunAndMoon.ReadGeorgiaTidalInformation(System.IO.FileInfo)">
            <summary>
            This method is a quick and dirty hack to rad in some tidal info about Georgia Coast and add into spectrogram images.
            The method is not efficient - just enough to the job done!.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.TileImage.ImageComponent.XBias">
            <summary>
            Gets or sets XBias.
            Represents the image this rectangle needs to be drawn from.
            -1: image before on x axis
            0: current image
            1: next image on x axis.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.TileImage.ImageComponent.YBias">
            <summary>
            Gets or sets YBias
            Represents the image this rectangle needs to be drawn from.
            -1: image before on y axis
            0: current image
            1: next image on y axis.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.TileImage.Tiler.WriteImages">
            <summary>
            Gets or sets a value indicating whether images are written.
            Dirty hack to short circuit Tile's functionality for unit testing.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.TileImage.Tiler.Tile(AudioAnalysisTools.TileImage.ISuperTile)">
            <summary>
            Split one large image (a super tile) into smaller tiles.
            </summary>
            <param name="superTile">The super tile to be split.</param>
        </member>
        <member name="M:AudioAnalysisTools.TileImage.Tiler.Tile(AudioAnalysisTools.TileImage.ISuperTile,AudioAnalysisTools.TileImage.ISuperTile,AudioAnalysisTools.TileImage.ISuperTile)">
            <summary>
            Split one large image (a super tile) into smaller tiles.
                The super tile needs to be aligned within the layer first
            NOTE: If a tile spans multiple supertiles,
            it will paint forward/backward by using either the end of the current segment and the start
            of the next segment or the end of the previous segment and the start of the current segment.
            </summary>
            <param name="previous">
            The previous super tile. Null if nothing beforehand.
            </param>
            <param name="current">
            The super tile currently being operated on.
            </param>
            <param name="next">
            The next super tile that will be processed (positive x-dimension).
            </param>
        </member>
        <member name="M:AudioAnalysisTools.TileImage.Tiler.GetImageParts(SixLabors.ImageSharp.Rectangle,SixLabors.ImageSharp.Rectangle)">
            <summary>
            Returns a set of rectangles that can be used to compose a baseRectangle.
            </summary>
            <param name="baseRectangle">
            The base Rectangle.
            </param>
            <param name="requestedRectangle">
            The requested Rectangle.
            </param>
            <returns>
            The <see cref="!:ImageComponent[]"/>.
            </returns>
        </member>
        <!-- Badly formed XML comment ignored for member "M:AudioAnalysisTools.TileImage.Tiler.SplitAlongY(System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,AudioAnalysisTools.TileImage.TileBias)" -->
        <member name="M:AudioAnalysisTools.TileImage.Tiler.AlignSuperTileInLayer(System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32@,System.Int32@)">
            <summary>
            Aligns a supertile into a layer for one dimension only
                tiles are aligned to the center of the layer.
            </summary>
            <param name="layerLength">
            The layer Width.
            </param>
            <param name="layerTileCount">
            </param>
            <param name="layerTileLength">
            </param>
            <param name="superTileOffset">
            The super Tile Offset. This is a top/left coordinate
                relative to the start of the data
                that needs to be converted to a middle coordinate
                that is relative to the layer.
            </param>
            <param name="superTileWidth">
            The super Tile Width.
            </param>
            <param name="padding">
            </param>
            <param name="startTileEdge">
            The start Tile Edge.
            </param>
            <returns>
            The <see cref="T:System.Int32"/>.
            </returns>
        </member>
        <member name="M:AudioAnalysisTools.Tracks.ForwardTrackAlgorithm.GetForwardTracks(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,AnalysisPrograms.Recognizers.Base.ForwardTrackParameters,System.TimeSpan,System.Double)">
            <summary>
            This method returns foward (spectral peak) tracks enclosed in spectral events.
            It averages dB log values incorrectly but it is faster than doing many log conversions.
            </summary>
            <param name="sonogram">The spectrogram to be searched.</param>
            <returns>A list of acoustic events containing foward tracks.</returns>
        </member>
        <member name="T:AudioAnalysisTools.Tracks.OnebinTrackAlgorithm">
            <summary>
            This class searches a spectrogram for whistles, that is, for tones or spectral peaks that persist in one frequency bin.
            In practice, the whistles of birds and other natural sources do not occupy a single frequency bin,
            although this statement is confounded by the choice of recording sample rate and frame size.
            But typically, a bird whistle spreads itself across three or more frequency bins using typical values for SR etc.
            In this class, we make an assumption about the spectral profile of a whistle and the user is expected to find the appropriate
            sample rate, frame size and frame step such that the target whistle is detected using the profile.
            We define a whistle profile that is 11 bins wide. The actual whistle occupies the centre three bins, ie bins -1, 0 , +1.
            Bins -2 and +2 are ignored to allow for some flexibility in getting he right combination of sample rate, frame size and frame step.
            To establish that the centre three bins contain a spectral peak (i.e. are part of a potential whistle),
            we define top and bottom sidebands, each of width three bins.
            These are used to establish a baseline intensity which must be less than that of the centre three bins.
            The bottom sideband = bins -3, -4, -5. The top sideband = bins +3, +4, +5.
            Defining a whistle this way introduces edge effects at the top and bottom of the spectrogram.
            In case of the low frequency edge, in order to get as close as possible to the frequency bin zero, we do not incorporate a bottom sidebound into the calculations.
            Also note that a typical bird whistle is not exactly a pure tone. It typically fluctuates slightly from one frequency bin to an adjacent bin and back.
            Consequently a final step in this whistle detection algorithm is to merge adjacent whistle tracks.
            The algorithm is not perfect but it does detect constant tone sounds. Theis algorithm is designed so as not to pick up chirps,
            i.e. gradually rising and falling tones. However, here again the right choice of SR, frame size and frame step are important.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Tracks.OnebinTrackAlgorithm.GetOnebinTracks(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,AnalysisPrograms.Recognizers.Base.OnebinTrackParameters,System.TimeSpan,System.Double)">
            <summary>
            This method returns whistle (spectral peak) tracks enclosed as spectral events.
            It averages dB log values incorrectly but it is faster than doing many log conversions.
            </summary>
            <param name="spectrogram">The spectrogram to be searched.</param>
            <param name="parameters">The parameters that determine the search.</param>
            <param name="segmentStartOffset">Enables assignment of a start time (relative to recording) to any valid event.</param>
            <param name="decibelThreshold">The threshold for detection of a track.</param>
            <returns>A list of acoustic events containing whistle tracks.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Tracks.OnebinTrackAlgorithm.GetOnebinTracks(System.Double[0:,0:],System.Double,System.Double,System.Double,AudioAnalysisTools.UnitConverters)">
            <summary>
            This method finds whistle tracks, that is horizontal ridges in one frequency bin.
            </summary>
            <param name="peaks">Peaks matrix.</param>
            <param name="minDuration">Minimum duration of a whistle.</param>
            <param name="maxDuration">Maximum duration of a whistle.</param>
            <param name="threshold">Minimum amplitude threshold to be valid whistle.</param>
            <param name="converter">For the time/frequency scales.</param>
            <returns>A list of whistle tracks.</returns>
        </member>
        <member name="M:AudioAnalysisTools.Tracks.OneframeTrackAlgorithm.GetOneFrameTracks(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,AnalysisPrograms.Recognizers.Base.OneframeTrackParameters,System.TimeSpan,System.Double)">
            <summary>
            A one-frame track sounds like a click.
            A click is a sharp onset broadband sound of brief duration. Geometrically it is similar to a vertical whistle.
            THis method averages dB log values incorrectly but it is faster than doing many log conversions.
            This method is used to find acoustic events and is accurate enough for the purpose.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Tracks.OneframeTrackAlgorithm.GetOneFrameTracks(System.Double[0:,0:],System.Int32,System.Int32,System.Double,System.Double,System.Double,AudioAnalysisTools.UnitConverters)">
            <summary>
            Extracts click type tracks. A click occupies one frame. In a spectrogram it is equivalent to a vertical ridge.
            A click is a sudden onset event but may have a training echo.
            </summary>
            <param name="peaks">A matrix that identifies the location of sudden onset peaks.</param>
            <param name="minBin">Bottom of the frequency band to search.</param>
            <param name="maxBin">Top of the frequency band to search.</param>
            <param name="minBandwidthHertz">Minimum band width spanned by the click event.</param>
            <param name="maxBandwidthHertz">Maximum band width spanned by the click event.</param>
            <param name="threshold">The amplitude threshold to qualify as a sudden onset ridge.</param>
            <param name="converter">To do the time/freq scale conversions.</param>
            <returns>A list of click tracks.</returns>
        </member>
        <member name="T:AudioAnalysisTools.Tracks.UpwardTrackAlgorithm">
            <summary>
            EXPANATION: A vertical track is a near click or rapidly frequency-modulated tone. A good example is the whip component of the whip-bird call.
            They would typically be only a few time-frames duration.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.Tracks.UpwardTrackAlgorithm.GetUpwardTracks(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,AnalysisPrograms.Recognizers.Base.UpwardTrackParameters,System.TimeSpan,System.Double)">
            <summary>
            THis method averages dB log values incorrectly but it is faster than doing many log conversions and is accurate enough for the purpose.
            </summary>
            <param name="sonogram">The spectrogram to be searched.</param>
            <param name="parameters">parameters for the upwards track algorithm.</param>
            <param name="segmentStartOffset">The start time of the current recording segment under analysis.</param>
            <returns>A list of acoustic events containing foward tracks.</returns>
        </member>
        <member name="P:AudioAnalysisTools.RidgeDetection.RidgeDetectionConfiguration.RidgeMatrixLength">
            <summary>
            Gets or sets dimension of NxN matrix to use for ridge detection, must be odd number.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.RidgeDetection.Sobel5X5RidgeDetection_Version2(System.Double[0:,0:])">
            <summary>
            returns four matrices containing the values of ridges in four directions.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.RidgeDetection.Sobel5X5RidgeDetectionExperiment(System.Double[0:,0:],System.Double)">
            <summary>
            Returns a byte matrix of ridge directions
            0 = no ridge detected or below magnitude threshold.
            1 = ridge direction = horizontal or slope = 0;
            2 = ridge is positive slope or pi/4
            3 = ridge is vertical or pi/2
            4 = ridge is negative slope or 3pi/4.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.RidgeDetection.StructureTensorRidgeDetection(System.Double[0:,0:],System.Double,System.Double)">
            <summary>
            matrix is assumed to be a spectrogram image spectrogram, whose rows are freq bins and columns are time frames.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.RidgeDetection.IdentifySpectralRidges(System.Double[0:,0:],System.Double)">
             <summary>
            
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.RidgeDetection.JoinDisconnectedRidgesInMatrix(System.Byte[0:,0:],System.Double[0:,0:],System.Double)">
             <summary>
            JOINS DISCONNECTED RIDGES.
             </summary>
        </member>
        <member name="M:AudioAnalysisTools.RidgeDetection.SpectralRidges2Intensity(System.Byte[0:,0:],System.Double[0:,0:])">
            <summary>
            CONVERTs a binary matrix of spectral peak tracks to an output matrix containing the acoustic intensity
            in the neighbourhood of those peak tracks.
            </summary>
            <param name="binary">The spectral peak tracks.</param>
        </member>
        <member name="T:AudioAnalysisTools.SpectralPeakTracking2018">
            <summary>
            This class contain the pure algorithm that finds spectral peak tracks from a db spectrogram and settings.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralPeakTracking2018.GetPeakBinsIndex(System.Double[0:,0:],System.Int32,System.Int32)">
            <summary>
            outputs an array of peak bins indices per frame.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralPeakTracking2018.FindLocalSpectralPeaks(System.Double[0:,0:],System.Int32[],System.Int32,System.Int32,System.Int32,System.Double)">
            <summary>
            find spectral peaks per frame by subtracting the average energy of top and bottom band from the syllable band energy.
            then if it is higher than a dB threshold, the index of the peak bin will be returned.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralPeakTracking2018.SpectralPeakTracking(System.Double[0:,0:],System.Int32[],System.Double,System.Double)">
            <summary>
            if there is any local peak in a frame, this method will middle the peak bin and will count the following peaks in a
            pre-defined boundary (startX, endX, startY, endY). If the number of peaks in that boundary is higher than a threshold,
            that will be considered as a call.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralPeakTracking2018.CalculateAverageEnergy(System.Double[],System.Int32,System.Int32)">
            <summary>
            outputs the average energy within a specified band.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralPeakTracking2018.GetArbitraryFreqBandMatrix(System.Double[0:,0:],System.Int32,System.Int32)">
            <summary>
            outputs a matrix with arbitrary minimum and maximum frequency bins.
            this method exists in PatchSampling class.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralPeakTracking2018.GetArbitraryMatrix(System.Double[0:,0:],System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            outputs a matrix with arbitrary boundaries to Y (freq) and X (time) axes.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralPeakTracking2018.MakeHitMatrix(System.Double[0:,0:],System.Int32[][],System.Int32[][])">
            <summary>
            outputs a matrix with the same size of the input matrix.
            all values are zero, except the points of interest (i.e., local spectral peaks).
            these bins can be filled with amplitude values or 1.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralPeakTracking2018.DrawSonogram(AudioAnalysisTools.StandardSpectrograms.BaseSonogram,System.Double[0:,0:])">
            <summary>
            draw the spectrogram with red marks indicating the local spectral peaks.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralPeakTracking2018.DrawTracks(AudioAnalysisTools.StandardSpectrograms.BaseSonogram,System.Double[0:,0:],System.Collections.Generic.List{AudioAnalysisTools.Events.Tracks.Track})">
            <summary>
            draw the spectrogram with spectral tracks.
            </summary>
        </member>
        <member name="T:AudioAnalysisTools.SpectralPeakTracks">
            <summary>
            Finds and stores info about spectral peak tracks ie whistles and chirps in the passed spectrogram.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralPeakTracks.#ctor(System.Double[0:,0:],System.Double)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.SpectralPeakTracks"/> class.
            CONSTRUCTOR NOTE: Orientation of passed spectrogram is: row = spectral frames, columns = frequency bins.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.SpectralPeakTracks.TrackDensity">
            <summary>
            Gets average number of tracks per frame.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.SpectralPeakTracks.SptSpectrum">
            <summary>
            Gets the fractional peak cover; i.e. fraction of frames in freq bin that are a spectral peak.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.SpectralPeakTracks.RhzSpectrum">
            <summary>
            Gets spectrum of horizontal ridges.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.SpectralPeakTracks.RvtSpectrum">
            <summary>
            Gets spectrum of vertical ridges.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.SpectralPeakTracks.RpsSpectrum">
            <summary>
            Gets spectrum of positive slope ridges.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.SpectralPeakTracks.RngSpectrum">
            <summary>
            gets spectrum of negative slope ridges.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralPeakTracks.GetPeakTracksSpectrum(System.Double[0:,0:],System.Double)">
            <summary>
            Calculates spectral peak tracks.
            </summary>
            <param name="dBSpectrogram"> typically a decibel noise-reduced spectrogram.</param>
            <param name="dBThreshold">threshold for spectral peak to be a valid peak.</param>
        </member>
        <member name="M:AudioAnalysisTools.SpectralPeakTracks.LocalSpectralPeaks(System.Double[0:,0:],System.Double)">
            <summary>
            Finds local spectral peaks in a spectrogram, one frame at a time.
            IMPORTANT: Assume that the spectrogram matrix is oriented 90 degrees to visual orientation.
            i.e the rows = spectra; columns = freq bins.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralPeakTracks.CalculateSpectralPeakTracks(AudioAnalysisTools.WavTools.AudioRecording,System.Int32,System.Int32,System.Int32,System.Boolean,System.Double)">
            <summary>
            CALCULATEs SPECTRAL PEAK TRACKS: spectralIndices.SPT, RHZ, RVT, RPS, RNG
            This method is only called from IndexCalulate.analysis() when the IndexCalculation Duration is less than 10 seconds,
            because need to recalculate background noise etc.
            Otherwise the constructor of this class is called: sptInfo = new SpectralPeakTracks(decibelSpectrogram, peakThreshold);
            NOTE: We require a noise reduced decibel spectrogram
            FreqBinWidth can be accessed, if required, through dspOutput1.FreqBinWidth.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.SpectralPeakTracks.ConvertSpectralPeaksToNormalisedArray(System.Double[0:,0:])">
            <summary>
            This method only called from Indexcalculate when returning image of the sonogram for the passed recording segment.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.UnitConverters.#ctor(System.Double,System.Double,System.Double,System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.UnitConverters"/> class.
            IMPORTANT NOTE: segmentDuration should be the duration spanned by the spectrogram image, not the actual duration recording.
                            Given one frame per pixel column, the spectrogram duration = frameCount * seconds/frame.
            </summary>
            <param name="segmentStartOffset">Segment start relative to start of the recording.</param>
            <param name="segmentDuration">Set the time-scale. The spectrogram time-span. Typically 60 seconds.</param>
            <param name="nyquistFrequency">Sets the frequency scale.</param>
            <param name="imageWidth">Pixel width = number of time frames.</param>
            <param name="imageHeight">Pixel height = the number of frequency bins.</param>
        </member>
        <member name="M:AudioAnalysisTools.UnitConverters.#ctor(System.Double,System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.UnitConverters"/> class.
            Use this constructor or the next one when you have sample rate of recording from which spectrogram is derived.
            This constructor assumes that the step size equals the frame size.
            Enables calculations independent of the image size.
            </summary>
            <param name="segmentStartOffset">Start time in seconds of the current recording segment.</param>
            <param name="sampleRate">Sample rate of the recording segment.</param>
            <param name="frameSize">The window or frame size.</param>
        </member>
        <member name="M:AudioAnalysisTools.UnitConverters.#ctor(System.Double,System.Int32,System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.UnitConverters"/> class.
            Use this constructor or the next one when you have sample rate of recording from which spectrogram is derived.
            Enables calculations independent of the image size.
            </summary>
            <param name="segmentStartOffset">Start time in seconds of the current recording segment.</param>
            <param name="sampleRate">Sample rate of the recording segment.</param>
            <param name="frameSize">The window or frame size.</param>
            <param name="stepSize">THe step size which is LTE frame size.</param>
        </member>
        <member name="M:AudioAnalysisTools.UnitConverters.#ctor(System.Double,System.Int32,System.Int32,System.Double)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.UnitConverters"/> class.
            Use this constructor or the above when you have sample rate of recording from which spectrogram is derived.
            Enables calculations independent of the image size.
            Supplied with the frame overlap rather than the step size.
            </summary>
            <param name="segmentStartOffset">Start time in seconds of the current recording segment.</param>
            <param name="sampleRate">Sample rate of the recording segment.</param>
            <param name="frameSize">The window or frame size.</param>
            <param name="frameOverlap">Fractional overlap of frames.</param>
        </member>
        <member name="P:AudioAnalysisTools.UnitConverters.TemporalScale">
            <summary>
            Gets the temporal scale. Measured in seconds per pixel.
            <c>To</c> converts seconds to pixels.
            <c>From</c> converts pixels to seconds.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.UnitConverters.SpectralScale">
            <summary>
            Gets the spectral scale.
            </summary>
            <remarks>
            Measured in hertz per pixel.
            </remarks>
        </member>
        <member name="M:AudioAnalysisTools.UnitConverters.GetPixelRectangle(AudioAnalysisTools.Events.Interfaces.ISpectralEvent)">
            <summary>
            Gets a rectangle suitable for drawing.
            </summary>
            <remarks>
            Top and left are floored to pixel boundaries.
            Width and height are rounded up.
            **No border pixels are substracted from width or height!**.
            </remarks>
            <param name="event">The event to get the border for.</param>
            <returns>The rectangle representing the border.</returns>
        </member>
        <member name="M:AudioAnalysisTools.UnitConverters.GetPoint(AudioAnalysisTools.Events.Interfaces.ISpectralEvent)">
            <summary>
            Gets the top and left of an event, in a fashion suitable for drawing.
            </summary>
            <remarks>
            Top and left are floored to pixel boundaries.
            </remarks>
            <param name="event">The event to get the point for.</param>
            <returns>The point.</returns>
        </member>
        <member name="M:AudioAnalysisTools.UnitConverters.GetSize(AudioAnalysisTools.Events.Interfaces.ISpectralEvent)">
            <summary>
            Gets the width and height of an event.
            </summary>
            <remarks>
            Width and height are rounded up.
            </remarks>
            <param name="event">The event to get the size for.</param>
            <returns>The size.</returns>
        </member>
        <member name="M:AudioAnalysisTools.UnitConverters.GetSecondsDurationFromFrameCount(System.Int32)">
            <summary>
            Returns the duration in seconds of the passed number of frames.
            NOTE: In the case where frames are overlapped, the last frame in any sequence is longer than the frame step.
            This correction becomes sgnificant when the frameCount is small.
            </summary>
            <param name="frameCount">The number of frames.</param>
            <returns>Duration inseconds.</returns>
        </member>
        <member name="M:AudioAnalysisTools.UnitConverters.GetFrameCountFromSecondsDuration(System.Double)">
            <summary>
            Returns the number of frames for the passed duration in seconds.
            Do the calculations in signal samples.
            TODO: Question should we do round or floor?.
            </summary>
            <param name="seconds">The elapsed time.</param>
            <returns>The number of frames.</returns>
        </member>
        <member name="M:AudioAnalysisTools.WavTools.AudioRecording.#ctor(Acoustics.Tools.Wav.WavReader)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.WavTools.AudioRecording"/> class.
            Wrapper for the wav reader.
            Audio must be in wav format.
            Use MasterAudioUtility to convert or segment the audio first.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.WavTools.AudioRecording.#ctor(System.Byte[])">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.WavTools.AudioRecording"/> class.
            Wrapper for the wav reader.
            Audio must be in wav format.
            Use MasterAudioUtility to convert or segment the audio first.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.WavTools.AudioRecording.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.WavTools.AudioRecording"/> class.
            Wrapper for the wav reader.
            Audio must be in wav format.
            Use MasterAudioUtility to convert or segment the audio first.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.WavTools.AudioRecording.#ctor(System.Byte[],System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.WavTools.AudioRecording"/> class.
            Wrapper for the wav reader.
            Audio must be in wav format.
            Use MasterAudioUtility to convert or segment the audio first.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.WavTools.AudioRecording.BaseName">
            <summary>
            Gets the file name without the extension.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.WavTools.AudioRecording.WavReader">
            <summary>
            Gets a wrapper for the wav reader.
            Audio must be in wav format.
            Use MasterAudioUtility to convert or segment the audio first.
            </summary>
        </member>
        <member name="P:AudioAnalysisTools.WavTools.AudioRecording.Duration">
            <summary>
            Gets returns Time Span of the recording.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.WavTools.AudioRecording.GetWaveForm(System.Int32)">
            <summary>
            returns the wave form representation of the signal.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.WavTools.AudioRecording.GetAudioRecording(System.IO.FileInfo,System.Int32,System.String,System.String)">
            <summary>
            TODO - this is long winded way to get file. Need to talk to Mark.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.WavTools.AudioRecording.ExtractSegment(System.IO.FileInfo,System.TimeSpan,System.TimeSpan,System.TimeSpan,System.Int32,System.IO.FileInfo)">
            <summary>
            This method extracts a recording segment and saves it to disk at the location fiOutputSegment.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.WavTools.AudioRecording.GetRecordingSubsegment(AudioAnalysisTools.WavTools.AudioRecording,System.Int32,System.Int32,System.Int32)">
            <summary>
            returns a subsample of a recording with a buffer on either side.
            Main complication is dealing with edge effects.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.WavTools.TowseyWavReader.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.WavTools.TowseyWavReader"/> class.
            CONSTRUCTOR 1
            signal passed as file name.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.WavTools.TowseyWavReader.#ctor(System.Byte[])">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.WavTools.TowseyWavReader"/> class.
            CONSTRUCTOR 2
            signal passed as an array of bytes.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.WavTools.TowseyWavReader.#ctor(System.Byte[],System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.WavTools.TowseyWavReader"/> class.
            CONSTRUCTOR 3
            signal passed as an array of bytes.
            </summary>
        </member>
        <member name="M:AudioAnalysisTools.WavTools.TowseyWavReader.#ctor(System.Double[],System.Int32,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:AudioAnalysisTools.WavTools.TowseyWavReader"/> class.
            CONSTRUCTOR 4
            signal passed as an array of doubles.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Base.CommonParameters">
            <summary>
            Common parameters needed from a config file to detect components.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.CommonParameters.SpeciesName">
            <summary>
            Gets or sets the name species name to give to a component.
            Leave blank if you're don't want an event to have a species name.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.CommonParameters.FrameSize">
            <summary>
            Gets or sets the frame or Window size, i.e. number of signal samples. Must be power of 2. Typically <c>512</c>.
            </summary>
            <value>The size of the window (frame) in samples.</value>.
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.CommonParameters.FrameStep">
            <summary>
            Gets or sets the frame or Window step i.e. before start of next frame.
            The overlap can be any number of samples but less than <see cref="P:AnalysisPrograms.Recognizers.Base.CommonParameters.FrameSize"/>.
            </summary>
            <value>The size of the window step in samples.</value>.
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.CommonParameters.WindowFunction">
            <summary>
            Gets or sets the windowing function used in conjunction with the FFT when making spectrogram.
            This can have quite an impact in some cases so it is worth giving user the option.
            The default is a <see cref="F:TowseyLibrary.WindowFunctions.HANNING"/> window.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.CommonParameters.BgNoiseThreshold">
            <summary>
            Gets or sets the threshold in decibels which determines signal over
            background noise.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.CommonParameters.MinHertz">
            <summary>
            Gets or sets the bottom bound of a search band. Units are Hertz.
            A search band is the frequency band within which an algorithm searches for a particular track or event.
            This is to be carefully distinguished from the top and bottom bounds of a specific event.
            A search band consists of two parallel lines/freqeuncy bins.
            An event is represented by a rectangle.
            Events will/should always lie within a search band. There may be exception in edge cases, i.e. where an event sits on a search bound.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.CommonParameters.MaxHertz">
            <summary>
            Gets or sets the the top bound of a search band. Units are Hertz.
            A search band is the frequency band within which an algorithm searches for a particular track or event.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.CommonParameters.BottomHertzBuffer">
            <summary>
            Gets or sets the buffer (bandwidth of silence) below the component rectangle. Units are Hertz.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.CommonParameters.TopHertzBuffer">
            <summary>
            Gets or sets the buffer (bandwidth of silence) above the component rectangle. Units are Hertz.
            Quite often this will be set to <value>null</value> which indicates as upper bounds variable,
            depending on distance of the source.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.CommonParameters.MinDuration">
            <summary>
            Gets or sets the minimum allowed duration of the component. Units are seconds.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.CommonParameters.MaxDuration">
            <summary>
            Gets or sets the maximum allowed duration of the component. Units are seconds.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.CommonParameters.DecibelThresholds">
            <summary>
            Gets or sets an array of decibel thresholds.
            Each threshold determines the minimum "loudness" of an event that can be detected.
            Units are decibels.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.CommonParameters.NoiseReductionType">
            <summary>
            The type of noise reduction to use.
            Defaults to <see cref="F:AudioAnalysisTools.DSP.NoiseReductionType.Standard"/>.
            </summary>
            <value>One of the <see cref="P:AnalysisPrograms.Recognizers.Base.CommonParameters.NoiseReductionType"/> values.</value>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Base.DctParameters">
            <summary>
            Common parameters needed from a config file to detect components,
            used by algorithms that have tunable DCT parameters.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.DctParameters.DctDuration">
            <summary>
            Gets or sets the time duration (in seconds) of a Discrete Cosine Transform.
            </summary>
            <value>The duration of the window in seconds.</value>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.DctParameters.DctThreshold">
            <summary>
            Gets or sets the minimum acceptable value of a DCT coefficient.
            </summary>
            <remarks>
            Lowering `DctThreshold` increases the likelihood that random noise
            will be accepted as a true oscillation; increasing `DctThreshold`
            increases the likelihood that a target oscillation is rejected.
            </remarks>
            <value>A value representing a minimum amplitude threshold in the range `[0, 1]`.</value>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.DctParameters.MinOscillationFrequency">
            <summary>
            Gets or sets the minimum OSCILLATIONS PER SECOND
            Ignore oscillation rates below the min amplitude above the max threshold.
            </summary>
            <value>The value in oscillations per second.</value>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.DctParameters.MaxOscillationFrequency">
            <summary>
            Gets or sets the maximum OSCILLATIONS PER SECOND
            Ignore oscillation rates below the min &amp; above the max threshold.
            </summary>
            <value>The value in oscillations per second.</value>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.DctParameters.EventThreshold">
            <summary>
            Gets or sets the Event threshold - use this to determine FP / FN trade-off for events.
            </summary>
            <value>A number between <c>0.0</c> and <c>1.0</c>.</value>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Base.BlobParameters">
            <summary>
            Parameters needed from a config file to detect blob components.
            The following parameters worked well on a ten minute recording containing 14-16 calls.
            Note: if you lower the dB threshold, you need to increase maxDurationSeconds.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Base.BlobParameters.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:AnalysisPrograms.Recognizers.Base.BlobParameters"/> class.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Base.HarmonicParameters">
            <summary>
            Parameters needed from a config file to detect the stacked harmonic components of a soundscape.
            This can also be used for recognizing the harmonics of non-biological sounds such as from turbines, motor-bikes, compressors, hi-revving motors, etc.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.HarmonicParameters.DctThreshold">
            <summary>
            Gets or sets the dctThreshold.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.HarmonicParameters.MinFormantGap">
            <summary>
            Gets or sets the bottom bound of the gap between formants. Units are Hertz.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.HarmonicParameters.MaxFormantGap">
            <summary>
            Gets or sets the top bound of gap between formants. Units are Hertz.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.HarmonicParameters.SmoothingWindow">
            <summary>
            Gets or sets a smoothing window.
            This is used to run a moving average filter along each of the frequency bins.
            It can help to smooth over discontinuous formants.
            If applied sensible values are 3, 5, or 7.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Base.HarmonicParameters.DetectHarmonicsInSpectrogramData(System.Double[0:,0:],System.Double,System.Int32)">
            <summary>
            A METHOD TO DETECT a set of stacked HARMONICS/FORMANTS in the sub-band of a spectrogram.
            Developed for GenericRecognizer of harmonics.
            NOTE 1: This method assumes the matrix is derived from a spectrogram rotated so that the matrix rows are spectral columns of the spectrogram.
            NOTE 2: As of March 2020, this method averages the values in five adjacent frames. This is to reduce noise.
                    But it requires that the frequency of any potential formants is not changing rapidly.
                    A side-effect is that the edges of harmonic events become blurred.
                    This may not be suitable for detecting human speech. However can reduce the frame step.
            NOTE 3: This method assumes that the minimum  number of formants in a stack = 3.
                    This means that the first 4 values in the returned array of DCT coefficients are set = 0 (see below).
            </summary>
            <param name="m">data matrix derived from the subband of a spectrogram.</param>
            <param name="xThreshold">Minimum acceptable value to be considered part of a harmonic.</param>
            <returns>three arrays: dBArray, intensity, maxIndexArray.</returns>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Base.HarmonicParameters.ConvertScoreArray2HarmonicEvents(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.Double[],System.Double[],AudioAnalysisTools.UnitConverters,System.Int32[],System.Double,System.Double,System.Int32,System.Int32,System.Int32,System.Double,System.TimeSpan)">
            <summary>
            Finds harmonic events in an array harmonic scores.
            NOTE: The score array is assumed to be temporal i.e. each element of the array is derived from a time frame.
            The method uses the passed scoreThreshold in order to calculate a normalised score.
            Max possible score := threshold * 5.
            normalised score := score / maxPossibleScore.
            </summary>
            <param name="scores">the array of harmonic scores.</param>
            <param name="maxIndexArray">the array of max index values derived from the DCT. Used to calculate the harmonic interval.</param>
            <param name="minDuration">duration of event must exceed this to be a valid event.</param>
            <param name="maxDuration">duration of event must be less than this to be a valid event.</param>
            <param name="minHz">lower freq bound of the event.</param>
            <param name="maxHz">upper freq bound of the event.</param>
            <param name="scoreThreshold">threshold.</param>
            <param name="segmentStartOffset">the time offset from segment start to the recording start.</param>
            <returns>a list of acoustic events.</returns>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Base.OscillationParameters">
            <summary>
            Parameters needed from a config file to detect oscillation components.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Base.ForwardTrackParameters">
            <summary>
            Parameters needed from a config file to detect forwards spectral peak tracks.
            A ForwardTrack sounds like a fluctuating tone or technically, a chirp. Each track point advances one time step. Points may move up or down by at most two frequency bins.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.ForwardTrackParameters.CombinePossibleHarmonics">
            <summary>
            Gets or sets a value indicating whether coincident tracks stacked on top of one another are to be combined.
            Coincident means the tracks' start and end times are not greater than the specified seconds interval.
            Stacked means that the frequency gap between each of the stacked tracks does not exceed the specified Hertz interval.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.MinAndMaxBandwidthParameters.MinBandwidthHertz">
            <summary>
            Gets or sets the minimum allowed bandwidth of a spectrogram track or event, units = Hertz.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.MinAndMaxBandwidthParameters.MaxBandwidthHertz">
            <summary>
            Gets or sets the maximum allowed bandwidth of a spectrogram track or event, units = Hertz.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Base.OnebinTrackParameters">
            <summary>
            Parameters needed from a config file to detect whistle components.
            A one-bin sounds like a pure-tone whistle. Each track point advances one time step. Points stay in the same frequency bin.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.OnebinTrackParameters.CombinePossibleSyllableSequence">
            <summary>
            Gets or sets a value indicating whether proximal whistle tracks are to be combined.
            Proximal means the whistle tracks are in the same frequency band
            ... and that the gap between their start times is not greater than the specified seconds interval.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Base.OneframeTrackParameters">
            <summary>
            Parameters needed from a config file to detect click components.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Base.UpwardTrackParameters">
            <summary>
            Parameters needed from a config file to detect vertical track components i.e. events which are completed within very few time frames, i.e. whips and near clicks.
            An UpwardTrack sounds like a whip. Each track point ascends one frequency bin. Points may move forwards or back one frame step.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.UpwardTrackParameters.CombineProximalSimilarEvents">
            <summary>
            Gets or sets a value indicating whether proximal similar vertical tracks are to be combined.
            Proximal means track time starts are not separated by more than the specified seconds interval.
            Similar means that track frequency bounds do not differ by more than the specified Hertz interval.
            </summary>
        </member>
        <member name="M:NeuralNets.ART_2A.#ctor(System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:NeuralNets.ART_2A"/> class.
            CONSTRUCTOR.
            </summary>
        </member>
        <member name="M:NeuralNets.ART_2A.IndexOfFirstUncommittedNode">
            <summary>
            returns -1 if all F2 nodes committed.
            </summary>
        </member>
        <member name="M:NeuralNets.ART_2A.ChangeWts(System.Double[],System.Double[])">
             <summary>
             original Pascal header was: Procedure ChangeWtsART2a(var index:word);  {is my version of ART2_AMatchAndUpdateWts;}.
            
             </summary>
        </member>
        <member name="M:NeuralNets.BinaryCluster.#ctor(System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:NeuralNets.BinaryCluster"/> class.
            CONSTRUCTOR.
            </summary>
        </member>
        <member name="M:NeuralNets.BinaryCluster.InitialiseWtArrays(System.Collections.Generic.List{System.Double[]},System.Int32[],System.Int32)">
            <summary>
            Initialise Uncommitted array := true
            Initialize weight array.
            </summary>
        </member>
        <member name="M:NeuralNets.BinaryCluster.PropagateIP2OP(System.Double[])">
             <summary>
             Only calculate ouputs for committed nodes. Output of uncommitted nodes = 0;
             Output for any OP node = AND_OR_Similarity with input.
            
             Output = 1 - fractional Hamming distance
                    = 1 - (hammingDistance / (double)this.IPSize).
             </summary>
        </member>
        <member name="M:NeuralNets.BinaryCluster.ChangeWts(System.Double[],System.Double[])">
             <summary>
             original Pascal header was: Procedure ChangeWtsFuzzyART(var index:word).
            
             </summary>
        </member>
        <member name="M:NeuralNets.BinaryCluster.GetIndexOfFirstUncommittedNode">
            <summary>
            returns -1 if all F2 nodes committed.
            </summary>
        </member>
        <member name="M:NeuralNets.BinaryCluster.ChangeWtsOfFirstUncommittedNode(System.Double[])">
            <summary>
            sets wts of first uncommitted node to the current IP vector.
            </summary>
        </member>
        <member name="M:NeuralNets.BinaryCluster.ChangeWtsOfCommittedNode(System.Double[],System.Int32)">
            <summary>
            change weights of a committed node
            if beta = 1 then fast learning, if beta = 0 then leader learning ie no change of wts.
            </summary>
        </member>
        <member name="M:NeuralNets.BinaryCluster.DisplayClusterWeights(System.Collections.Generic.List{System.Double[]},System.Int32[])">
            <summary>
            Need to allow for possibility that a wt vector = null.
            </summary>
        </member>
        <member name="M:NeuralNets.BinaryCluster.PruneClusters(System.Collections.Generic.List{System.Double[]},System.Int32[],System.Double,System.Int32)">
            <summary>
            removes wtVectors from a list where two threshold conditions not satisfied:
            1) Sum of positive wts must exceed weight threshold
            2) Cluster size (i.e. total number of frames hit by wtVector) must exceed threshold.
            </summary>
        </member>
        <member name="M:NeuralNets.BinaryCluster.PruneClusters2(System.Collections.Generic.List{System.Double[]},System.Int32[],System.Double,System.Int32)">
            <summary>
            removes wtVectors from a list where three threshold conditions not satisfied
            1) Sum of positive wts must exceed threshold
            2) Cluster size (i.e. total frames hit by wtVector must exceed threshold
            3) All hits are isolated hits ie do not last more than one frame
            returns 1) number of clusters remaining; and 2) percent isolated hits.
            </summary>
        </member>
        <member name="M:NeuralNets.BinaryCluster.HammingSimilarity(System.Double[],System.Double[])">
            <summary>
            returns a value between 0-1
            1- fractional Hamming Distance.
            </summary>
        </member>
        <member name="M:NeuralNets.BinaryCluster.AND_OR_Similarity(System.Double[],System.Double[])">
            <summary>
            Given two binary vectors, returns the 'AND count' divided by the 'OR count'.
            The AND count is always less than or equal to OR count and therefore
            the returned values must lie in 0,1.
            Is equivalent to average of recall and precision if one of the vectors is considered a target.
            Method assumes that both vectors are of the same length.
            </summary>
        </member>
        <member name="M:NeuralNets.BinaryCluster.GetClusterSpectrum(System.Collections.Generic.List{System.Double[]})">
            <summary>
            Sums the weights over all the clusters.
            </summary>
            <param name="clusterWts">a list of wt vectors. Each weight corresponds to a compressed freq band.</param>
            <returns>a reduced spectrum of wts.</returns>
        </member>
        <member name="M:NeuralNets.Cluster.#ctor(System.Collections.Generic.List{System.Double[]})">
            <summary>
            Initializes a new instance of the <see cref="T:NeuralNets.Cluster"/> class.
            CONSTRUCTOR
            Init with list of vectors.
            </summary>
        </member>
        <member name="M:NeuralNets.Cluster.#ctor(System.Double[])">
            <summary>
            Initializes a new instance of the <see cref="T:NeuralNets.Cluster"/> class.
            CONSTRUCTOR
            Init with centroid.
            </summary>
        </member>
        <member name="M:NeuralNets.Cluster.DistanceFromCentroid(System.Double[])">
            <summary>
            calculate euclidian distance of vector from centroid.
            </summary>
        </member>
        <member name="M:NeuralNets.FuzzyART.#ctor(System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:NeuralNets.FuzzyART"/> class.
            CONSTRUCTOR.
            </summary>
        </member>
        <member name="M:NeuralNets.FuzzyART.PropagateIPToF2(System.Double[])">
            <summary>
            Only calculate ouputs for committed nodes. THe uncommitted OPs remain = 0.
            </summary>
        </member>
        <member name="M:NeuralNets.FuzzyART.IndexOfFirstUncommittedNode">
            <summary>
            returns -1 if all F2 nodes committed.
            </summary>
        </member>
        <member name="M:NeuralNets.FuzzyART.ChangeWts(System.Double[],System.Double[])">
             <summary>
             original Pascal header was: Procedure ChangeWtsFuzzyART(var index:word).
            
             </summary>
        </member>
        <member name="M:NeuralNets.FuzzyART.ChangeWtsOfCommittedNode(System.Double[],System.Int32)">
            <summary>
            change weights of a committed node
            if beta = 1 then fast learning, if beta = 0 then leader learning ie no change of wts.
            </summary>
        </member>
        <member name="M:NeuralNets.VQ.Train">
            <summary>
            multiple repeats of training using VQ algorithm.
            </summary>
        </member>
        <member name="M:NeuralNets.VQ.TrainOnce">
            <summary>
            train once with VQ until error less than some condition.
            </summary>
        </member>
    </members>
</doc>
