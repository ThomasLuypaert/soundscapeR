<?xml version="1.0"?>
<doc>
    <assembly>
        <name>AnalysisPrograms</name>
    </assembly>
    <members>
        <member name="P:AnalysisPrograms.AcousticIndices.AcousticIndicesConfig.LdSpectrogramConfig">
            <summary>
            Gets or sets the LDFC spectrogram configuration.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.AcousticWorkbench.Orchestration.RemoteSegment">
            <summary>
            Represents a segment of a remote target audio file.
            This is not a hierarchical structure.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Aed">
            <summary>
                Acoustic Event Detection.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Aed.Arguments">
            <summary>
            The arguments.
            </summary>
        </member>
        <member name="F:AnalysisPrograms.Aed.EcosoundsAedIdentifier">
            <summary>
            The ecosounds aed identifier.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Aed.DefaultSettings">
            <summary>
                Gets the initial (default) settings for the analysis.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Aed.DisplayName">
            <summary>
                Gets the name to display for the analysis.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Aed.Identifier">
            <summary>
                Gets Identifier.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.AnalyseLongRecordings.AnalyseLongRecording.Execute(AnalysisPrograms.AnalyseLongRecordings.AnalyseLongRecording.Arguments)">
            <summary>
            2. Analyses long audio recording (mp3 or wav) as per passed config file. Outputs an events.csv file AND an
            indices.csv file
            Signed off: Michael Towsey 4th December 2012.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.AnalyseLongRecordings.AnalyseLongRecording.Cleanup(AnalysisPrograms.AnalyseLongRecordings.AnalyseLongRecording.Arguments,System.IO.FileInfo)">
            <summary>
            Generic organization of resources after a run.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.AnalysesAvailable.Execute(McMaster.Extensions.CommandLineUtils.CommandLineApplication)">
            <summary>
            Writes all recognised IAnalysers to Console.
            1. Returns list of available analyses
            Signed off: Anthony Truskinger 2016.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Audio2InputForConvCnn">
            <summary>
            Use the following paths for the command line for the 'audio2sonogram' task.
            audio2InputForConvCNN "Path to CSV file" @"C:\Work\GitHub\audio-analysis\AudioAnalysis\AnalysisConfigFiles\Mangalam.Sonogram.yml"  "Output directory" true.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Audio2InputForConvCnn.Execute(AnalysisPrograms.Audio2InputForConvCnn.Arguments)">
            <summary>
            This is the entrypoint for generating ConCNN spectrograms - one at a time.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Audio2InputForConvCnn.Main(AnalysisPrograms.Audio2InputForConvCnn.Arguments)">
            <summary>
            This method written 18-09-2014 to process Mangalam's CNN recordings.
            Calculate the SNR statistics for each recording and then write info back to csv file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Audio2InputForConvCnn.ProcessMeriemsDataset">
            <summary>
            This method was written 9th March 2015 to process a dataset of some 1000 x 5 second recordings.
            The dataset was originally prepared by Meriem for use in her Master's thesis.
            The data is being processed to produce grayscale spectrogram images for use by Mangalam.
            She will classify them using a CNN.
            Note: NO SNR statistics are calculated. All reocrdings must be in single level directory.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Audio2InputForConvCnn.CsvDataRecord">
            <summary>
            In line class used to store a single record read from a line of the csv file.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Audio2InputForConvCnn.AudioToSonogramResult">
            <summary>
            In line class used to return results from the static method Audio2InputForConvCNN.GenerateFourSpectrogramImages().
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Audio2InputForConvCnn.AudioToSonogramResult.AudioEventId">
            <summary>
            Gets or sets iD of the event included in the recording segment.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Audio2InputForConvCnn.AudioToSonogramResult.SiteName">
            <summary>
            Gets or sets name of site where recording was made.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Audio2InputForConvCnn.AudioToSonogramResult.CommonTags">
            <summary>
            Gets or sets class label for this recording.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Audio2InputForConvCnn.AudioToSonogramResult.SpectrogramFile">
            <summary>
            Gets or sets path to spectrogram images of this recording.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Audio2InputForConvCnn.AudioToSonogramResult.SnrStatistics">
            <summary>
            Gets or sets snr information for this recording.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Audio2InputForConvCnn.AudioToSonogramResult.WriteResultAsLineOfCsv">
            <summary>
            CONSTRUCT the header for csv file
             audio_event_id,site_name,common_tags,Threshold,Snr,FractionOfFramesGTThreshold,FractionOfFramesGTThirdSNR,path.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Audio2InputForConvCnn.AudioToSonogramResult.GetCsvHeader">
            <summary>
            CONSTRUCT the header for the above csv file
            Following line is headers from Anthony's returned csv file
            "audio_event_id,audio_recording_id,audio_recording_uuid,projects,site_name,event_start_date_utc,event_duration_seconds,common_tags,species_tags,other_tags,path,Threshold,Snr,FractionOfFramesGTThreshold,FractionOfFramesGTHalfSNR".
            <para>
            Following line is header for these results.
             audio_event_id,site_name,common_tags,Threshold,Snr,FractionOfFramesGTThreshold,FractionOfFramesGTThirdSNR,path.
            </para>
            </summary>
        </member>
        <member name="T:AnalysisPrograms.PreprocessorForConvDnn">
            <summary>
            This analyzer preprocesses short audio segments a few seconds to maximum 1 minute long for processing by a convolutional Deep NN.
            It does not accumulate data or other indices over a long recording.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.AudioCutter">
            <summary>
            Cuts a file into smaller segments.
            </summary>
            <remarks>
            This cutter is useful when you want audio cut the same way AP.exe cuts it.
            </remarks>
        </member>
        <member name="T:AnalysisPrograms.ConcatenateIndexFiles">
             <summary>
             First argument on command line to call this action is "concatenateIndexFiles"
            
             NOTE: This code was last tested on 2016 October 10. Both tests passed.
             </summary>
        </member>
        <member name="M:AnalysisPrograms.ConcatenateIndexFiles.Execute(AnalysisPrograms.ConcatenateIndexFiles.Arguments)">
            <summary>
            Concatenation is designed only for the output from a "Towsey.Acoustic" analysis.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.ConcatenateIndexFiles.ConcatenateRibbonImages(System.IO.DirectoryInfo[],System.String,System.IO.DirectoryInfo,System.String,System.String,AudioAnalysisTools.SunAndMoon.SunMoonTides[])">
            <summary>
            This method is designed only to read in Spectrogram ribbons for Georgia marine recordings.
            Used to prepare images for Aaron Rice.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.ConcatenateIndexFiles.TESTMETHOD_ConcatenateIndexFilesTest1">
            <summary>
            Test data derived from ZuZana's INDONESIAN RECORDINGS, recording site 2. Obtained July 2016.
            This tests concatenation when ConcatenateEverythingYouCanLayYourHandsOn = true
            This test was set up October 2016. The test was transfered to this separate TESTMETHOD in April 2017.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.ConcatenateIndexFiles.TESTMETHOD_ConcatenateIndexFilesTest2">
            <summary>
            Test data derived from ZuZana's INDONESIAN RECORDINGS, recording site 2. Obtained July 2016.
            TEST 2: Do test of CONCATENATE A 24 hour BLOCK of DATA
                    That is, ConcatenateEverythingYouCanLayYourHandsOn = false
            This test was set up October 2016. The test was transfered to this separate TESTMETHOD in April 2017.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.ConcatenateIndexFiles.TESTMETHOD_ConcatenateIndexFilesTest3">
            <summary>
            Test data derived from ZuZana's INDONESIAN RECORDINGS, recording site 2. Obtained July 2016.
            TEST 3: Do test of CONCATENATE A 24 hour BLOCK of DATA
                    That is, ConcatenateEverythingYouCanLayYourHandsOn = false
            HOWEVER, NOTE that the start and end dates are set = null.
            In this situation the default behaviour is to concatenate the earliest to the last dates found in 24 hour blocks.
            This test was set up October 2016. The test was transfered to this separate TESTMETHOD in April 2017.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.ConcatenateIndexFiles.TESTMETHOD_ConcatenateIndexFilesTest4">
            <summary>
            Test data derived from ZuZana's INDONESIAN RECORDINGS, recording site 2. Obtained July 2016.
            This tests concatenation when ConcatenateEverythingYouCanLayYourHandsOn = true
            It works with a reduced data set that will be used for UNIT TESTING, 13th April 2017.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.ContentDescription.BuildModel">
             <summary>
             THis class builds/makes a set of content description templates.
             Templates are initially defined manually in a YAML file. Each template in a YAML file is called a "manifest".
             The array of manifests in a yml file is used to calculate an array of "functional templates" in a json file.
             The json file is generated automatically from the information provided in the manifests.yml file.
             A  template manifest contains the "provenance" of the template (i.e. details of the recordings, source locations etc used to make the functional template.
             It also contains the information required to calculate the template definition.
             The core of a functional template is its definition, which is stored as a dictionary of spectral indices.
             The functional template also contains information required to scan new recordings with the template definition.
            
             IMPORTANT NOTE: At current time (Nov, 2019) Functional Templates are made by reading csv files containing pre-calculated spectral indices.
                             In addition, the Functional Templates can subsequently be tested (this is optional) by reading csv files of spectral indices.
                             The first two FileInfo arguments in the arguments list are compulsory and templates cannot be made without them.
                             Arguments 3 and 4 are optional. They must be provided for testing the templates. Testing also requires files of pre-calculated spectral indices.
             TODO: Refactor the code so that functional templates can be made and tested reading directly from .wav recordings files.
             </summary>
        </member>
        <member name="T:AnalysisPrograms.ContentDescription.UseModel">
            <summary>
            This class is derived from AbstractStrongAnalyser.
            It is equivalent to AnalyseLongRecording.cs or a species recognizer.
            To call this class, the first argument on the commandline must be 'audio2csv'.
            Given a one-minute recording segment, the UseModel.Analyze() method calls AudioAnalysisTools.Indices.IndexCalculateSixOnly.Analysis().
            This calculates six spectral indices, ACI, ENT, EVN, BGN, PMN, OSC. This set of 6x256 acoustic features is used for content description.
            The content description methods are called from UseModel.Analyze() method.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.ContentDescription.UseModel.CdConfig.LdSpectrogramConfig">
            <summary>
            Gets or sets the LDFC spectrogram configuration.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.ContentDescription.UseModel.Analyze``1(AnalysisBase.AnalysisSettings,AnalysisBase.SegmentSettings{``0})">
            <summary>
            This method calls IndexCalculateSixOnly.Analysis() to calculate six spectral indices
            and then calls ContentSignatures.AnalyzeOneMinute() to obtain a content description derived from those indices and an array of functional templates.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.ContentDescription.UseModel.GetPlots(System.Collections.Generic.Dictionary{System.String,System.Double[]})">
            <summary>
            Produce plots for graphical display.
            NOTE: The threshold can be changed later.
            </summary>
            <returns>A list of graphical plots.</returns>
        </member>
        <member name="M:AnalysisPrograms.ContentDescription.UseModel.DrawSpectrogramsFromSpectralIndices(AudioAnalysisTools.LongDurationSpectrograms.LdSpectrogramConfig,System.IO.DirectoryInfo,AudioAnalysisTools.Indices.IndexGenerationData,System.String,System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]})">
            <summary>
            This is cut down version of the method of same name in LDSpectrogramRGB.cs.
            </summary>
            <param name="ldSpectrogramConfig">config for ldfc spectrogram.</param>
            <param name="outputDirectory">outputDirectory.</param>
            <param name="indexGenerationData">indexGenerationData.</param>
            <param name="basename">stem name of the original recording.</param>
            <param name="indexSpectrograms">Optional spectra to pass in. If specified the spectra will not be loaded from disk!.</param>
        </member>
        <member name="T:AnalysisPrograms.Create4Sonograms">
            <summary>
            TODO: THIS CLASS NOW OBSOLETE. CAN REMOVE.
                  REPLACED BY SPECTROGRAM GENERATOR CLASS.
            Call this class by using the activity (first command line argument) "Create4Sonograms".
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Crow.Analysis(System.IO.FileInfo,System.Collections.Generic.Dictionary{System.String,System.String},System.TimeSpan)">
            <summary>
            The CORE ANALYSIS METHOD.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.DrawEasyImage">
            <summary>
            First argument on command line to call this action is "drawEasyImage".
            </summary>
        </member>
        <member name="T:AnalysisPrograms.DrawLongDurationSpectrograms">
             <summary>
             First argument on command line to call this action is "ColourSpectrogram"
             Activity Codes for other tasks to do with spectrograms and audio files:
            
             audio2csv - Calls AnalyseLongRecording.Execute(): Outputs acoustic indices and LD false-colour spectrograms.
             audio2sonogram - Calls AnalysisPrograms.Audio2Sonogram.Main(): Produces a sonogram from an audio file - EITHER custom OR via SOX.Generates multiple spectrogram images and oscilllations info
             indicescsv2image - Calls DrawSummaryIndexTracks.Main(): Input csv file of summary indices. Outputs a tracks image.
             colourspectrogram - Calls DrawLongDurationSpectrograms.Execute():  Produces LD spectrograms from matrices of indices.
             zoomingspectrograms - Calls DrawZoomingSpectrograms.Execute():  Produces LD spectrograms on different time scales.
             differencespectrogram - Calls DifferenceSpectrogram.Execute():  Produces Long duration difference spectrograms
            
             audiofilecheck - Writes information about audio files to a csv file.
             snr - Calls SnrAnalysis.Execute():  Calculates signal to noise ratio.
             audiocutter - Cuts audio into segments of desired length and format
             createfoursonograms.
             </summary>
        </member>
        <member name="M:AnalysisPrograms.DrawLongDurationSpectrograms.DrawAggregatedSpectrograms(AnalysisPrograms.DrawLongDurationSpectrograms.Arguments,System.String,System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]})">
            <summary>
            The integer returned from this method is the count of time-frames in the spectrogram.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.DrawLongDurationSpectrograms.DrawFalseColorSpectrograms(System.String,System.TimeSpan,System.IO.FileInfo,System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]})">
            <summary>
            Draws two false-color spectrograms using a default set of arguments.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.DrawLongDurationSpectrograms.DrawRidgeSpectrograms(AnalysisPrograms.DrawLongDurationSpectrograms.Arguments,System.String,System.Collections.Generic.Dictionary{System.String,System.Double[0:,0:]})">
            <summary>
            The integer returned from this method is the number of seconds duration of the spectrogram.
            Note that this method is called only when spectrogramScale = 0.1.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.DrawSummaryIndexTracks">
            <summary>
            4. Produces a tracks image of column values in a csv file - one track per csv column.
            Signed off: Michael Towsey 27th July 2012.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.DrawSummaryIndexTracks.Main(AnalysisPrograms.DrawSummaryIndexTracks.Arguments)">
            <summary>
            Loads a csv file of summary indices, normalises the values for visualisation and displays a TracksImage.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Draw.RibbonPlots.RibbonPlot">
            <summary>
            Draws ribbon plots from ribbon FCS images.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Draw.Zooming.DrawZoomingSpectrograms">
            <summary>
            Renders index data as false color images at various scales, with various styles.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.DummyAnalysis">
            <summary>
            The purpose of this analyser is to make inter-program parallelisation easier to develop.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.EPR">
             <summary>
             This program runs an alternative version of Event Pattern Recognition (EPR)
             It can be used to detect Ground Parrots.
             It was developed by Michael Towsey in order to address difficulties in the original EPR algorithm - see more below.
             COMMAND LINE ARGUMENTS:
             string recordingPath = args[0];   //the recording to be scanned
             string iniPath       = args[1];   //the initialisation file containing parameters for AED and EPR
             string targetName    = args[2];   //prefix of name of the created output files
            
             The program currently produces only ONE output file: an image of the recording to be scanned with an energy track and two score tracks.
                 1) Energy track  - Measure of the total energy in the user defined frequency band, one value per frame.
                 2) Score Track 1 - Oscillation score - Requires user defined parameters to detect the repeated chirp of a Ground Parrot.
                                    Is a way to cut down the search space. Only deploy template at places where high Oscillation score.
                 3) Score Track 2 - Template score - dB centre-surround difference of each template rectangle.
                                    Currently the dB Score is averaged over the 15 AEs in the groundparrot template.
            
             THE EXISTING ALGORITHM:
             1) Convert the signal to dB spectrogram
             2) AED: i) noise removal
                    ii) convert to binary using dB threshold.
                   iii) Use spidering algorithm to marquee acoustic events.
                    iv) Split over-size events where possible
                     v) Remove under-size events.
             3) EPR: i) Align first AE of template to first 'valid' AE in spectrogram. A valid AE is one whose lower left vertex lies in the
                        user-defined freq band. Currently align lower left vertex for groundparrot recogniser.
                    ii) For each AE in template find closest AE in spectrogram. (Least euclidian distance)
                   iii) For each AE in template, calculate percent overlap to closest AE in spectrogram.
                    iv) Apply threshold to adjust the FP-FN trade-off.
            
             PROBLEM WITH EXISTING ALGORITHM:
             AED:
                    i) Major problem is that the AEs found by AED depend greatly on the user-supplied dB threshold.
                       If threshold too low, the components of the ground parrot call get incorporated into a single larger AE.
                   ii) The spidering algorithm (copied by Brad from MatLab into F#) is computationally expensive.
             EPR:
                    i) EPR is hard coded for groundparrots. In particular the configuration of AEs in the template is hard-coded.
                   ii) EPR is hard coded to align the template using the lower-left vertex of the first AE.
                       This is suitable for the rising cadence of a groundparrot call - but not if descending.
            
             POSSIBLE SOLUTIONS TO EPR AND AED
             AED:
                    i) Need an approach whose result does not depend critically on the user-supplied dB threshold.
                       SOLUTION: Try multiple thresholds starting high and dropping in 2dB steps - pick largest score.
                   ii) Use oscillation detection (OD) to find locations where good change of ground parrot.
                          This only works if the chirps are repeated at fixed interval.
             EPR:
                    i) Instead of aligning lower-left of AEs align the centroid.
                   ii) Only consider AEs whose centroid lies in the frequency band.
                  iii) Only consider AEs whose area is 'similar' to first AE of template.
                   iv) Only find overlaps for AEs 2-15 if first overlap exceeds the threshold.
            
              ###############################################################################################################
             TWO NEW EPR ALGORITHMS BELOW:
             IDEA 1:
             Note: NOT all the above ideas have been implemented. Just a few.
                   The below does NOT implement AED and does not attempt noise removal to avoid the dB thresholding problem.
                   The below uses a different EPR metric
             1) Convert the signal to dB spectrogram
             2) Detect energy oscillations in the user defined frequency band.
                     i) Calulate the dB power in freq band of each frame.
             3) DCT:
                     i) Use Discrete Cosine Transform to detect oscillations in band energy.
                    ii) Only apply template where the DCT score exceeds a threshold (normalised). Align start of template to high dB frame.
             4) TEMPLATE SCORE
                     i) Calculate dB score for first AE in template. dB score = max_dB - surround_dB
                                                where max_dB = max dB value for all pixels in first template AE.
                    ii) Do not proceed if dB score below threshold else calculate dB score for remaining template AEs.
                   iii) Calculate average dB score over all 15 AEs in template.
            
             COMMENT ON NEW ALGORITHM
             1) It is very fast.
             2) Works well where call shows up as energy oscillation.
             3) Is not as accurate because the dB score has less discrimination than original EPR.
             BUT COULD COMBINE THE TWO APPROACHES.
            
             ###############################################################################################################
             IDEA 2: ANOTHER EPR ALGORITHM
             1) Convert the signal to dB spectrogram
             2) Detect energy oscillations in the user defined frequency band.
                     i) Calulate the dB power in freq band of each frame.
            
             3) DCT: OPTIONAL
             ONLY PROCEED IF HAVE HIGH dB SCORE and HIGH DCT SCORE
            
             4) NOISE COMPENSAION
                     Subtract modal noise but DO NOT truncate -dB values to zero.
            
             5) AT POINTS THAT EXCEED dB and DCT thresholds
                i) loop through dB thresholds from 10dB down to 3dB in steps of 1-2dB.
               ii) determine valid AEs in freq band and within certain time range of current position.
                   A valid AE has two attributes: a) entirely within freq band and time width; b) >= 70% overlap with first template AE
              iii) Accumulate a list of valid starting point AEs
              iv) Apply template to each valid start point.
                     a) extract AEs at dB threshold apporpriate to the valid AE
                     a) align centroid of valid AE with centroid of first template AE
                     c) calculate the overlap score
            
            
            
             </summary>
        </member>
        <member name="M:AnalysisPrograms.EPR.GetLocationScore(AudioAnalysisTools.StandardSpectrograms.BaseSonogram,TowseyLibrary.Oblong)">
            <summary>
            reutrns the difference between the maximum dB value in a retangular location and the average of the boundary dB values.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.EventStatistics.EventStatisticsEntry.PaddingFunction(System.Double)">
            <summary>
            Add this much paddding to each acoustic event.
            Returns the total padding, half of which will be symmetrically to either side, or assymertrically if
            boundary effects occur.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.EventStatistics.ImportedEvent.Order">
            <summary>
            Gets or sets the order, a tag field that allows us to maintain the order of imported events, as provided to
            the program.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.EventStatistics.ImportedEvent.ToString">
            <summary>
            Returns a JSON encoded string that describes this object.
            </summary>
            <returns>The string that describes this object.</returns>
        </member>
        <member name="M:AnalysisPrograms.FileRenamer.StartParallel(System.IO.FileInfo[],System.Boolean,System.TimeSpan)">
            <summary>
            Determine new files names and rename if not a dry run.
            </summary>
            <param name="files">Array of files.</param>
            <param name="isDryRun">Dry run or not.</param>
            <param name="timezone">Timezone string to use.</param>
            <returns>Array of file names in same order.</returns>
        </member>
        <member name="T:AnalysisPrograms.GroundParrotRecogniser">
            <summary>
            The ground parrot recognizer.
            </summary>
        </member>
        <member name="F:AnalysisPrograms.GroundParrotRecogniser.KeyNormalizedMinScore">
            <summary>
            The Key Normalized Min Score.
            </summary>
        </member>
        <member name="F:AnalysisPrograms.GroundParrotRecogniser.GroundParrotTemplate1">
            <summary>
            This is the ground parrot template used by Birgit and hard coded by Brad.
            It defines a set of 15 chirps enclosed in a rectangle.
            Each row represents one rectangle or chirp.
            Col1: start of the rectangle in seconds from beginning of the recording
            Col2: end   of the rectangle in seconds from beginning of the recording
            Col3: maximum freq (Hz) of the rectangle
            Col4: minimum freq (Hz) of the rectangle.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.GroundParrotRecogniser.Detect(System.IO.FileInfo,AnalysisPrograms.Aed.AedConfiguration,System.Double,System.TimeSpan)">
            <summary>
            Detect using EPR.
            </summary>
            <param name="wavFilePath">
                The wav file path.
            </param>
            <param name="eprNormalisedMinScore">
                The epr Normalised Min Score.
            </param>
            <returns>
            Tuple containing base Sonogram and list of acoustic events.
            </returns>
        </member>
        <member name="M:AnalysisPrograms.GroundParrotRecogniser.GetEprParametersFromConfigFileOrDefaults(Acoustics.Shared.ConfigFile.Config)">
            <summary>
            Get epr parameters from init file.
            </summary>
            <param name="configuration">The Config configuration object to read.</param>
        </member>
        <member name="M:AnalysisPrograms.GroundParrotRecogniser.ReadGroundParrotTemplateAsMatrix(System.Double,System.Int32)">
            <summary>
            Takes the template defined by Birgit and converts it to integer bins using the user supplied time &amp; hz scales.
            </summary>
            <param name="timeScale">seconds per frame.</param>
            <param name="hzScale">herz per freq bin.</param>
        </member>
        <member name="M:AnalysisPrograms.Human1.Analysis(System.IO.FileInfo,System.Collections.Generic.Dictionary{System.String,System.String},System.TimeSpan)">
            <summary>
            THIS IS THE CORE DETECTION METHOD
            Detects the human voice.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.KoalaMale">
             <summary>
              NOTES:
             (1) The main part of a male koala call consists of a series of inhlations and exhalations;
                 The inhalations are longer and sound like snoring. The exhalations are shorter and the sound is similar to belching.
                 For more on the koala bellow see http://theconversation.com/grunt-work-unique-vocal-folds-give-koalas-their-low-pitched-voice-20800
                 The article interviews Dr. Ben Charlton who came to work with us in 2012.
            
             (2) This class detects male koala calls by detecting the characteristic oscillations of their snoring or inhalations.
                 These snoring oscillations = approx 20-50 per second.
                 They are not constant but tend to increase in rate through the inhalation.
            
             (3) In order to detect 50 oscillations/sec, we need at the very least 100 frames/sec and preferably a frame rate = 150/sec
                    so that a period = 50/s sits near the middle of the array of DCT coefficients.
            
             (4) Frame rate is affected by three parameters: 1) SAMPLING RATE; 2) FRAME LENGTH; 3) FRAME OVERLAP.
                 If the SR ~= 170640, the FRAME LENGTH should = 256 or 512.
                 The best way to adjust frame rate is to adjust frame overlap. I finally decided on the option of automatically calculating the frame overlap
                 to suit the maximum oscillation to be detected.
                 This calculation is done by the method OscillationDetector.CalculateRequiredFrameOverlap();
            
             (5) One should not set the DCT length to be too long because (1) the DCT is expensive to calculate.
                  and (2) the koala oscillation is not constant but the DCT assumes stationarity. 0.3s is good for koala. 0.5s - 1.0s is OK for canetoad.
            
             (6) To reduce the probability of false-positives, the Koala Recognizer filters out oscillation events
                 that are not accompanied by neighbouring oscillation events within 4 seconds.
                 This filtering is done in the method KoalaMale.FilterMaleKoalaEvents().
            
             The action code for this analysis (to enter on the command line) is "KoalaMale".
             </summary>
        </member>
        <member name="M:AnalysisPrograms.KoalaMale.Analysis(AudioAnalysisTools.WavTools.AudioRecording,System.Collections.Generic.IDictionary{System.String,System.String},System.TimeSpan)">
            <summary>
            THE KEY ANALYSIS METHOD.
            </summary>
            <param name="configDict">
                The configuration for the analysis.
            </param>
            <returns>
            The results of the analysis.
            </returns>
        </member>
        <member name="M:AnalysisPrograms.KoalaMale.FilterMaleKoalaEvents(System.Collections.Generic.List{AudioAnalysisTools.AcousticEvent})">
            <summary>
            This method removes isolated koala events.
                Expect at least N consecutive inhales with centres spaced between 1.5 and 2.5 seconds
                N=3 seems best value.
            </summary>
            <param name="events">
            The events.
            </param>
            <returns>
            The <see cref="T:System.Collections.Generic.List`1"/>.
            </returns>
        </member>
        <member name="M:AnalysisPrograms.LSKiwi3.Execute(AnalysisPrograms.LSKiwi3.Arguments)">
            <summary>
            A WRAPPER AROUND THE analyser.Analyze(analysisSettings) METHOD
            To be called as an executable with command line arguments.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.LSKiwi3.Analysis(System.IO.FileInfo,AnalysisBase.AnalysisSettings,System.TimeSpan)">
            <summary>
            ################ THE KEY ANALYSIS METHOD
            Returns a DataTable.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.LSKiwi3.CalculateKiwiBandWidthScore(AudioAnalysisTools.StandardSpectrograms.BaseSonogram,System.Int32,System.Int32,System.Double[])">
            <summary>
            Checks acoustic activity that spills outside the kiwi bandwidth.
            use the periodicity array to cut down comoputaiton.
            Only look where we already know there is periodicity.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.LSKiwi3.CalculateKiwiBandWidthScore(AudioAnalysisTools.StandardSpectrograms.BaseSonogram,System.TimeSpan,System.TimeSpan,System.Int32,System.Int32)">
            <summary>
            Checks acoustic activity that spills outside the kiwi bandwidth.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.LSKiwi3.ConvertEvents2Indices(System.Data.DataTable,System.TimeSpan,System.TimeSpan,System.Double)">
            <summary>
            Converts a DataTable of events to a datatable where one row = one minute of indices.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.LSKiwi3.ProcessCsvFile(System.IO.FileInfo,System.IO.FileInfo)">
            <summary>
            This method should no longer be used.
            It depends on use of the DataTable class which ceased when Anthony did a major refactor in mid-2014.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.LSKiwi3.NormaliseColumnsOfDataTable(System.Data.DataTable)">
            <summary>
            takes a data table of indices and normalises column values to values in [0,1].
            </summary>
        </member>
        <member name="T:AnalysisPrograms.LSKiwiROC">
            <summary>
            SEPARATE PROCESSING TASK FOR KIWI OUTPUT
            little spotted kiwi calls from Andrew @ Victoria university.
            Signed off: Michael Towsey 27th July 2012.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.LSKiwiROC.ROCCurve(System.Data.DataTable,System.Int32,System.Int32,System.String)">
            <summary>
            Calculates an ROC score for the predictions and tags provided in the passed data table.
            First order the data by appropriate score as per the sort string.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.MainEntry">
            <summary>
            Main Entry for Analysis Programs.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.MainEntry.ApDefaultLogVerbosity">
            <summary>
            Gets the default log level set by an environment variable.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.MainEntry.ApPlainLogging">
            <summary>
            Gets a value indicating whether or not we should use simpler logging semantics. Usually means no color.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.MainEntry.ApMetricRecording">
            <summary>
            Gets a value indicating whether we will submit metrics to the remote metric server.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.MainEntry.ApAutoAttach">
            <summary>
            Gets a value indicating whether or not the debugger should automatically attach.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.MainEntry.CheckAndUpdateApplicationConfig">
            <summary>
            If AnalysisPrograms.exe is launched with a 8.3 short name then it
            fails to find it's application config. .NET looks for a config named
            the same name as the executable. Normally AnalysisPrograms.exe looks
            for and finds AnalysisPrograms.exe.config. But if the program is launched
            as ANALYS~1.EXE it tries to search for ANALYS~2.EXE.config which does not
            exist.
            <para>
            This has shown to be an issue with R's system and system2 functions. They
            translate the executable function using `Sys.which` which automatically
            converts executable names to 8.3 short format on Windows.
            </para>
            <para>
            The saga continues: .NET Core also has a dependency on a runtime.json file
            existing and having the name AnalysisPrograms.runtimeconfig.json.
            In short this is still a problem. I've changed the approach to solving this
            now though: I'm simply going to copy the config and give it the short file name
            and place it next to the other one. Hopefully that is stable.
            See `AP.CopyFiles.targets` for the fix.
            </para>
            <para>
            This method checks if this is the case and overrides the setting for
            checking where to find a config file.
            </para>
            </summary>
            <returns><value>True</value> if modifications were made.</returns>
        </member>
        <member name="M:AnalysisPrograms.MainEntry.CheckForDataAnnotations">
            <summary>
            Checks to see whether we can load a DLL that we depend on from the GAC.
            We have to check this early on or else we get some pretty hard to
            diagnose errors (and also because our CLI parser depends on it).
            </summary>
            <returns>A message if there is a problem.</returns>
        </member>
        <member name="M:AnalysisPrograms.MainEntry.HangBeforeExit">
            <summary>
            This method will stop the program from exiting if the solution was built in #DEBUG
            and the program was started by Visual Studio.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.MainEntry.PrepareForErrors">
            <summary>
            Attaches an exception handler and also does a check
            to see if necessary DLLs exist. WARNING: can quit process!.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.OscillationsGeneric">
            <summary>
            ACTIVITY NAME = oscillationsGeneric
            does a general search for oscillation in an audio file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.OscillationsGeneric.AnnotateSonogram(AudioAnalysisTools.StandardSpectrograms.BaseSonogram,System.String)">
            <summary>
            Puts title bar, X &amp; Y axes and gridlines on the passed sonogram.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.PlanesTrainsAndAutomobiles.Analysis(System.IO.FileInfo,System.Collections.Generic.Dictionary{System.String,System.String},System.TimeSpan)">
            <summary>
            ################ THE KEY ANALYSIS METHOD
            Returns a DataTable.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Production.Arguments.SourceConfigOutputDirArguments.ToAnalysisSettings(AnalysisBase.AnalysisSettings,System.Boolean,System.String,Acoustics.Shared.ConfigFile.Config)">
            <summary>
            Helper method used for Execute and Dev entry points. Mocks the values normally set by analysis coordinator.
            </summary>
            <param name="defaults">
            The default AnalysisSettings used - usually from the IAnalyzer2 interface.
            </param>
            <param name="outputIntermediate">
            The output Intermediate switch - true to use the default writing behavior.
            </param>
            <param name="resultSubDirectory">Path to further nest results.</param>
            <param name="configuration">The configuration object to use.</param>
            <returns>
            An AnalysisSettings object.
            </returns>
        </member>
        <member name="P:AnalysisPrograms.Production.Arguments.SubCommandBase.Parent">
            <summary>
            Gets or sets the Parent command.
            This is set by CommandLineUtils automatically.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Production.Arguments.SubCommandBase.OnExecuteAsync(McMaster.Extensions.CommandLineUtils.CommandLineApplication)">
            <summary>
            This method is called when we run the command.
            This method is automatically invoked by CommandLineUtils through reflection.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Production.Arguments.SubCommandBase.OnValidate(System.ComponentModel.DataAnnotations.ValidationContext,McMaster.Extensions.CommandLineUtils.Abstractions.CommandLineContext)">
            <summary>
            This method is invoked when the Model is validated as a whole. It allows for complex
            validation scenarios.
            This method is automatically invoked by CommandLineUtils through reflection.
            </summary>
            <param name="context">The current validation context.</param>
            <param name="appContext">The current command line application.</param>
            <returns>A validation result.</returns>
        </member>
        <member name="T:AnalysisPrograms.Production.CustomHelpTextGenerator">
            <summary>
            A default implementation of help text generation.
            </summary>
        </member>
        <member name="F:AnalysisPrograms.Production.ExceptionLookup.UnhandledExceptionErrorCode">
            <summary>
            The default exit code to use for exceptions not recognized. Must not be greater than 255.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Production.FileSystemProvider">
            <summary>
            Determine the output format for analysis results.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Production.FileSystemProvider.DetermineFileSystem(System.String,System.Boolean)">
            <summary>
            Determine what kind of filesystem to use.
            After this point we *should theoretically* not need to use System.IO.Path.
            </summary>
        </member>
        <member name="E:AnalysisPrograms.Production.PhysicalConsoleLogger.CancelKeyPress">
            <summary>
            <see cref="E:System.Console.CancelKeyPress"/>.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Production.Validation.DirectoryExistsOrCreateAttribute">
            <summary>
            Validates that if the user specifies a value for a property that the value represents a directory that exists
            as determined by System.IO.Directory.Exists(directory).
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Production.Validation.DirectoryExistsOrCreateAttribute.IsValid(System.Object,System.ComponentModel.DataAnnotations.ValidationContext)">
            <summary>
            Validates that the given directory exists.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Production.Validation.ExistingFileAttribute.IsValid(System.Object,System.ComponentModel.DataAnnotations.ValidationContext)">
            <summary>
            Validates that the given directory exists.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Production.Validation.InRangeAttribute.IsValid(System.Object,System.ComponentModel.DataAnnotations.ValidationContext)">
            <summary>
            Validates that the given directory exists.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Base.IEventRecognizer">
            <summary>
            This interface specializes IAnalyser2 to be a species recognizer.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Base.IEventRecognizer.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            Do your analysis. This method is called once per segment (typically one-minute segments).
            </summary>
            <param name="audioRecording">The audio recording to process - it should be a minute or two long.</param>
            <param name="configuration">The configuration to use for this analysis.</param>
            <param name="segmentStartOffset">In analyze long recording scenarios this is the time from the start of the original audio recording for this segment.</param>
            <param name="getSpectralIndexes">Invoke this lazy function to get indices for the current segment.</param>
            <param name="outputDirectory">The current output directory.</param>
            <param name="imageWidth">The expected width of output images.</param>
            <returns>A recognizer results object.</returns>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.MultiRecognizer.MultiRecognizerConfig.EventThreshold">
            <summary>
            Gets or sets the threshold for which to filter events.
            Defaults to 0.0 for the multi recogniser as we want the base recogniser's filters to be used.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Base.RecognizerBase.SummarizeHighResolutionIndices(AnalysisBase.AnalysisResult2,AudioAnalysisTools.Indices.IndexCalculateResult[],AnalysisPrograms.AcousticIndices.AcousticIndicesConfig)">
            <summary>
            Compress high resolution indices - intended to be used when summarizing results.
            Summarize method not yet written.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Base.RecognizerBase.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <inheritdoc />
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Base.RecognizerBase.BeforeAnalyze(AnalysisBase.AnalysisSettings)">
            <summary>
            Run once before each segment of analysis.
            </summary>
            <param name="analysisSettings">Settings used for the analysis.</param>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Base.RecognizerEntry.Execute(AnalysisPrograms.Recognizers.Base.RecognizerEntry.Arguments)">
            <summary>
            This entrypoint should be used for testing short files (less than 2 minutes).
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.RecognizerResults.ScoreTrack">
            <summary>
            Gets or sets currently used to return a score track image that can be appended to a **high resolution indices image**.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.Base.RecognizerResults.Plots">
            <summary>
            Gets or sets a list of plots.
            Used by the multi recognizer.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.AnthusNovaeseelandiae">
            <summary>
            A recognizer for the Australasian pipit, https://en.wikipedia.org/wiki/Australasian_pipit .
            It is a fairly small slender passerine of open country in Australia, New Zealand and New Guinea.
            It is 16 to 19 cm long, and weighs about 40 grams.
            The plumage is pale brown above with dark streaks. The underparts are pale with streaks on the breast.
            There is a pale stripe over the eye and dark malar and moustachial stripes. The long tail has white outer-feathers and is often wagged up and down.
            The legs are long and pinkish-brown while the bill is slender and brownish.
            It has a sparrow-like chirruping call and a drawn-out tswee call. This recognizer detects the chirrup call.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.AnthusNovaeseelandiae.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            This method is called once per segment (typically one-minute segments).
            </summary>
            <param name="audioRecording">one minute of audio recording.</param>
            <param name="config">config file that contains parameters used by all profiles.</param>
            <param name="segmentStartOffset">when recording starts.</param>
            <param name="getSpectralIndexes">not sure what this is.</param>
            <param name="outputDirectory">where the recognizer results can be found.</param>
            <param name="imageWidth"> assuming ????.</param>
            <returns>recognizer results.</returns>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Birds.ArdeaInsignis">
            <summary>
            Used to recognise calls of the White Heron in Bhutan.
            Originally a project of Tshering Dema.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Birds.ArdeaInsignis.SummariseResults(AnalysisBase.AnalysisSettings,AnalysisBase.FileSegment,AnalysisBase.ResultBases.EventBase[],AnalysisBase.ResultBases.SummaryIndexBase[],AnalysisBase.ResultBases.SpectralIndexBase[],AnalysisBase.AnalysisResult2[])">
            <summary>
            Summarize your results. This method is invoked exactly once per original file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Birds.ArdeaInsignis.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            Do your analysis. This method is called once per segment (typically one-minute segments).
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Birds.ArdeaInsignis.GetTemplatesForAlgorithm1(System.Int32)">
            <summary>
            Constructs a list of simple template for the White Herron oscillation call.
            each template is a vector of real values representing acoustic intensity.
            </summary>
            <param name="callBinWidth">Typical value = 13.</param>
            <returns>list of templates.</returns>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Birds.ArdeaInsignis.RecognizerTest(System.Double[],System.IO.FileInfo)">
            <summary>
            This test checks a score array (array of doubles) against a standard or benchmark previously stored.
            If the benchmark file does not exist then the passed score array is written to become the benchmark.
            </summary>
            <param name="scoreArray">scoreArray.</param>
            <param name="wavFile">wavFile.</param>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Birds.ArdeaInsignis.RecognizerTest(System.Collections.Generic.IEnumerable{AnalysisBase.ResultBases.EventBase},System.IO.FileInfo)">
            <summary>
            This test checks an array of acoustic events (array of EventBase) against a standard or benchmark previously stored.
            If the benchmark file does not exist then the array of EventBase is written to a text file.
            If a benchmark does exist the current array is first written to file and then both
            current (test) file and the benchmark file are read as text files and compared.
            </summary>
            <param name="events">a list of acoustic events.</param>
            <param name="wavFile">path of wav file.</param>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Birds.AtrichornisRufescens">
            <summary>
            A recognizer for the Rufous scrubbird, https://en.wikipedia.org/wiki/Rufous_scrubbird.
            The rufous scrubbird (Atrichornis rufescens) is a bird species in the family Atrichornithidae. It is endemic to Australia. 
            This recognizer has been trained on good quality calls provided by NSW DPI by Brad Law and Kristen Thompson.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Birds.CalyptorhynchusLathami">
            <summary>
            A recognizer for the Glossy-black Cockatoo, https://en.wikipedia.org/wiki/Glossy_black_cockatoo.
            The glossy black cockatoo (Calyptorhynchus lathami), is the smallest member of the subfamily Calyptorhynchinae found in eastern Australia.
            This recognizer has been trained on good quality calls provided by NSW DPI by Brad Law and Kristen Thompson.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Birds.ClimacterisPicumnus">
            <summary>
            A recognizer for the Brown treecreeper, https://en.wikipedia.org/wiki/Brown_treecreeper.
            The brown treecreeper (Climacteris picumnus) is the largest Australasian treecreeper. The bird, endemic to eastern Australia, has a broad distribution.
            This recognizer has been trained on good quality calls provided by NSW DPI by Brad Law and Kristen Thompson.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Birds.LewiniaPectoralis">
             <summary>
             AKA: Lewin's Rail
             This call recognizer depends on an oscillation recognizer picking up the Kek-kek repeated at a period of 200ms
            
             This recognizer was first developed around 2007 for Masters student, Jenny Gibson, and her supervisor, Ian Williamson.
             It was updated in October 2016 to become one of the new recognizers derived from RecognizerBase.
            
             To call this recognizer, the first command line argument must be "EventRecognizer".
             Alternatively, this recognizer can be called via the MultiRecognizer.
             </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Birds.LewiniaPectoralis.SummariseResults(AnalysisBase.AnalysisSettings,AnalysisBase.FileSegment,AnalysisBase.ResultBases.EventBase[],AnalysisBase.ResultBases.SummaryIndexBase[],AnalysisBase.ResultBases.SpectralIndexBase[],AnalysisBase.AnalysisResult2[])">
            <summary>
            Summarize your results. This method is invoked exactly once per original file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Birds.LewiniaPectoralis.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            Do your analysis. This method is called once per segment (typically one-minute segments).
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Birds.LewiniaPectoralis.Analysis(AudioAnalysisTools.WavTools.AudioRecording,AudioAnalysisTools.StandardSpectrograms.SonogramConfig,AnalysisPrograms.Recognizers.Birds.LewinsRailConfig,System.Boolean,System.TimeSpan)">
            <summary>
            THE KEY ANALYSIS METHOD.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Birds.ManorinaMelanophrys">
            <summary>
            A recognizer for the Bell miner, https://en.wikipedia.org/wiki/Bell_miner.
            The bell miner (Manorina melanophrys), commonly known as the bellbird, is a colonial honeyeater, endemic to southeastern Australia.
            The common name refers to their bell-like call. 'Miner' is an old alternative spelling of 'myna', and is shared with other members of the genus Manorina.
            This recognizer has been trained on good quality calls provided by NSW DPI by Brad Law and Kristen Thompson.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Birds.NinoxConnivens">
            <summary>
            A recognizer for the Barking Owl, https://en.wikipedia.org/wiki/Barking_owl.
            The barking owl (Ninox connivens), also known as the winking owl, is a nocturnal bird species native to mainland Australia
            and partsof Papua New Guinea and the Moluccas. They are a medium-sized brown owl and have a characteristic voice with
            calls ranging from a barking dog noise to a shrill human-like howl of great intensity.
            This recognizer has been trained on good quality calls provided by NSW DPI by Brad Law and Kristen Thompson.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Birds.TytoNovaehollandiae">
            <summary>
            A recognizer for the Masked owl, https://en.wikipedia.org/wiki/Australian_masked_owl.
            The Australian masked owl (Tyto novaehollandiae) is a barn owl of Southern New Guinea and the non-desert areas of Australia.
            This recognizer has been trained on good quality calls provided by NSW DPI by Brad Law and Kristen Thompson.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Birds.TytoTenebricosa">
            <summary>
            A recognizer for the Greater sooty owl, https://en.wikipedia.org/wiki/https://en.wikipedia.org/wiki/Greater_sooty_owl.
            The greater sooty owl (Tyto tenebricosa) is a medium to large owl found in south-eastern
            Australia, Montane rainforests of New Guinea and have been seen on
            Flinders Island in the Bass Strait. 
            This recognizer has been trained on good quality calls provided by NSW DPI by Brad Law and Kristen Thompson.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.CisticolaExilis">
            <summary>
            A recognizer for calls of the golden-headed cisticola (Cisticola exilis), https://en.wikipedia.org/wiki/Golden-headed_cisticola .
            It is a species of warbler in the family Cisticolidae, found in Australia and 13 Asian countries.
            Grows to 9–11.5 centimetres (3.5–4.5 in) long, it is usually brown and cream in colour.
            It produces a variety of calls distinct from other birds, which, according to the Sunshine Coast Council, range from a "teewip" to a "wheezz, whit-whit".
            It has a very large range and population, which is thought to be increasing. It is not a threatened species.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.NinoxBoobook">
            <summary>
            A recognizer for the Australian Boobook Owl, /// https://en.wikipedia.org/wiki/Australian_boobook .
            Eight subspecies of the Australian boobook are recognized,
            with three further subspecies being reclassified as separate species in 2019 due to their distinctive calls and genetics.
            THis recognizer has been trained on good quality calls from the Gympie recordings obtained by Yvonne Phillips.
            The recognizer has also been run across several recordings of Boobook from NZ (recordings obtained from Stuart Parsons.
            The NZ Boobook calls were of poor quality (distant and echo) and were 200 Hertz higher and performance was not good.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.NinoxBoobook.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            This method is called once per segment (typically one-minute segments).
            </summary>
            <param name="audioRecording">one minute of audio recording.</param>
            <param name="config">config file that contains parameters used by all profiles.</param>
            <param name="segmentStartOffset">when recording starts.</param>
            <param name="getSpectralIndexes">not sure what this is.</param>
            <param name="outputDirectory">where the recognizer results can be found.</param>
            <param name="imageWidth"> assuming ????.</param>
            <returns>recognizer results.</returns>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.NinoxBoobook.SetFrequencyProfileScore(AudioAnalysisTools.ChirpEvent)">
            <summary>
            The Boobook call syllable is shaped like an inverted "U". Its total duration is close to 0.15 seconds.
            The rising portion lasts for 0.06s, followed by a turning portion, 0.03s, followed by the decending portion of 0.06s.
            The constants for this method were obtained from the calls in a Gympie recording obtained by Yvonne Phillips.
            </summary>
            <param name="ev">An event containing at least one forward track i.e. a chirp.</param>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.NinoxBoobook.WriteFrequencyProfiles(System.Collections.Generic.List{AudioAnalysisTools.ChirpEvent})">
            <summary>
            WARNING - this method assumes that the rising and falling parts of a Boobook call syllable last for 5 frames.
            </summary>
            <param name="events">List of spectral events.</param>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.NinoxStrenua">
            <summary>
            A recognizer for the Australian Powerful Owl, https://en.wikipedia.org/wiki/Powerful_owl.
            The owl is so named because it is the largest of the Australian owls and it preys on large marsupials such as possums.
            Its range is confined to the East and SE coast of Australia.
            Its conservation status is "threatened".
            This recognizer has been trained on good quality calls provided by NSW DPI by Brad Law and Kristen Thompson.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.NinoxStrenua.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            This method is called once per segment (typically one-minute segments).
            </summary>
            <param name="audioRecording">one minute of audio recording.</param>
            <param name="config">config file that contains parameters used by all profiles.</param>
            <param name="segmentStartOffset">when recording starts.</param>
            <param name="getSpectralIndexes">not sure what this is.</param>
            <param name="outputDirectory">where the recognizer results can be found.</param>
            <param name="imageWidth"> Should be same as number of frames in the expected spectrogram.</param>
            <returns>recognizer results.</returns>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Frogs.CriniaRemota">
             <summary>
             Crinia remota, AKA: The Remote froglet
             This is a frog recognizer based on the "trill" or "washboard" template
             It detects an irregular trill type typical of many frogs.
             NOTE: The standard canetoad oscillation recognizer is not suitable for those frogs whose trill is irregular.
             The algorithm implemented in this recognizer is as follows:
            
             1. Extract the frequency band containing the call and average the energy in each frame.
             2. Extract the side-bands (leaving a gap) and calculate average energy in each from of each side-band.
             3. Subtract sidebands from dominant call band.
             4. Find the C.remota calls using an IMPULSE/DECAY filter that is tuned to the expected pulse interval, even though irregular.
             5. Pass the resulting score array (output from impulse-decay filter) through an event recognizer.
             6. This returns events within user set duration bounds.
            
             To call this recognizer, the first command line argument must be "EventRecognizer".
             Alternatively, this recognizer can be called via the MultiRecognizer.
             </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.CriniaRemota.SummariseResults(AnalysisBase.AnalysisSettings,AnalysisBase.FileSegment,AnalysisBase.ResultBases.EventBase[],AnalysisBase.ResultBases.SummaryIndexBase[],AnalysisBase.ResultBases.SpectralIndexBase[],AnalysisBase.AnalysisResult2[])">
            <summary>
            Summarize your results. This method is invoked exactly once per original file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.CriniaRemota.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            Do your analysis. This method is called once per segment (typically one-minute segments).
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Frogs.LitoriaBicolor">
             <summary>
             To call this LitoriaBicolor recognizer, the first command line argument must be "EventRecognizer".
             Alternatively, this recognizer can be called via the MultiRecognizer.
            
             This frog recognizer is based on the "kek-kek" recognizer for the Lewin's Rail
             It looks for synchronous oscillations in two frequency bands
             This recognizer was first developed for Jenny ???, a Masters student around 2007.
             It has been updated in October 2016 to become one of the new RecognizerBase recognizers.
             however the Correlation technique used for the Lewins Rail did not work because the ossilations in the upper and lower freq bands are not correlated.
             Instead measure the oscillations in the upper and lower bands independently.
            
             </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaBicolor.SummariseResults(AnalysisBase.AnalysisSettings,AnalysisBase.FileSegment,AnalysisBase.ResultBases.EventBase[],AnalysisBase.ResultBases.SummaryIndexBase[],AnalysisBase.ResultBases.SpectralIndexBase[],AnalysisBase.AnalysisResult2[])">
            <summary>
            Summarize your results. This method is invoked exactly once per original file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaBicolor.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            Do your analysis. This method is called once per segment (typically one-minute segments).
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaBicolor.Analysis(AudioAnalysisTools.WavTools.AudioRecording,AudioAnalysisTools.StandardSpectrograms.SonogramConfig,AnalysisPrograms.Recognizers.Frogs.LitoriaBicolorConfig,System.Boolean,System.TimeSpan)">
            <summary>
            THE KEY ANALYSIS METHOD.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Frogs.LitoriaCaerulea">
             <summary>
             LitoriaCaerulea AKA: The Common Green Tree Frog
             This is a frog recognizer based on the "croak" or "honk" template
             It detects croak type calls by extracting three features: croak bandwidth, dominant frequency, croak duration.
             It may also look for trains of repeated croaks and set a minimum pulse train duration.
            
             To call this recognizer, the first command line argument must be "EventRecognizer".
             Alternatively, this recognizer can be called via the MultiRecognizer.
             </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaCaerulea.SummariseResults(AnalysisBase.AnalysisSettings,AnalysisBase.FileSegment,AnalysisBase.ResultBases.EventBase[],AnalysisBase.ResultBases.SummaryIndexBase[],AnalysisBase.ResultBases.SpectralIndexBase[],AnalysisBase.AnalysisResult2[])">
            <summary>
            Summarize your results. This method is invoked exactly once per original file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaCaerulea.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            Do your analysis. This method is called once per segment (typically one-minute segments).
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Frogs.LitoriaFallax">
             <summary>
             This is a frog recognizer based on the "ribit" or "washboard" template
             It detects ribit type calls by extracting three features: dominant frequency, pulse rate and pulse train duration.
            
             This type recognizer was first developed for the Canetoad and has been duplicated with modification for other frogs
             To call this recognizer, the first command line argument must be "EventRecognizer".
             Alternatively, this recognizer can be called via the MultiRecognizer.
            
             </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaFallax.SummariseResults(AnalysisBase.AnalysisSettings,AnalysisBase.FileSegment,AnalysisBase.ResultBases.EventBase[],AnalysisBase.ResultBases.SummaryIndexBase[],AnalysisBase.ResultBases.SpectralIndexBase[],AnalysisBase.AnalysisResult2[])">
            <summary>
            Summarize your results. This method is invoked exactly once per original file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaFallax.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            Do your analysis. This method is called once per segment (typically one-minute segments).
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Frogs.LitoriaFreycineti">
            <summary>
            This recogniser is unfinished. No guarantees.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaFreycineti.SummariseResults(AnalysisBase.AnalysisSettings,AnalysisBase.FileSegment,AnalysisBase.ResultBases.EventBase[],AnalysisBase.ResultBases.SummaryIndexBase[],AnalysisBase.ResultBases.SpectralIndexBase[],AnalysisBase.AnalysisResult2[])">
            <summary>
            Summarize your results. This method is invoked exactly once per original file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaFreycineti.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            Do your analysis. This method is called once per segment (typically one-minute segments).
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Frogs.LitoriaNasuta">
             <summary>
             Litoria nasuta  AKA The Striped Rocket Frog
             This is a frog recognizer based on the "croak" or "honk" template.
             The algorithm is similar to L.caerulea without the use of DCT to detect pulse trains.
             It detects croak type calls by extracting three features: croak bandwidth, dominant frequency, croak duration.
            
             The Stewart CD recording of L.nasuta exhibits a long pulse train - a DCT could be used to pickup the pulse train.
             However in the recording from Karlina, L.nasuta does not exhibit a long pulse train.
            
             To call this recognizer, the first command line argument must be "EventRecognizer".
             Alternatively, this recognizer can be called via the MultiRecognizer.
             </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaNasuta.SummariseResults(AnalysisBase.AnalysisSettings,AnalysisBase.FileSegment,AnalysisBase.ResultBases.EventBase[],AnalysisBase.ResultBases.SummaryIndexBase[],AnalysisBase.ResultBases.SpectralIndexBase[],AnalysisBase.AnalysisResult2[])">
            <summary>
            Summarize your results. This method is invoked exactly once per original file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaNasuta.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            Do your analysis. This method is called once per segment (typically one-minute segments).
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Frogs.LitoriaOlong">
            <summary>
            This is a recognizer for the Litoria olong.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaOlong.SummariseResults(AnalysisBase.AnalysisSettings,AnalysisBase.FileSegment,AnalysisBase.ResultBases.EventBase[],AnalysisBase.ResultBases.SummaryIndexBase[],AnalysisBase.ResultBases.SpectralIndexBase[],AnalysisBase.AnalysisResult2[])">
            <summary>
            Summarize your results. This method is invoked exactly once per original file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaOlong.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            Do your analysis. This method is called once per segment (typically one-minute segments).
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Frogs.LitoriaPallida">
             <summary>
             This is a frog recognizer based on the "ribit" or "washboard" template
             It detects ribit type calls by extracting three features: dominant frequency, pulse rate and pulse train duration.
            
             This type recognizer was first developed for the Canetoad and has been duplicated with modification for other frogs
             To call this recognizer, the first command line argument must be "EventRecognizer".
             Alternatively, this recognizer can be called via the MultiRecognizer.
            
             </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaPallida.SummariseResults(AnalysisBase.AnalysisSettings,AnalysisBase.FileSegment,AnalysisBase.ResultBases.EventBase[],AnalysisBase.ResultBases.SummaryIndexBase[],AnalysisBase.ResultBases.SpectralIndexBase[],AnalysisBase.AnalysisResult2[])">
            <summary>
            Summarize your results. This method is invoked exactly once per original file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaPallida.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            Do your analysis. This method is called once per segment (typically one-minute segments).
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Frogs.LitoriaRothii">
             <summary>
             This is a frog recognizer based on the "ribit" or "washboard" template
             It detects ribit type calls by extracting three features: dominant frequency, pulse rate and pulse train duration.
            
             This type recognizer was first developed for the Canetoad and has been duplicated with modification for other frogs
             To call this recognizer, the first command line argument must be "EventRecognizer".
             Alternatively, this recognizer can be called via the MultiRecognizer.
            
             </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaRothii.SummariseResults(AnalysisBase.AnalysisSettings,AnalysisBase.FileSegment,AnalysisBase.ResultBases.EventBase[],AnalysisBase.ResultBases.SummaryIndexBase[],AnalysisBase.ResultBases.SpectralIndexBase[],AnalysisBase.AnalysisResult2[])">
            <summary>
            Summarize your results. This method is invoked exactly once per original file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaRothii.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            Do your analysis. This method is called once per segment (typically one-minute segments).
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.Frogs.LitoriaRubella">
             <summary>
             This is a frog recognizer based on the "ribit" or "washboard" template
             It detects ribit type calls by extracting three features: dominant frequency, pulse rate and pulse train duration.
            
             This type recognizer was first developed for the Canetoad and has been duplicated with modification for other frogs
             To call this recognizer, the first command line argument must be "EventRecognizer".
             Alternatively, this recognizer can be called via the MultiRecognizer.
            
             </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaRubella.SummariseResults(AnalysisBase.AnalysisSettings,AnalysisBase.FileSegment,AnalysisBase.ResultBases.EventBase[],AnalysisBase.ResultBases.SummaryIndexBase[],AnalysisBase.ResultBases.SpectralIndexBase[],AnalysisBase.AnalysisResult2[])">
            <summary>
            Summarize your results. This method is invoked exactly once per original file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.Frogs.LitoriaRubella.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            Do your analysis. This method is called once per segment (typically one-minute segments).
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.GenericRecognizer">
            <summary>
            This class calls algorithms for generic syllable/component types.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.GenericRecognizer.Description">
            <inheritdoc />
        </member>
        <member name="M:AnalysisPrograms.Recognizers.GenericRecognizer.ParseConfig(System.IO.FileInfo)">
            <inheritdoc />
        </member>
        <member name="M:AnalysisPrograms.Recognizers.GenericRecognizer.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <inheritdoc/>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.GenericRecognizer.RunOneProfile(AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.String,AnalysisPrograms.Recognizers.Base.CommonParameters,System.Nullable{System.Double},System.TimeSpan)">
            <summary>
            Gets the events for one profile at one decibel threshold.
            </summary>
            <param name="spectrogram">Spectrogram derived from audio segment.</param>
            <param name="profileName">Profile name in the config file.</param>
            <param name="decibelThreshold">Threshold for this pass.</param>
            <param name="segmentStartOffset">The same for any given recording segment.</param>
            <returns>A results object.</returns>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.GenericRecognizer.SaveDebugSpectrogram(AnalysisPrograms.Recognizers.Base.RecognizerResults,Acoustics.Shared.ConfigFile.Config,System.IO.DirectoryInfo,System.String)">
            <summary>
            THis method can be modified if want to do something non-standard with the output spectrogram.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.GenericRecognizer.GenericRecognizerConfig">
            <summary>
            A generic recognizer is a user-defined combinations of component
            algorithms.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.Recognizers.GenericRecognizer.GenericRecognizerConfig.Profiles">
            <inheritdoc />
        </member>
        <member name="P:AnalysisPrograms.Recognizers.GenericRecognizer.GenericRecognizerConfig.PostProcessing">
            <summary>
            Gets or sets the post-processing config.
            Used to obtain parameters for all post-processing steps.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.IctalurusFurcatus">
            <summary>
            This is a Blue Catfish recognizer (Ictalurus furcatus).
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.IctalurusFurcatus.SummariseResults(AnalysisBase.AnalysisSettings,AnalysisBase.FileSegment,AnalysisBase.ResultBases.EventBase[],AnalysisBase.ResultBases.SummaryIndexBase[],AnalysisBase.ResultBases.SpectralIndexBase[],AnalysisBase.AnalysisResult2[])">
            <summary>
            Summarize your results. This method is invoked exactly once per original file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.IctalurusFurcatus.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            Do your analysis. This method is called once per segment (typically one-minute segments).
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.PetaurusAustralis">
            <summary>
            A recognizer for the Yellow-bellied glider, https://en.wikipedia.org/wiki/Yellow-bellied_glider.
            The yellow-bellied glider (Petaurus australis), also known as the fluffy glider,
            is an arboreal and nocturnal gliding possum that lives in native eucalypt forests
            in eastern Australia, from northern Queensland south to Victoria.
            This recognizer has been trained on good quality calls provided by NSW DPI by Brad Law and Kristen Thompson.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.PetaurusBreviceps">
            <summary>
            A recognizer for the Sugar glider, https://en.wikipedia.org/wiki/Sugar_glider.
            The sugar glider (Petaurus breviceps) is a small, omnivorous, arboreal,
            and nocturnal gliding possum belonging to the marsupial infraclass.
            The common name refers to its predilection for sugary foods such as sap
            and nectar and its ability to glide through the air, much like a flying squirrel.
            This recognizer has been trained on good quality calls provided by NSW DPI by Brad Law and Kristen Thompson.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.PetaurusNorfolcensis">
            <summary>
            A recognizer for the Squirrel glider, https://en.wikipedia.org/wiki/Squirrel_glider.
            The squirrel glider (Petaurus norfolcensis) is a nocturnal gliding possum.
            The squirrel glider is one of the wrist-winged gliders of the genus Petaurus
            This recognizer has been trained on good quality calls provided by NSW DPI by Brad Law and Kristen Thompson.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.PhascolarctosCinereus">
            <summary>
            A recognizer for bellows of the male Koala.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.PhascolarctosCinereus.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            This method is called once per segment (typically one-minute segments).
            </summary>
            <param name="audioRecording">one minute of audio recording.</param>
            <param name="config">config file that contains parameters used by all profiles.</param>
            <param name="segmentStartOffset">when recording starts.</param>
            <param name="getSpectralIndexes">not sure what this is.</param>
            <param name="outputDirectory">where the recognizer results can be found.</param>
            <param name="imageWidth"> assuming ????.</param>
            <returns>recognizer results.</returns>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.PhascolarctosCinereus.KoalaConfig">
            <summary>
            The configuration for the Koala V2 recognizer.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.PteropusSpecies">
            <summary>
            This is a recognizer for species of Flying Fox, Pteropus species.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.PteropusSpecies.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            This method is called once per segment (typically one-minute segments).
            </summary>
            <param name="audioRecording">one minute of audio recording.</param>
            <param name="genericConfig">config file that contains parameters used by all profiles.</param>
            <param name="segmentStartOffset">when recording starts.</param>
            <param name="getSpectralIndexes">not sure what this is.</param>
            <param name="outputDirectory">where the recognizer results can be found.</param>
            <param name="imageWidth"> assuming ????.</param>
            <returns>recognizer results.</returns>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.PteropusSpecies.TerritorialCall(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.String,System.TimeSpan)">
            <summary>
            THis method does the work.
            </summary>
            <param name="audioRecording">the recording.</param>
            <param name="configuration">the config file.</param>
            <param name="profileName">name of the call/event type.</param>
            <param name="segmentStartOffset">where one segment is located in the total recording.</param>
            <returns>a list of events.</returns>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.PteropusSpecies.FilterEventsForSpectralProfile(System.Collections.Generic.List{AudioAnalysisTools.AcousticEvent},AudioAnalysisTools.StandardSpectrograms.BaseSonogram)">
            <summary>
            Remove events whose acoustic profile does not match that of a flying fox.
            </summary>
            <param name="events">unfiltered acoustic events.</param>
            <param name="sonogram">includes matrix of spectrogram values.</param>
            <returns>filtered acoustic events.</returns>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.PteropusSpecies.WingBeats(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.String,System.TimeSpan)">
            <summary>
            THis method does the work.
            </summary>
            <param name="audioRecording">the recording.</param>
            <param name="configuration">the config file.</param>
            <param name="profileName">name of call/event type to be found.</param>
            <param name="segmentStartOffset">where one segment is located in the total recording.</param>
            <returns>a list of events.</returns>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.PteropusSpecies.GetSonogram(Acoustics.Shared.ConfigFile.Config,AudioAnalysisTools.WavTools.AudioRecording)">
            <summary>
            returns a base sonogram type from which spectrogram images are prepared.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.PteropusSpecies.SaveDebugSpectrogram(AnalysisPrograms.Recognizers.Base.RecognizerResults,Acoustics.Shared.ConfigFile.Config,System.IO.DirectoryInfo,System.String)">
            <summary>
            THis method can be modified if want to do something non-standard with the output spectrogram.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Recognizers.RhinellaMarina">
             <summary>
             AKA: The bloody canetoad
             This is a frog recognizer based on the "ribit" or "washboard" template
             It detects ribit type calls by extracting three features: dominant frequency, pulse rate and pulse train duration.
            
             This type recognizer was first developed for the Canetoad and has been duplicated with modification for other frogs
             e.g. Litoria rothii and Litoria olongburesnsis.
             To call this recognizer, the first command line argument must be "EventRecognizer".
             Alternatively, this recognizer can be called via the MultiRecognizer.
             </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.RhinellaMarina.SummariseResults(AnalysisBase.AnalysisSettings,AnalysisBase.FileSegment,AnalysisBase.ResultBases.EventBase[],AnalysisBase.ResultBases.SummaryIndexBase[],AnalysisBase.ResultBases.SpectralIndexBase[],AnalysisBase.AnalysisResult2[])">
            <summary>
            Summarize your results. This method is invoked exactly once per original file.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.RhinellaMarina.Recognize(AudioAnalysisTools.WavTools.AudioRecording,Acoustics.Shared.ConfigFile.Config,System.TimeSpan,System.Lazy{AudioAnalysisTools.Indices.IndexCalculateResult[]},System.IO.DirectoryInfo,System.Nullable{System.Int32})">
            <summary>
            Do your analysis. This method is called once per segment (typically one-minute segments).
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.RhinellaMarina.RecognizerTest(System.Double[],System.IO.FileInfo)">
            <summary>
            This test checks a score array (array of doubles) against a standard or benchmark previously stored.
            If the benchmark file does not exist then the passed score array is written to become the benchmark.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.Recognizers.RhinellaMarina.RecognizerTest(System.Collections.Generic.IEnumerable{AnalysisBase.ResultBases.EventBase},System.IO.FileInfo)">
            <summary>
            This test checks an array of acoustic events (array of EventBase) against a standard or benchmark previously stored.
            If the benchmark file does not exist then the array of EventBase is written to a text file.
            If a benchmark does exist the current array is first written to file and then both
            current (test) file and the benchmark file are read as text files and compared.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.RheobatrachusSilus.Analysis(System.IO.FileInfo,System.Collections.Generic.Dictionary{System.String,System.String},System.TimeSpan)">
            <summary>
            ################ THE KEY ANALYSIS METHOD.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.Sandpit">
             <summary>
             Activity Code for this class:= sandpit
            
             Activity Codes for other tasks to do with spectrograms and audio files:
             audio2csv - Calls AnalyseLongRecording.Execute(): Outputs acoustic indices and LD false-colour spectrograms.
             audio2sonogram - Calls AnalysisPrograms.Audio2Sonogram.Main(): Produces a sonogram from an audio file - EITHER custom OR via SOX.Generates multiple spectrogram images and oscilllations info
             indicescsv2image - Calls DrawSummaryIndexTracks.Main(): Input csv file of summary indices. Outputs a tracks image.
             colourspectrogram - Calls DrawLongDurationSpectrograms.Execute():  Produces LD spectrograms from matrices of indices.
             drawzoomingspectrograms - Calls DrawZoomingSpectrograms.Execute():  Produces LD spectrograms on different time scales.
             differencespectrogram - Calls DifferenceSpectrogram.Execute():  Produces Long duration difference spectrograms
            
             audiofilecheck - Writes information about audio files to a csv file.
             snr - Calls SnrAnalysis.Execute():  Calculates signal to noise ratio.
             audiocutter - Cuts audio into segments of desired length and format
             createfoursonograms.
             </summary>
        </member>
        <member name="M:AnalysisPrograms.Segment.Execute_Segmentation(System.IO.FileInfo,System.Int32,System.Int32,System.Double,System.Double,System.Double,System.Double,System.Double)">
            <param name="minDuration">used for smoothing intensity as well as for removing short events.</param>
        </member>
        <member name="T:AnalysisPrograms.SourcePreparers.LocalSourcePreparer">
            <summary>
            Local source file preparer.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.SourcePreparers.LocalSourcePreparer.PrepareFile(System.IO.DirectoryInfo,System.String,System.String,System.TimeSpan,System.TimeSpan,System.Int32)">
            <summary>
            Prepare an audio file. This will be a single segment of a larger audio file, modified based on the analysisSettings.
            </summary>
            <param name="outputDirectory">
            The analysis Base Directory.
            </param>
            <param name="source">
            The source audio file.
            </param>
            <param name="outputMediaType">
            The output Media Type.
            </param>
            <param name="startOffset">
            The start Offset from start of entire original file.
            </param>
            <param name="endOffset">
            The end Offset from start of entire original file.
            </param>
            <param name="targetSampleRateHz">
            The target Sample Rate Hz.
            </param>
            <returns>
            The prepared file. The returned FileSegment will have the targetFile and OriginalFileDuration set -
            these are the path to the segmented file and the duration of the segmented file.
            The start and end offsets will not be set.
            </returns>
        </member>
        <member name="M:AnalysisPrograms.SourcePreparers.LocalSourcePreparer.CalculateSegments``1(System.Collections.Generic.IEnumerable{AnalysisBase.Segment.ISegment{``0}},AnalysisBase.AnalysisSettings)">
            <summary>
            Calculate the file segments for analysis.
            </summary>
            <param name="fileSegments">
            The file segments.
            </param>
            <param name="settings">
            The settings.
            </param>
            <returns>
            Enumerable of sub-segments.
            </returns>
        </member>
        <member name="M:AnalysisPrograms.SourcePreparers.LocalSourcePreparer.PrepareFile``1(System.IO.DirectoryInfo,AnalysisBase.Segment.ISegment{``0},System.String,System.Nullable{System.Int32},System.IO.DirectoryInfo,System.Int32[],System.Nullable{System.Boolean})">
            <summary>
            Prepare an audio file. This will be a single segment of a larger audio file, modified based on the analysisSettings.
            </summary>
            <param name="outputDirectory">
                The analysis Base Directory.
            </param>
            <param name="source">
                The source audio file.
            </param>
            <param name="outputMediaType">
                The output Media Type.
            </param>
            <param name="targetSampleRateHz">
                The target Sample Rate Hz.
            </param>
            <returns>
            The prepared file. The returned FileSegment will have the targetFile and OriginalFileDuration set -
            these are the path to the segmented file and the duration of the segmented file.
            The start and end offsets will not be set.
            </returns>
        </member>
        <member name="T:AnalysisPrograms.SourcePreparers.RemoteSourcePreparer">
            <summary>
            Remote source file preparer.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.SourcePreparers.RemoteSourcePreparer.PrepareFile(System.IO.DirectoryInfo,System.String,System.String,System.TimeSpan,System.TimeSpan,System.Int32)">
            <summary>
            Prepare an audio file. This will be a single segment of a larger audio file,
            modified based on the provided settings.
            </summary>
            <param name="outputDirectory">
            The analysis Base Directory.
            </param>
            <param name="source">
            The source audio file.
            </param>
            <param name="outputMediaType">
            The output Media Type.
            </param>
            <param name="startOffset">
            The start Offset from start of entire original file.
            </param>
            <param name="endOffset">
            The end Offset from start of entire original file.
            </param>
            <param name="targetSampleRateHz">
            The target Sample Rate Hz.
            </param>
            <returns>
            The prepared file. The returned FileSegment will have the targetFile and OriginalFileDuration set -
            these are the path to the segmented file and the duration of the segmented file.
            The start and end offsets will not be set.
            </returns>
        </member>
        <member name="M:AnalysisPrograms.SourcePreparers.RemoteSourcePreparer.CalculateSegments``1(System.Collections.Generic.IEnumerable{AnalysisBase.Segment.ISegment{``0}},AnalysisBase.AnalysisSettings)">
            <summary>
            Calculate the file segments for analysis.
            </summary>
            <param name="fileSegments">
            The file segments.
            </param>
            <param name="settings">
            The settings.
            </param>
            <returns>
            Enumerable of sub-segments.
            </returns>
        </member>
        <member name="M:AnalysisPrograms.SourcePreparers.RemoteSourcePreparer.PrepareFile``1(System.IO.DirectoryInfo,AnalysisBase.Segment.ISegment{``0},System.String,System.Nullable{System.Int32},System.IO.DirectoryInfo,System.Int32[],System.Nullable{System.Boolean})">
            <summary>
            Prepare an audio file. This will be a single segment of a larger audio file, modified based on the analysisSettings.
            </summary>
            <param name="outputDirectory">
                The analysis Base Directory.
            </param>
            <param name="source">
                The source audio file.
            </param>
            <param name="outputMediaType">
                The output Media Type.
            </param>
            <param name="targetSampleRateHz">
                The target Sample Rate Hz.
            </param>
            <returns>
            The prepared file. The returned FileSegment will have the targetFile and OriginalFileDuration set -
            these are the path to the segmented file and the duration of the segmented file.
            The start and end offsets will not be set.
            </returns>
        </member>
        <member name="M:AnalysisPrograms.SpeciesAccumulationCurve.Execute(AnalysisPrograms.SpeciesAccumulationCurve.Arguments)">
            <summary>
            EXECUTABLE
            extracts acoustic richness indices from a single recording.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.SpeciesAccumulationCurve.GetRankOrder(System.String,System.Int32)">
            <summary>
            returns the row indices for a single column of an array, ranked by value.
            Used to order the sampling of an acoustic recording split into one minute chunks.
            </summary>
            <returns>array of index locations in descending order.</returns>
        </member>
        <member name="T:AnalysisPrograms.SpectrogramGenerator.Audio2Sonogram">
            <summary>
            Produces standard greyscale spectrograms of various types from a wav audio file.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.SpectrogramGenerator.AudioToSonogramResult">
            <summary>
            In line class used to return results from the static method SpectrogramGenerator.GenerateSpectrogramImages().
            </summary>
        </member>
        <member name="T:AnalysisPrograms.SpectrogramGenerator.SpectrogramGenerator">
            <summary>
            This analyzer simply generates short (i.e. one minute) spectrograms and outputs them to CSV files.
            It does not accumulate data or other indices over a long recording.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.SpectrogramGenerator.SpectrogramGenerator.GenerateSpectrogramImages(System.IO.FileInfo,AnalysisPrograms.SpectrogramGenerator.SpectrogramGeneratorConfig,System.String)">
            <summary>
            Calculates the following spectrograms as per settings in the Images array in the config file: Towsey.SpectrogramGenerator.yml:
            Waveform.
            DecibelSpectrogram.
            DecibelSpectrogramNoiseReduced.
            MelScaleSpectrogram
            Cepstrogram.
            OctaveScaleSpectrogram
            RibbonSpectrogram.
            DifferenceSpectrogram.
            AmplitudeSpectrogramLocalContrastNormalization.
            Experimental.
            Comment the config.yml file with a hash, those spectrograms that are not required.
            </summary>
            <param name="sourceRecording">The name of the original recording.</param>
            <param name="config">Contains parameter info to make spectrograms.</param>
            <param name="sourceRecordingName">.Name of source recording. Required only spectrogram labels.</param>
        </member>
        <member name="M:AnalysisPrograms.SpectrogramGenerator.SpectrogramGenerator.GetDecibelSpectrogram_Ridges(System.Double[0:,0:],AudioAnalysisTools.StandardSpectrograms.SpectrogramStandard,System.String)">
            <summary>
            AN EXPERIMENTAL SPECTROGRAM - A FALSE-COLOR VERSION OF A standard scale SPECTROGRAM.
            </summary>
            <param name="dbSpectrogramData">The original data for decibel spectrogram.</param>
            <param name="nrSpectrogram">The noise-reduced spectrogram.</param>
            <param name="sourceRecordingName">Name of the source file. Required only to add label to spectrogram.</param>
            <returns>Image of spectrogram.</returns>
        </member>
        <member name="M:AnalysisPrograms.SpectrogramGenerator.SpectrogramGenerator.GetCepstrogram(AudioAnalysisTools.StandardSpectrograms.SonogramConfig,AudioAnalysisTools.WavTools.AudioRecording,System.String)">
            <summary>
            Returns a cepstrogram image.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.SpectrogramGenerator.SpectrogramGeneratorConfig.BgNoiseThreshold">
            <summary>
            The default threshold = zero decibels.
            This removes the least background noise.
            Values up to 4 decibels are possibly effective.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.SpectrogramGenerator.SpectrogramGeneratorConfig.DifferenceThreshold">
            <summary>
            DIFFERENCE SPECTROGRAM - PARAMETER (in decibels).
            </summary>
        </member>
        <member name="P:AnalysisPrograms.SpectrogramGenerator.SpectrogramGeneratorConfig.DoPreemphasis">
            <summary>
            CEPSTROGRAM - PARAMETER.
            Do pre-emphasis prior to FFT.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.SpectrogramGenerator.SpectrogramGeneratorConfig.FilterbankCount">
            <summary>
            CEPSTROGRAM - PARAMETER
            The size of the Mel-scale filter bank.
            The default value is 64.
            THe minimum I have seen referenced = 26.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.SpectrogramGenerator.SpectrogramGeneratorConfig.IncludeDelta">
            <summary>
            CEPSTROGRAM - PARAMETER.
            Include the delta features in the returned MFCC feature vector.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.SpectrogramGenerator.SpectrogramGeneratorConfig.IncludeDoubleDelta">
            <summary>
            CEPSTROGRAM - PARAMETER.
            Include the delta-delta or acceleration features in the returned MFCC feature vector.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.SpectrogramGenerator.SpectrogramGeneratorConfig.NeighborhoodSeconds">
            <summary>
            LOCAL CONTRAST NORMALIZATION PARAMETERS.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.SpectrogramGenerator.SpectrogramGeneratorConfig.LcnContrastLevel">
            <summary>
            LOCAL CONTRAST NORMALIZATION PARAMETERS.
            </summary>
        </member>
        <member name="P:AnalysisPrograms.SpectrogramGenerator.SpectrogramGeneratorConfig.Images">
            <summary>
            Which images to draw. Defaults to all of them.
            </summary>
        </member>
        <member name="M:AnalysisPrograms.SPT.doSPT(AudioAnalysisTools.StandardSpectrograms.BaseSonogram,System.Double,System.Int32)">
            <summary>
            Performs Spectral Peak Tracking on a recording
            Returns a matrix derived from the sonogram.
            </summary>
            <param name="sonogram">the sonogram.</param>
            <param name="intensityThreshold">Intensity threshold in decibels above backgorund.</param>
            <param name="smallLengthThreshold">remove event swhose length is less than this threshold.</param>
        </member>
        <member name="M:AnalysisPrograms.SPT.doSPT(System.Double[0:,0:],System.Double,System.Int32)">
            <summary>
            Performs Spectral Peak Tracking on a recording
            Returns a matrix derived from the passed sonogram.Data().
            </summary>
            <param name="intensityThreshold">Intensity threshold in decibels above backgorund.</param>
            <param name="smallLengthThreshold">remove event swhose length is less than this threshold.</param>
        </member>
        <member name="T:AnalysisPrograms.SurfAnalysis.CsvDataRecord">
            <summary>
            In line class used to store a single record read from a line of the csv file.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.SurfAnalysis.AudioToSonogramResult">
            <summary>
            In line class used to return results from the static method GenerateFourSpectrogramImages().
            </summary>
        </member>
        <member name="T:AnalysisPrograms.PreprocessorForSurfAnalysis">
            <summary>
            This analyzer preprocesses short audio segments a few seconds to maximum 1 minute long for processing by a convolutional Deep NN.
            It does not accumulate data or other indices over a long recording.
            </summary>
        </member>
        <member name="T:AnalysisPrograms.BuildMetadata">
            <summary>
            Automatically generated metadata for the build that generated this code.
            </summary>
        </member>
    </members>
</doc>
